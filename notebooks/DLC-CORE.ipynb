{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heard-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "applied-junction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "offshore-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcutcore as deeplabcut\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chubby-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = r'C:\\Users\\Peter\\Dropbox\\behavior_analysis\\proj-pw-2021-02-11\\config.yaml'\n",
    "video_path = r'C:\\Users\\Peter\\Dropbox\\behavior_analysis\\proj-pw-2021-02-11\\videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "invisible-parts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\Dropbox\\behavior_analysis\\proj-pw-2021-02-11\\training-datasets\\iteration-0\\UnaugmentedDataSet_projFeb11  already exists!\n",
      "C:\\Users\\Peter\\Dropbox\\behavior_analysis\\proj-pw-2021-02-11\\labeled-data\\00089__x__TRIAL_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Dropbox\\behavior_analysis\\proj-pw-2021-02-11\\labeled-data\\00090__x__TRIAL_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "Downloading a ImageNet-pretrained model from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz....\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.85,\n",
       "  1,\n",
       "  (array([ 5,  9, 19,  1, 33, 38,  2, 35, 11, 28,  4, 12, 16, 31, 10, 20, 27,\n",
       "          21,  0,  8, 13, 30, 26, 29, 36, 24, 17, 14,  3, 32, 18, 34, 15]),\n",
       "   array([37, 25, 23,  7,  6, 22])))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "extensive-novel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['paw', 'index', 'pinky', 'pellet'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\proj_pw85shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis_tf2\\\\lib\\\\site-packages\\\\deeplabcutcore\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\Documentation_data-proj_85shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\dlc-models\\\\iteration-0\\\\projFeb11-trainset85shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching batchsize to 1, as default/tensorpack/deterministic loaders do not support batches >1. Use imgaug loader.\n",
      "Starting with standard pose-dataset loader.\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\n",
      "Display_iters overwritten as 500\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\dlc-models\\\\iteration-0\\\\projFeb11-trainset85shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['paw', 'index', 'pinky', 'pellet'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\proj_pw85shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis_tf2\\\\lib\\\\site-packages\\\\deeplabcutcore\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\Documentation_data-proj_85shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'output_stride': 16, 'deconvolutionstride': 2}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 500 loss: 0.0315 lr: 0.005\n",
      "iteration: 1000 loss: 0.0177 lr: 0.005\n",
      "iteration: 1500 loss: 0.0152 lr: 0.005\n",
      "iteration: 2000 loss: 0.0132 lr: 0.005\n",
      "iteration: 2500 loss: 0.0119 lr: 0.005\n",
      "iteration: 3000 loss: 0.0107 lr: 0.005\n",
      "iteration: 3500 loss: 0.0096 lr: 0.005\n",
      "iteration: 4000 loss: 0.0090 lr: 0.005\n",
      "iteration: 4500 loss: 0.0085 lr: 0.005\n",
      "iteration: 5000 loss: 0.0081 lr: 0.005\n",
      "iteration: 5500 loss: 0.0075 lr: 0.005\n",
      "iteration: 6000 loss: 0.0073 lr: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 6500 loss: 0.0071 lr: 0.005\n",
      "iteration: 7000 loss: 0.0068 lr: 0.005\n",
      "iteration: 7500 loss: 0.0064 lr: 0.005\n",
      "iteration: 8000 loss: 0.0066 lr: 0.005\n",
      "iteration: 8500 loss: 0.0061 lr: 0.005\n",
      "iteration: 9000 loss: 0.0060 lr: 0.005\n",
      "iteration: 9500 loss: 0.0060 lr: 0.005\n",
      "iteration: 10000 loss: 0.0058 lr: 0.005\n",
      "iteration: 10500 loss: 0.0105 lr: 0.02\n",
      "iteration: 11000 loss: 0.0091 lr: 0.02\n",
      "iteration: 11500 loss: 0.0081 lr: 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8c61d62a1d5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         [_, loss_val, summary] = sess.run([train_op, total_loss, merged_summaries],\n\u001b[1;32m--> 192\u001b[1;33m                                           feed_dict={learning_rate: current_lr})\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 958\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1181\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path, displayiters=500, saveiters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "anonymous-filename",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['paw', 'index', 'pinky', 'pellet'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\proj_pw85shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis_tf2\\\\lib\\\\site-packages\\\\deeplabcutcore\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\Documentation_data-proj_85shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\dlc-models\\\\iteration-0\\\\projFeb11-trainset85shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_projFeb11shuffle1_11000  with # of trainingiterations: 11000\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\Dropbox\\behavior_analysis\\proj-pw-2021-02-11\\dlc-models\\iteration-0\\projFeb11-trainset85shuffle1\\train\\snapshot-11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:00, 46.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-11000\n",
      "Results for 11000  training iterations: 85 1 train error: 3.66 pixels. Test error: 5.05  pixels.\n",
      "With pcutoff of 0.6  train error: 3.66 pixels. Test error: 5.05 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "authentic-stanford",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['paw', 'index', 'pinky', 'pellet'],\n",
      " 'batch_size': 8,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\proj_pw85shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis_tf2\\\\lib\\\\site-packages\\\\deeplabcutcore\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\Documentation_data-proj_85shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'num_outputs': 1,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\dlc-models\\\\iteration-0\\\\projFeb11-trainset85shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-11000 for model C:\\Users\\Peter\\Dropbox\\behavior_analysis\\proj-pw-2021-02-11\\dlc-models\\iteration-0\\projFeb11-trainset85shuffle1\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\Dropbox\\behavior_analysis\\proj-pw-2021-02-11\\dlc-models\\iteration-0\\projFeb11-trainset85shuffle1\\train\\snapshot-11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                                                                                      | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Starting to analyze %  00086__x__TRIAL_FRONT.avi\n",
      "Loading  00086__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:09, 173.26it/s]                                                                                                                                                                                                                                                                                          \n",
      "  3%|████████                                                                                                                                                                                                                                                                    | 48/1600 [00:00<00:05, 300.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00090__x__TRIAL_FRONT.avi\n",
      "Loading  00090__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:08, 189.49it/s]                                                                                                                                                                                                                                                                                          \n",
      "  3%|████████                                                                                                                                                                                                                                                                    | 48/1600 [00:00<00:04, 315.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00084__x__TRIAL_FRONT.avi\n",
      "Loading  00084__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:08, 188.23it/s]                                                                                                                                                                                                                                                                                          \n",
      "  3%|████████                                                                                                                                                                                                                                                                    | 48/1600 [00:00<00:05, 307.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00089__x__TRIAL_FRONT.avi\n",
      "Loading  00089__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:08, 190.45it/s]                                                                                                                                                                                                                                                                                          \n",
      "  3%|████████                                                                                                                                                                                                                                                                    | 48/1600 [00:00<00:05, 291.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00082__x__TRIAL_FRONT.avi\n",
      "Loading  00082__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:08, 186.54it/s]                                                                                                                                                                                                                                                                                          \n",
      "  0%|                                                                                                                                                                                                                                                                                      | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00083__x__TRIAL_FRONT.avi\n",
      "Loading  00083__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:08, 189.42it/s]                                                                                                                                                                                                                                                                                          \n",
      "  3%|████████                                                                                                                                                                                                                                                                    | 48/1600 [00:00<00:05, 300.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00081__x__TRIAL_FRONT.avi\n",
      "Loading  00081__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:08, 191.44it/s]                                                                                                                                                                                                                                                                                          \n",
      "  3%|████████                                                                                                                                                                                                                                                                    | 48/1600 [00:00<00:05, 289.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00085__x__TRIAL_FRONT.avi\n",
      "Loading  00085__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:08, 191.39it/s]                                                                                                                                                                                                                                                                                          \n",
      "  3%|████████                                                                                                                                                                                                                                                                    | 48/1600 [00:00<00:05, 305.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00087__x__TRIAL_FRONT.avi\n",
      "Loading  00087__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:08, 193.22it/s]                                                                                                                                                                                                                                                                                          \n",
      "  3%|████████                                                                                                                                                                                                                                                                    | 48/1600 [00:00<00:05, 298.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00088__x__TRIAL_FRONT.avi\n",
      "Loading  00088__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:08, 191.80it/s]                                                                                                                                                                                                                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_projFeb11shuffle1_11000'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config_path, videos=[video_path], videotype='avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "crucial-sharp",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 128.99it/s]\n",
      "4it [00:00, 105.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Filtering with median model 00087__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00085__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00088__x__TRIAL_FRONT.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 142.83it/s]\n",
      "4it [00:00, 137.97it/s]\n",
      "4it [00:00, 133.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Filtering with median model 00090__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00082__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 129.15it/s]\n",
      "4it [00:00, 133.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model 00084__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00086__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00083__x__TRIAL_FRONT.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 137.97it/s]\n",
      "4it [00:00, 137.89it/s]\n",
      "4it [00:00, 142.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Filtering with median model 00089__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00081__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.filterpredictions(config_path, [video_path], videotype='avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "herbal-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████████▍                                                                                                                                                                                                                                                                 | 62/1600 [00:00<00:02, 614.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00090__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 617.48it/s]\n",
      "  3%|█████████▏                                                                                                                                                                                                                                                                  | 55/1600 [00:00<00:02, 539.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00088__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 584.34it/s]\n",
      "  4%|█████████▉                                                                                                                                                                                                                                                                  | 59/1600 [00:00<00:02, 584.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00085__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 592.12it/s]\n",
      "  3%|████████▌                                                                                                                                                                                                                                                                   | 51/1600 [00:00<00:03, 505.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00086__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 603.28it/s]\n",
      "  3%|████████▋                                                                                                                                                                                                                                                                   | 52/1600 [00:00<00:03, 515.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00089__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 612.05it/s]\n",
      "  2%|█████▏                                                                                                                                                                                                                                                                      | 31/1600 [00:00<00:05, 301.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00082__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 607.63it/s]\n",
      "  3%|████████                                                                                                                                                                                                                                                                    | 48/1600 [00:00<00:03, 470.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00084__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 594.32it/s]\n",
      "  4%|█████████▍                                                                                                                                                                                                                                                                  | 56/1600 [00:00<00:02, 554.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00087__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 638.17it/s]\n",
      "  4%|██████████▍                                                                                                                                                                                                                                                                 | 62/1600 [00:00<00:02, 614.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00081__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 566.55it/s]\n",
      "  3%|███████                                                                                                                                                                                                                                                                     | 42/1600 [00:00<00:03, 407.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Dropbox\\\\behavior_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00083__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 554.96it/s]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(config_path, [video_path], videotype='avi', filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adult-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-maximum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
