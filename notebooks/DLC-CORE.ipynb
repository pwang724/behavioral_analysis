{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heard-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow\n",
    "tensorflow.__version__\n",
    "import deeplabcutcore as deeplabcut\n",
    "import matplotlib as mpl\n",
    "\n",
    "config_path = r'C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11\\config.yaml'\n",
    "video_path = r'C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11\\videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "invisible-parts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11\\training-datasets\\iteration-0\\UnaugmentedDataSet_projFeb11  already exists!\n",
      "C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11\\labeled-data\\00089__x__TRIAL_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11\\labeled-data\\00090__x__TRIAL_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.85,\n",
       "  1,\n",
       "  (array([16, 23,  1,  0, 19, 15, 29, 38, 26, 35, 32, 11,  5, 34,  6, 37, 18,\n",
       "           4, 31, 10, 33,  3, 27, 28, 24, 21, 25,  7, 12,  2, 14, 22,  9]),\n",
       "   array([13, 20, 17, 36, 30,  8])))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extensive-novel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['paw', 'index', 'pinky', 'pellet'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\proj_pw85shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis_tf2\\\\lib\\\\site-packages\\\\deeplabcutcore\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\Documentation_data-proj_85shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\dlc-models\\\\iteration-0\\\\projFeb11-trainset85shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching batchsize to 1, as default/tensorpack/deterministic loaders do not support batches >1. Use imgaug loader.\n",
      "Starting with standard pose-dataset loader.\n",
      "Initializing ResNet\n",
      "WARNING:tensorflow:From C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tf_slim\\layers\\layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\nnet\\losses.py:38: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\n",
      "Display_iters overwritten as 100\n",
      "Save_iters overwritten as 2000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\dlc-models\\\\iteration-0\\\\projFeb11-trainset85shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['paw', 'index', 'pinky', 'pellet'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\proj_pw85shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis_tf2\\\\lib\\\\site-packages\\\\deeplabcutcore\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\Documentation_data-proj_85shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'output_stride': 16, 'deconvolutionstride': 2}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 100 loss: 0.0611 lr: 0.005\n",
      "iteration: 200 loss: 0.0264 lr: 0.005\n",
      "iteration: 300 loss: 0.0222 lr: 0.005\n",
      "iteration: 400 loss: 0.0209 lr: 0.005\n",
      "iteration: 500 loss: 0.0202 lr: 0.005\n",
      "iteration: 600 loss: 0.0188 lr: 0.005\n",
      "iteration: 700 loss: 0.0188 lr: 0.005\n",
      "iteration: 800 loss: 0.0178 lr: 0.005\n",
      "iteration: 900 loss: 0.0169 lr: 0.005\n",
      "iteration: 1000 loss: 0.0164 lr: 0.005\n",
      "iteration: 1100 loss: 0.0162 lr: 0.005\n",
      "iteration: 1200 loss: 0.0156 lr: 0.005\n",
      "iteration: 1300 loss: 0.0155 lr: 0.005\n",
      "iteration: 1400 loss: 0.0152 lr: 0.005\n",
      "iteration: 1500 loss: 0.0142 lr: 0.005\n",
      "iteration: 1600 loss: 0.0138 lr: 0.005\n",
      "iteration: 1700 loss: 0.0137 lr: 0.005\n",
      "iteration: 1800 loss: 0.0136 lr: 0.005\n",
      "iteration: 1900 loss: 0.0135 lr: 0.005\n",
      "iteration: 2000 loss: 0.0133 lr: 0.005\n",
      "iteration: 2100 loss: 0.0134 lr: 0.005\n",
      "iteration: 2200 loss: 0.0127 lr: 0.005\n",
      "iteration: 2300 loss: 0.0126 lr: 0.005\n",
      "iteration: 2400 loss: 0.0119 lr: 0.005\n",
      "iteration: 2500 loss: 0.0117 lr: 0.005\n",
      "iteration: 2600 loss: 0.0117 lr: 0.005\n",
      "iteration: 2700 loss: 0.0113 lr: 0.005\n",
      "iteration: 2800 loss: 0.0114 lr: 0.005\n",
      "iteration: 2900 loss: 0.0115 lr: 0.005\n",
      "iteration: 3000 loss: 0.0106 lr: 0.005\n",
      "iteration: 3100 loss: 0.0107 lr: 0.005\n",
      "iteration: 3200 loss: 0.0111 lr: 0.005\n",
      "iteration: 3300 loss: 0.0107 lr: 0.005\n",
      "iteration: 3400 loss: 0.0101 lr: 0.005\n",
      "iteration: 3500 loss: 0.0095 lr: 0.005\n",
      "iteration: 3600 loss: 0.0104 lr: 0.005\n",
      "iteration: 3700 loss: 0.0098 lr: 0.005\n",
      "iteration: 3800 loss: 0.0094 lr: 0.005\n",
      "iteration: 3900 loss: 0.0104 lr: 0.005\n",
      "iteration: 4000 loss: 0.0094 lr: 0.005\n",
      "iteration: 4100 loss: 0.0100 lr: 0.005\n",
      "iteration: 4200 loss: 0.0097 lr: 0.005\n",
      "iteration: 4300 loss: 0.0097 lr: 0.005\n",
      "iteration: 4400 loss: 0.0087 lr: 0.005\n",
      "iteration: 4500 loss: 0.0087 lr: 0.005\n",
      "iteration: 4600 loss: 0.0091 lr: 0.005\n",
      "iteration: 4700 loss: 0.0088 lr: 0.005\n",
      "iteration: 4800 loss: 0.0088 lr: 0.005\n",
      "iteration: 4900 loss: 0.0090 lr: 0.005\n",
      "iteration: 5000 loss: 0.0089 lr: 0.005\n",
      "iteration: 5100 loss: 0.0087 lr: 0.005\n",
      "iteration: 5200 loss: 0.0087 lr: 0.005\n",
      "iteration: 5300 loss: 0.0084 lr: 0.005\n",
      "iteration: 5400 loss: 0.0078 lr: 0.005\n",
      "iteration: 5500 loss: 0.0080 lr: 0.005\n",
      "iteration: 5600 loss: 0.0080 lr: 0.005\n",
      "iteration: 5700 loss: 0.0080 lr: 0.005\n",
      "iteration: 5800 loss: 0.0084 lr: 0.005\n",
      "iteration: 5900 loss: 0.0080 lr: 0.005\n",
      "iteration: 6000 loss: 0.0082 lr: 0.005\n",
      "iteration: 6100 loss: 0.0078 lr: 0.005\n",
      "iteration: 6200 loss: 0.0077 lr: 0.005\n",
      "iteration: 6300 loss: 0.0081 lr: 0.005\n",
      "iteration: 6400 loss: 0.0078 lr: 0.005\n",
      "iteration: 6500 loss: 0.0075 lr: 0.005\n",
      "iteration: 6600 loss: 0.0075 lr: 0.005\n",
      "iteration: 6700 loss: 0.0074 lr: 0.005\n",
      "iteration: 6800 loss: 0.0075 lr: 0.005\n",
      "iteration: 6900 loss: 0.0078 lr: 0.005\n",
      "iteration: 7000 loss: 0.0074 lr: 0.005\n",
      "iteration: 7100 loss: 0.0073 lr: 0.005\n",
      "iteration: 7200 loss: 0.0082 lr: 0.005\n",
      "iteration: 7300 loss: 0.0071 lr: 0.005\n",
      "iteration: 7400 loss: 0.0072 lr: 0.005\n",
      "iteration: 7500 loss: 0.0070 lr: 0.005\n",
      "iteration: 7600 loss: 0.0067 lr: 0.005\n",
      "iteration: 7700 loss: 0.0070 lr: 0.005\n",
      "iteration: 7800 loss: 0.0069 lr: 0.005\n",
      "iteration: 7900 loss: 0.0072 lr: 0.005\n",
      "iteration: 8000 loss: 0.0066 lr: 0.005\n",
      "iteration: 8100 loss: 0.0066 lr: 0.005\n",
      "iteration: 8200 loss: 0.0066 lr: 0.005\n",
      "iteration: 8300 loss: 0.0069 lr: 0.005\n",
      "iteration: 8400 loss: 0.0067 lr: 0.005\n",
      "iteration: 8500 loss: 0.0074 lr: 0.005\n",
      "iteration: 8600 loss: 0.0068 lr: 0.005\n",
      "iteration: 8700 loss: 0.0069 lr: 0.005\n",
      "iteration: 8800 loss: 0.0071 lr: 0.005\n",
      "iteration: 8900 loss: 0.0065 lr: 0.005\n",
      "iteration: 9000 loss: 0.0068 lr: 0.005\n",
      "iteration: 9100 loss: 0.0067 lr: 0.005\n",
      "iteration: 9200 loss: 0.0065 lr: 0.005\n",
      "iteration: 9300 loss: 0.0068 lr: 0.005\n",
      "iteration: 9400 loss: 0.0067 lr: 0.005\n",
      "iteration: 9500 loss: 0.0066 lr: 0.005\n",
      "iteration: 9600 loss: 0.0066 lr: 0.005\n",
      "iteration: 9700 loss: 0.0063 lr: 0.005\n",
      "iteration: 9800 loss: 0.0062 lr: 0.005\n",
      "iteration: 9900 loss: 0.0062 lr: 0.005\n",
      "iteration: 10000 loss: 0.0065 lr: 0.005\n",
      "iteration: 10100 loss: 0.0107 lr: 0.02\n",
      "iteration: 10200 loss: 0.0126 lr: 0.02\n",
      "iteration: 10300 loss: 0.0114 lr: 0.02\n",
      "iteration: 10400 loss: 0.0108 lr: 0.02\n",
      "iteration: 10500 loss: 0.0095 lr: 0.02\n",
      "iteration: 10600 loss: 0.0100 lr: 0.02\n",
      "iteration: 10700 loss: 0.0107 lr: 0.02\n",
      "iteration: 10800 loss: 0.0094 lr: 0.02\n",
      "iteration: 10900 loss: 0.0097 lr: 0.02\n",
      "iteration: 11000 loss: 0.0093 lr: 0.02\n",
      "iteration: 11100 loss: 0.0083 lr: 0.02\n",
      "iteration: 11200 loss: 0.0082 lr: 0.02\n",
      "iteration: 11300 loss: 0.0085 lr: 0.02\n",
      "iteration: 11400 loss: 0.0087 lr: 0.02\n",
      "iteration: 11500 loss: 0.0080 lr: 0.02\n",
      "iteration: 11600 loss: 0.0078 lr: 0.02\n",
      "iteration: 11700 loss: 0.0083 lr: 0.02\n",
      "iteration: 11800 loss: 0.0079 lr: 0.02\n",
      "iteration: 11900 loss: 0.0084 lr: 0.02\n",
      "iteration: 12000 loss: 0.0076 lr: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 12100 loss: 0.0071 lr: 0.02\n",
      "iteration: 12200 loss: 0.0081 lr: 0.02\n",
      "iteration: 12300 loss: 0.0070 lr: 0.02\n",
      "iteration: 12400 loss: 0.0071 lr: 0.02\n",
      "iteration: 12500 loss: 0.0071 lr: 0.02\n",
      "iteration: 12600 loss: 0.0074 lr: 0.02\n",
      "iteration: 12700 loss: 0.0069 lr: 0.02\n",
      "iteration: 12800 loss: 0.0076 lr: 0.02\n",
      "iteration: 12900 loss: 0.0069 lr: 0.02\n",
      "iteration: 13000 loss: 0.0072 lr: 0.02\n",
      "iteration: 13100 loss: 0.0070 lr: 0.02\n",
      "iteration: 13200 loss: 0.0064 lr: 0.02\n",
      "iteration: 13300 loss: 0.0065 lr: 0.02\n",
      "iteration: 13400 loss: 0.0069 lr: 0.02\n",
      "iteration: 13500 loss: 0.0070 lr: 0.02\n",
      "iteration: 13600 loss: 0.0066 lr: 0.02\n",
      "iteration: 13700 loss: 0.0065 lr: 0.02\n",
      "iteration: 13800 loss: 0.0064 lr: 0.02\n",
      "iteration: 13900 loss: 0.0070 lr: 0.02\n",
      "iteration: 14000 loss: 0.0072 lr: 0.02\n",
      "iteration: 14100 loss: 0.0063 lr: 0.02\n",
      "iteration: 14200 loss: 0.0061 lr: 0.02\n",
      "iteration: 14300 loss: 0.0060 lr: 0.02\n",
      "iteration: 14400 loss: 0.0060 lr: 0.02\n",
      "iteration: 14500 loss: 0.0064 lr: 0.02\n",
      "iteration: 14600 loss: 0.0062 lr: 0.02\n",
      "iteration: 14700 loss: 0.0070 lr: 0.02\n",
      "iteration: 14800 loss: 0.0059 lr: 0.02\n",
      "iteration: 14900 loss: 0.0058 lr: 0.02\n",
      "iteration: 15000 loss: 0.0060 lr: 0.02\n",
      "iteration: 15100 loss: 0.0059 lr: 0.02\n",
      "iteration: 15200 loss: 0.0061 lr: 0.02\n",
      "iteration: 15300 loss: 0.0060 lr: 0.02\n",
      "iteration: 15400 loss: 0.0056 lr: 0.02\n",
      "iteration: 15500 loss: 0.0059 lr: 0.02\n",
      "iteration: 15600 loss: 0.0055 lr: 0.02\n",
      "iteration: 15700 loss: 0.0055 lr: 0.02\n",
      "iteration: 15800 loss: 0.0062 lr: 0.02\n",
      "iteration: 15900 loss: 0.0062 lr: 0.02\n",
      "iteration: 16000 loss: 0.0058 lr: 0.02\n",
      "iteration: 16100 loss: 0.0050 lr: 0.02\n",
      "iteration: 16200 loss: 0.0060 lr: 0.02\n",
      "iteration: 16300 loss: 0.0056 lr: 0.02\n",
      "iteration: 16400 loss: 0.0055 lr: 0.02\n",
      "iteration: 16500 loss: 0.0055 lr: 0.02\n",
      "iteration: 16600 loss: 0.0055 lr: 0.02\n",
      "iteration: 16700 loss: 0.0055 lr: 0.02\n",
      "iteration: 16800 loss: 0.0053 lr: 0.02\n",
      "iteration: 16900 loss: 0.0055 lr: 0.02\n",
      "iteration: 17000 loss: 0.0055 lr: 0.02\n",
      "iteration: 17100 loss: 0.0050 lr: 0.02\n",
      "iteration: 17200 loss: 0.0056 lr: 0.02\n",
      "iteration: 17300 loss: 0.0051 lr: 0.02\n",
      "iteration: 17400 loss: 0.0052 lr: 0.02\n",
      "iteration: 17500 loss: 0.0054 lr: 0.02\n",
      "iteration: 17600 loss: 0.0056 lr: 0.02\n",
      "iteration: 17700 loss: 0.0055 lr: 0.02\n",
      "iteration: 17800 loss: 0.0051 lr: 0.02\n",
      "iteration: 17900 loss: 0.0055 lr: 0.02\n",
      "iteration: 18000 loss: 0.0053 lr: 0.02\n",
      "iteration: 18100 loss: 0.0055 lr: 0.02\n",
      "iteration: 18200 loss: 0.0050 lr: 0.02\n",
      "iteration: 18300 loss: 0.0050 lr: 0.02\n",
      "iteration: 18400 loss: 0.0051 lr: 0.02\n",
      "iteration: 18500 loss: 0.0048 lr: 0.02\n",
      "iteration: 18600 loss: 0.0052 lr: 0.02\n",
      "iteration: 18700 loss: 0.0051 lr: 0.02\n",
      "iteration: 18800 loss: 0.0051 lr: 0.02\n",
      "iteration: 18900 loss: 0.0055 lr: 0.02\n",
      "iteration: 19000 loss: 0.0055 lr: 0.02\n",
      "iteration: 19100 loss: 0.0048 lr: 0.02\n",
      "iteration: 19200 loss: 0.0054 lr: 0.02\n",
      "iteration: 19300 loss: 0.0051 lr: 0.02\n",
      "iteration: 19400 loss: 0.0047 lr: 0.02\n",
      "iteration: 19500 loss: 0.0047 lr: 0.02\n",
      "iteration: 19600 loss: 0.0051 lr: 0.02\n",
      "iteration: 19700 loss: 0.0043 lr: 0.02\n",
      "iteration: 19800 loss: 0.0048 lr: 0.02\n",
      "iteration: 19900 loss: 0.0047 lr: 0.02\n",
      "iteration: 20000 loss: 0.0048 lr: 0.02\n",
      "iteration: 20100 loss: 0.0049 lr: 0.02\n",
      "iteration: 20200 loss: 0.0047 lr: 0.02\n",
      "iteration: 20300 loss: 0.0043 lr: 0.02\n",
      "iteration: 20400 loss: 0.0041 lr: 0.02\n",
      "iteration: 20500 loss: 0.0053 lr: 0.02\n",
      "iteration: 20600 loss: 0.0048 lr: 0.02\n",
      "iteration: 20700 loss: 0.0046 lr: 0.02\n",
      "iteration: 20800 loss: 0.0048 lr: 0.02\n",
      "iteration: 20900 loss: 0.0047 lr: 0.02\n",
      "iteration: 21000 loss: 0.0049 lr: 0.02\n",
      "iteration: 21100 loss: 0.0045 lr: 0.02\n",
      "iteration: 21200 loss: 0.0042 lr: 0.02\n",
      "iteration: 21300 loss: 0.0046 lr: 0.02\n",
      "iteration: 21400 loss: 0.0042 lr: 0.02\n",
      "iteration: 21500 loss: 0.0043 lr: 0.02\n",
      "iteration: 21600 loss: 0.0048 lr: 0.02\n",
      "iteration: 21700 loss: 0.0043 lr: 0.02\n",
      "iteration: 21800 loss: 0.0043 lr: 0.02\n",
      "iteration: 21900 loss: 0.0047 lr: 0.02\n",
      "iteration: 22000 loss: 0.0045 lr: 0.02\n",
      "iteration: 22100 loss: 0.0046 lr: 0.02\n",
      "iteration: 22200 loss: 0.0043 lr: 0.02\n",
      "iteration: 22300 loss: 0.0041 lr: 0.02\n",
      "iteration: 22400 loss: 0.0042 lr: 0.02\n",
      "iteration: 22500 loss: 0.0042 lr: 0.02\n",
      "iteration: 22600 loss: 0.0043 lr: 0.02\n",
      "iteration: 22700 loss: 0.0045 lr: 0.02\n",
      "iteration: 22800 loss: 0.0049 lr: 0.02\n",
      "iteration: 22900 loss: 0.0042 lr: 0.02\n",
      "iteration: 23000 loss: 0.0044 lr: 0.02\n",
      "iteration: 23100 loss: 0.0042 lr: 0.02\n",
      "iteration: 23200 loss: 0.0042 lr: 0.02\n",
      "iteration: 23300 loss: 0.0044 lr: 0.02\n",
      "iteration: 23400 loss: 0.0040 lr: 0.02\n",
      "iteration: 23500 loss: 0.0045 lr: 0.02\n",
      "iteration: 23600 loss: 0.0044 lr: 0.02\n",
      "iteration: 23700 loss: 0.0046 lr: 0.02\n",
      "iteration: 23800 loss: 0.0044 lr: 0.02\n",
      "iteration: 23900 loss: 0.0046 lr: 0.02\n",
      "iteration: 24000 loss: 0.0043 lr: 0.02\n",
      "iteration: 24100 loss: 0.0043 lr: 0.02\n",
      "iteration: 24200 loss: 0.0039 lr: 0.02\n",
      "iteration: 24300 loss: 0.0040 lr: 0.02\n",
      "iteration: 24400 loss: 0.0036 lr: 0.02\n",
      "iteration: 24500 loss: 0.0041 lr: 0.02\n",
      "iteration: 24600 loss: 0.0044 lr: 0.02\n",
      "iteration: 24700 loss: 0.0039 lr: 0.02\n",
      "iteration: 24800 loss: 0.0042 lr: 0.02\n",
      "iteration: 24900 loss: 0.0039 lr: 0.02\n",
      "iteration: 25000 loss: 0.0036 lr: 0.02\n",
      "iteration: 25100 loss: 0.0036 lr: 0.02\n",
      "iteration: 25200 loss: 0.0037 lr: 0.02\n",
      "iteration: 25300 loss: 0.0041 lr: 0.02\n",
      "iteration: 25400 loss: 0.0040 lr: 0.02\n",
      "iteration: 25500 loss: 0.0041 lr: 0.02\n",
      "iteration: 25600 loss: 0.0040 lr: 0.02\n",
      "iteration: 25700 loss: 0.0039 lr: 0.02\n",
      "iteration: 25800 loss: 0.0045 lr: 0.02\n",
      "iteration: 25900 loss: 0.0048 lr: 0.02\n",
      "iteration: 26000 loss: 0.0040 lr: 0.02\n",
      "iteration: 26100 loss: 0.0039 lr: 0.02\n",
      "iteration: 26200 loss: 0.0038 lr: 0.02\n",
      "iteration: 26300 loss: 0.0039 lr: 0.02\n",
      "iteration: 26400 loss: 0.0041 lr: 0.02\n",
      "iteration: 26500 loss: 0.0038 lr: 0.02\n",
      "iteration: 26600 loss: 0.0036 lr: 0.02\n",
      "iteration: 26700 loss: 0.0035 lr: 0.02\n",
      "iteration: 26800 loss: 0.0033 lr: 0.02\n",
      "iteration: 26900 loss: 0.0035 lr: 0.02\n",
      "iteration: 27000 loss: 0.0039 lr: 0.02\n",
      "iteration: 27100 loss: 0.0038 lr: 0.02\n",
      "iteration: 27200 loss: 0.0036 lr: 0.02\n",
      "iteration: 27300 loss: 0.0034 lr: 0.02\n",
      "iteration: 27400 loss: 0.0037 lr: 0.02\n",
      "iteration: 27500 loss: 0.0035 lr: 0.02\n",
      "iteration: 27600 loss: 0.0030 lr: 0.02\n",
      "iteration: 27700 loss: 0.0038 lr: 0.02\n",
      "iteration: 27800 loss: 0.0037 lr: 0.02\n",
      "iteration: 27900 loss: 0.0033 lr: 0.02\n",
      "iteration: 28000 loss: 0.0033 lr: 0.02\n",
      "iteration: 28100 loss: 0.0038 lr: 0.02\n",
      "iteration: 28200 loss: 0.0040 lr: 0.02\n",
      "iteration: 28300 loss: 0.0036 lr: 0.02\n",
      "iteration: 28400 loss: 0.0034 lr: 0.02\n",
      "iteration: 28500 loss: 0.0030 lr: 0.02\n",
      "iteration: 28600 loss: 0.0033 lr: 0.02\n",
      "iteration: 28700 loss: 0.0033 lr: 0.02\n",
      "iteration: 28800 loss: 0.0037 lr: 0.02\n",
      "iteration: 28900 loss: 0.0034 lr: 0.02\n",
      "iteration: 29000 loss: 0.0039 lr: 0.02\n",
      "iteration: 29100 loss: 0.0042 lr: 0.02\n",
      "iteration: 29200 loss: 0.0032 lr: 0.02\n",
      "iteration: 29300 loss: 0.0036 lr: 0.02\n",
      "iteration: 29400 loss: 0.0037 lr: 0.02\n",
      "iteration: 29500 loss: 0.0032 lr: 0.02\n",
      "iteration: 29600 loss: 0.0031 lr: 0.02\n",
      "iteration: 29700 loss: 0.0033 lr: 0.02\n",
      "iteration: 29800 loss: 0.0037 lr: 0.02\n",
      "iteration: 29900 loss: 0.0035 lr: 0.02\n",
      "iteration: 30000 loss: 0.0036 lr: 0.02\n",
      "iteration: 30100 loss: 0.0030 lr: 0.02\n",
      "iteration: 30200 loss: 0.0033 lr: 0.02\n",
      "iteration: 30300 loss: 0.0037 lr: 0.02\n",
      "iteration: 30400 loss: 0.0037 lr: 0.02\n",
      "iteration: 30500 loss: 0.0031 lr: 0.02\n",
      "iteration: 30600 loss: 0.0032 lr: 0.02\n",
      "iteration: 30700 loss: 0.0032 lr: 0.02\n",
      "iteration: 30800 loss: 0.0037 lr: 0.02\n",
      "iteration: 30900 loss: 0.0031 lr: 0.02\n",
      "iteration: 31000 loss: 0.0031 lr: 0.02\n",
      "iteration: 31100 loss: 0.0031 lr: 0.02\n",
      "iteration: 31200 loss: 0.0032 lr: 0.02\n",
      "iteration: 31300 loss: 0.0033 lr: 0.02\n",
      "iteration: 31400 loss: 0.0032 lr: 0.02\n",
      "iteration: 31500 loss: 0.0034 lr: 0.02\n",
      "iteration: 31600 loss: 0.0031 lr: 0.02\n",
      "iteration: 31700 loss: 0.0031 lr: 0.02\n",
      "iteration: 31800 loss: 0.0029 lr: 0.02\n",
      "iteration: 31900 loss: 0.0034 lr: 0.02\n",
      "iteration: 32000 loss: 0.0032 lr: 0.02\n",
      "iteration: 32100 loss: 0.0032 lr: 0.02\n",
      "iteration: 32200 loss: 0.0031 lr: 0.02\n",
      "iteration: 32300 loss: 0.0029 lr: 0.02\n",
      "iteration: 32400 loss: 0.0032 lr: 0.02\n",
      "iteration: 32500 loss: 0.0029 lr: 0.02\n",
      "iteration: 32600 loss: 0.0027 lr: 0.02\n",
      "iteration: 32700 loss: 0.0025 lr: 0.02\n",
      "iteration: 32800 loss: 0.0033 lr: 0.02\n",
      "iteration: 32900 loss: 0.0029 lr: 0.02\n",
      "iteration: 33000 loss: 0.0028 lr: 0.02\n",
      "iteration: 33100 loss: 0.0027 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 33200 loss: 0.0031 lr: 0.02\n",
      "iteration: 33300 loss: 0.0029 lr: 0.02\n",
      "iteration: 33400 loss: 0.0026 lr: 0.02\n",
      "iteration: 33500 loss: 0.0031 lr: 0.02\n",
      "iteration: 33600 loss: 0.0029 lr: 0.02\n",
      "iteration: 33700 loss: 0.0029 lr: 0.02\n",
      "iteration: 33800 loss: 0.0030 lr: 0.02\n",
      "iteration: 33900 loss: 0.0037 lr: 0.02\n",
      "iteration: 34000 loss: 0.0035 lr: 0.02\n",
      "iteration: 34100 loss: 0.0034 lr: 0.02\n",
      "iteration: 34200 loss: 0.0029 lr: 0.02\n",
      "iteration: 34300 loss: 0.0026 lr: 0.02\n",
      "iteration: 34400 loss: 0.0028 lr: 0.02\n",
      "iteration: 34500 loss: 0.0029 lr: 0.02\n",
      "iteration: 34600 loss: 0.0029 lr: 0.02\n",
      "iteration: 34700 loss: 0.0024 lr: 0.02\n",
      "iteration: 34800 loss: 0.0027 lr: 0.02\n",
      "iteration: 34900 loss: 0.0028 lr: 0.02\n",
      "iteration: 35000 loss: 0.0028 lr: 0.02\n",
      "iteration: 35100 loss: 0.0028 lr: 0.02\n",
      "iteration: 35200 loss: 0.0031 lr: 0.02\n",
      "iteration: 35300 loss: 0.0025 lr: 0.02\n",
      "iteration: 35400 loss: 0.0027 lr: 0.02\n",
      "iteration: 35500 loss: 0.0024 lr: 0.02\n",
      "iteration: 35600 loss: 0.0029 lr: 0.02\n",
      "iteration: 35700 loss: 0.0025 lr: 0.02\n",
      "iteration: 35800 loss: 0.0030 lr: 0.02\n",
      "iteration: 35900 loss: 0.0028 lr: 0.02\n",
      "iteration: 36000 loss: 0.0028 lr: 0.02\n",
      "iteration: 36100 loss: 0.0025 lr: 0.02\n",
      "iteration: 36200 loss: 0.0029 lr: 0.02\n",
      "iteration: 36300 loss: 0.0027 lr: 0.02\n",
      "iteration: 36400 loss: 0.0027 lr: 0.02\n",
      "iteration: 36500 loss: 0.0024 lr: 0.02\n",
      "iteration: 36600 loss: 0.0024 lr: 0.02\n",
      "iteration: 36700 loss: 0.0025 lr: 0.02\n",
      "iteration: 36800 loss: 0.0022 lr: 0.02\n",
      "iteration: 36900 loss: 0.0026 lr: 0.02\n",
      "iteration: 37000 loss: 0.0027 lr: 0.02\n",
      "iteration: 37100 loss: 0.0029 lr: 0.02\n",
      "iteration: 37200 loss: 0.0022 lr: 0.02\n",
      "iteration: 37300 loss: 0.0026 lr: 0.02\n",
      "iteration: 37400 loss: 0.0027 lr: 0.02\n",
      "iteration: 37500 loss: 0.0025 lr: 0.02\n",
      "iteration: 37600 loss: 0.0027 lr: 0.02\n",
      "iteration: 37700 loss: 0.0033 lr: 0.02\n",
      "iteration: 37800 loss: 0.0028 lr: 0.02\n",
      "iteration: 37900 loss: 0.0025 lr: 0.02\n",
      "iteration: 38000 loss: 0.0024 lr: 0.02\n",
      "iteration: 38100 loss: 0.0024 lr: 0.02\n",
      "iteration: 38200 loss: 0.0029 lr: 0.02\n",
      "iteration: 38300 loss: 0.0025 lr: 0.02\n",
      "iteration: 38400 loss: 0.0022 lr: 0.02\n",
      "iteration: 38500 loss: 0.0021 lr: 0.02\n",
      "iteration: 38600 loss: 0.0024 lr: 0.02\n",
      "iteration: 38700 loss: 0.0030 lr: 0.02\n",
      "iteration: 38800 loss: 0.0026 lr: 0.02\n",
      "iteration: 38900 loss: 0.0025 lr: 0.02\n",
      "iteration: 39000 loss: 0.0022 lr: 0.02\n",
      "iteration: 39100 loss: 0.0023 lr: 0.02\n",
      "iteration: 39200 loss: 0.0023 lr: 0.02\n",
      "iteration: 39300 loss: 0.0026 lr: 0.02\n",
      "iteration: 39400 loss: 0.0026 lr: 0.02\n",
      "iteration: 39500 loss: 0.0025 lr: 0.02\n",
      "iteration: 39600 loss: 0.0023 lr: 0.02\n",
      "iteration: 39700 loss: 0.0024 lr: 0.02\n",
      "iteration: 39800 loss: 0.0023 lr: 0.02\n",
      "iteration: 39900 loss: 0.0032 lr: 0.02\n",
      "iteration: 40000 loss: 0.0025 lr: 0.02\n",
      "iteration: 40100 loss: 0.0024 lr: 0.02\n",
      "iteration: 40200 loss: 0.0025 lr: 0.02\n",
      "iteration: 40300 loss: 0.0024 lr: 0.02\n",
      "iteration: 40400 loss: 0.0026 lr: 0.02\n",
      "iteration: 40500 loss: 0.0022 lr: 0.02\n",
      "iteration: 40600 loss: 0.0023 lr: 0.02\n",
      "iteration: 40700 loss: 0.0023 lr: 0.02\n",
      "iteration: 40800 loss: 0.0023 lr: 0.02\n",
      "iteration: 40900 loss: 0.0026 lr: 0.02\n",
      "iteration: 41000 loss: 0.0027 lr: 0.02\n",
      "iteration: 41100 loss: 0.0020 lr: 0.02\n",
      "iteration: 41200 loss: 0.0023 lr: 0.02\n",
      "iteration: 41300 loss: 0.0027 lr: 0.02\n",
      "iteration: 41400 loss: 0.0022 lr: 0.02\n",
      "iteration: 41500 loss: 0.0023 lr: 0.02\n",
      "iteration: 41600 loss: 0.0024 lr: 0.02\n",
      "iteration: 41700 loss: 0.0024 lr: 0.02\n",
      "iteration: 41800 loss: 0.0022 lr: 0.02\n",
      "iteration: 41900 loss: 0.0021 lr: 0.02\n",
      "iteration: 42000 loss: 0.0020 lr: 0.02\n",
      "iteration: 42100 loss: 0.0020 lr: 0.02\n",
      "iteration: 42200 loss: 0.0020 lr: 0.02\n",
      "iteration: 42300 loss: 0.0021 lr: 0.02\n",
      "iteration: 42400 loss: 0.0021 lr: 0.02\n",
      "iteration: 42500 loss: 0.0022 lr: 0.02\n",
      "iteration: 42600 loss: 0.0025 lr: 0.02\n",
      "iteration: 42700 loss: 0.0023 lr: 0.02\n",
      "iteration: 42800 loss: 0.0021 lr: 0.02\n",
      "iteration: 42900 loss: 0.0024 lr: 0.02\n",
      "iteration: 43000 loss: 0.0024 lr: 0.02\n",
      "iteration: 43100 loss: 0.0024 lr: 0.02\n",
      "iteration: 43200 loss: 0.0021 lr: 0.02\n",
      "iteration: 43300 loss: 0.0020 lr: 0.02\n",
      "iteration: 43400 loss: 0.0021 lr: 0.02\n",
      "iteration: 43500 loss: 0.0020 lr: 0.02\n",
      "iteration: 43600 loss: 0.0021 lr: 0.02\n",
      "iteration: 43700 loss: 0.0020 lr: 0.02\n",
      "iteration: 43800 loss: 0.0021 lr: 0.02\n",
      "iteration: 43900 loss: 0.0022 lr: 0.02\n",
      "iteration: 44000 loss: 0.0029 lr: 0.02\n",
      "iteration: 44100 loss: 0.0036 lr: 0.02\n",
      "iteration: 44200 loss: 0.0027 lr: 0.02\n",
      "iteration: 44300 loss: 0.0025 lr: 0.02\n",
      "iteration: 44400 loss: 0.0024 lr: 0.02\n",
      "iteration: 44500 loss: 0.0022 lr: 0.02\n",
      "iteration: 44600 loss: 0.0021 lr: 0.02\n",
      "iteration: 44700 loss: 0.0022 lr: 0.02\n",
      "iteration: 44800 loss: 0.0022 lr: 0.02\n",
      "iteration: 44900 loss: 0.0021 lr: 0.02\n",
      "iteration: 45000 loss: 0.0021 lr: 0.02\n",
      "iteration: 45100 loss: 0.0020 lr: 0.02\n",
      "iteration: 45200 loss: 0.0021 lr: 0.02\n",
      "iteration: 45300 loss: 0.0020 lr: 0.02\n",
      "iteration: 45400 loss: 0.0022 lr: 0.02\n",
      "iteration: 45500 loss: 0.0022 lr: 0.02\n",
      "iteration: 45600 loss: 0.0021 lr: 0.02\n",
      "iteration: 45700 loss: 0.0024 lr: 0.02\n",
      "iteration: 45800 loss: 0.0021 lr: 0.02\n",
      "iteration: 45900 loss: 0.0022 lr: 0.02\n",
      "iteration: 46000 loss: 0.0023 lr: 0.02\n",
      "iteration: 46100 loss: 0.0021 lr: 0.02\n",
      "iteration: 46200 loss: 0.0025 lr: 0.02\n",
      "iteration: 46300 loss: 0.0027 lr: 0.02\n",
      "iteration: 46400 loss: 0.0020 lr: 0.02\n",
      "iteration: 46500 loss: 0.0020 lr: 0.02\n",
      "iteration: 46600 loss: 0.0021 lr: 0.02\n",
      "iteration: 46700 loss: 0.0021 lr: 0.02\n",
      "iteration: 46800 loss: 0.0019 lr: 0.02\n",
      "iteration: 46900 loss: 0.0020 lr: 0.02\n",
      "iteration: 47000 loss: 0.0020 lr: 0.02\n",
      "iteration: 47100 loss: 0.0020 lr: 0.02\n",
      "iteration: 47200 loss: 0.0023 lr: 0.02\n",
      "iteration: 47300 loss: 0.0021 lr: 0.02\n",
      "iteration: 47400 loss: 0.0021 lr: 0.02\n",
      "iteration: 47500 loss: 0.0021 lr: 0.02\n",
      "iteration: 47600 loss: 0.0024 lr: 0.02\n",
      "iteration: 47700 loss: 0.0023 lr: 0.02\n",
      "iteration: 47800 loss: 0.0019 lr: 0.02\n",
      "iteration: 47900 loss: 0.0020 lr: 0.02\n",
      "iteration: 48000 loss: 0.0020 lr: 0.02\n",
      "iteration: 48100 loss: 0.0019 lr: 0.02\n",
      "iteration: 48200 loss: 0.0019 lr: 0.02\n",
      "iteration: 48300 loss: 0.0019 lr: 0.02\n",
      "iteration: 48400 loss: 0.0019 lr: 0.02\n",
      "iteration: 48500 loss: 0.0026 lr: 0.02\n",
      "iteration: 48600 loss: 0.0034 lr: 0.02\n",
      "iteration: 48700 loss: 0.0020 lr: 0.02\n",
      "iteration: 48800 loss: 0.0022 lr: 0.02\n",
      "iteration: 48900 loss: 0.0024 lr: 0.02\n",
      "iteration: 49000 loss: 0.0018 lr: 0.02\n",
      "iteration: 49100 loss: 0.0021 lr: 0.02\n",
      "iteration: 49200 loss: 0.0019 lr: 0.02\n",
      "iteration: 49300 loss: 0.0021 lr: 0.02\n",
      "iteration: 49400 loss: 0.0026 lr: 0.02\n",
      "iteration: 49500 loss: 0.0022 lr: 0.02\n",
      "iteration: 49600 loss: 0.0021 lr: 0.02\n",
      "iteration: 49700 loss: 0.0020 lr: 0.02\n",
      "iteration: 49800 loss: 0.0022 lr: 0.02\n",
      "iteration: 49900 loss: 0.0019 lr: 0.02\n",
      "iteration: 50000 loss: 0.0021 lr: 0.02\n",
      "iteration: 50100 loss: 0.0022 lr: 0.02\n",
      "iteration: 50200 loss: 0.0022 lr: 0.02\n",
      "iteration: 50300 loss: 0.0021 lr: 0.02\n",
      "iteration: 50400 loss: 0.0022 lr: 0.02\n",
      "iteration: 50500 loss: 0.0023 lr: 0.02\n",
      "iteration: 50600 loss: 0.0021 lr: 0.02\n",
      "iteration: 50700 loss: 0.0030 lr: 0.02\n",
      "iteration: 50800 loss: 0.0027 lr: 0.02\n",
      "iteration: 50900 loss: 0.0019 lr: 0.02\n",
      "iteration: 51000 loss: 0.0020 lr: 0.02\n",
      "iteration: 51100 loss: 0.0020 lr: 0.02\n",
      "iteration: 51200 loss: 0.0018 lr: 0.02\n",
      "iteration: 51300 loss: 0.0019 lr: 0.02\n",
      "iteration: 51400 loss: 0.0017 lr: 0.02\n",
      "iteration: 51500 loss: 0.0020 lr: 0.02\n",
      "iteration: 51600 loss: 0.0018 lr: 0.02\n",
      "iteration: 51700 loss: 0.0021 lr: 0.02\n",
      "iteration: 51800 loss: 0.0018 lr: 0.02\n",
      "iteration: 51900 loss: 0.0021 lr: 0.02\n",
      "iteration: 52000 loss: 0.0020 lr: 0.02\n",
      "iteration: 52100 loss: 0.0019 lr: 0.02\n",
      "iteration: 52200 loss: 0.0019 lr: 0.02\n",
      "iteration: 52300 loss: 0.0018 lr: 0.02\n",
      "iteration: 52400 loss: 0.0018 lr: 0.02\n",
      "iteration: 52500 loss: 0.0019 lr: 0.02\n",
      "iteration: 52600 loss: 0.0017 lr: 0.02\n",
      "iteration: 52700 loss: 0.0020 lr: 0.02\n",
      "iteration: 52800 loss: 0.0018 lr: 0.02\n",
      "iteration: 52900 loss: 0.0018 lr: 0.02\n",
      "iteration: 53000 loss: 0.0018 lr: 0.02\n",
      "iteration: 53100 loss: 0.0017 lr: 0.02\n",
      "iteration: 53200 loss: 0.0018 lr: 0.02\n",
      "iteration: 53300 loss: 0.0020 lr: 0.02\n",
      "iteration: 53400 loss: 0.0019 lr: 0.02\n",
      "iteration: 53500 loss: 0.0020 lr: 0.02\n",
      "iteration: 53600 loss: 0.0019 lr: 0.02\n",
      "iteration: 53700 loss: 0.0020 lr: 0.02\n",
      "iteration: 53800 loss: 0.0019 lr: 0.02\n",
      "iteration: 53900 loss: 0.0020 lr: 0.02\n",
      "iteration: 54000 loss: 0.0019 lr: 0.02\n",
      "iteration: 54100 loss: 0.0018 lr: 0.02\n",
      "iteration: 54200 loss: 0.0019 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 54300 loss: 0.0018 lr: 0.02\n",
      "iteration: 54400 loss: 0.0017 lr: 0.02\n",
      "iteration: 54500 loss: 0.0016 lr: 0.02\n",
      "iteration: 54600 loss: 0.0021 lr: 0.02\n",
      "iteration: 54700 loss: 0.0019 lr: 0.02\n",
      "iteration: 54800 loss: 0.0019 lr: 0.02\n",
      "iteration: 54900 loss: 0.0021 lr: 0.02\n",
      "iteration: 55000 loss: 0.0019 lr: 0.02\n",
      "iteration: 55100 loss: 0.0018 lr: 0.02\n",
      "iteration: 55200 loss: 0.0018 lr: 0.02\n",
      "iteration: 55300 loss: 0.0020 lr: 0.02\n",
      "iteration: 55400 loss: 0.0018 lr: 0.02\n",
      "iteration: 55500 loss: 0.0023 lr: 0.02\n",
      "iteration: 55600 loss: 0.0024 lr: 0.02\n",
      "iteration: 55700 loss: 0.0019 lr: 0.02\n",
      "iteration: 55800 loss: 0.0018 lr: 0.02\n",
      "iteration: 55900 loss: 0.0018 lr: 0.02\n",
      "iteration: 56000 loss: 0.0019 lr: 0.02\n",
      "iteration: 56100 loss: 0.0017 lr: 0.02\n",
      "iteration: 56200 loss: 0.0018 lr: 0.02\n",
      "iteration: 56300 loss: 0.0023 lr: 0.02\n",
      "iteration: 56400 loss: 0.0020 lr: 0.02\n",
      "iteration: 56500 loss: 0.0020 lr: 0.02\n",
      "iteration: 56600 loss: 0.0022 lr: 0.02\n",
      "iteration: 56700 loss: 0.0025 lr: 0.02\n",
      "iteration: 56800 loss: 0.0020 lr: 0.02\n",
      "iteration: 56900 loss: 0.0017 lr: 0.02\n",
      "iteration: 57000 loss: 0.0020 lr: 0.02\n",
      "iteration: 57100 loss: 0.0019 lr: 0.02\n",
      "iteration: 57200 loss: 0.0019 lr: 0.02\n",
      "iteration: 57300 loss: 0.0017 lr: 0.02\n",
      "iteration: 57400 loss: 0.0016 lr: 0.02\n",
      "iteration: 57500 loss: 0.0018 lr: 0.02\n",
      "iteration: 57600 loss: 0.0017 lr: 0.02\n",
      "iteration: 57700 loss: 0.0018 lr: 0.02\n",
      "iteration: 57800 loss: 0.0018 lr: 0.02\n",
      "iteration: 57900 loss: 0.0020 lr: 0.02\n",
      "iteration: 58000 loss: 0.0016 lr: 0.02\n",
      "iteration: 58100 loss: 0.0017 lr: 0.02\n",
      "iteration: 58200 loss: 0.0017 lr: 0.02\n",
      "iteration: 58300 loss: 0.0015 lr: 0.02\n",
      "iteration: 58400 loss: 0.0015 lr: 0.02\n",
      "iteration: 58500 loss: 0.0020 lr: 0.02\n",
      "iteration: 58600 loss: 0.0019 lr: 0.02\n",
      "iteration: 58700 loss: 0.0022 lr: 0.02\n",
      "iteration: 58800 loss: 0.0018 lr: 0.02\n",
      "iteration: 58900 loss: 0.0017 lr: 0.02\n",
      "iteration: 59000 loss: 0.0017 lr: 0.02\n",
      "iteration: 59100 loss: 0.0018 lr: 0.02\n",
      "iteration: 59200 loss: 0.0016 lr: 0.02\n",
      "iteration: 59300 loss: 0.0018 lr: 0.02\n",
      "iteration: 59400 loss: 0.0018 lr: 0.02\n",
      "iteration: 59500 loss: 0.0022 lr: 0.02\n",
      "iteration: 59600 loss: 0.0020 lr: 0.02\n",
      "iteration: 59700 loss: 0.0019 lr: 0.02\n",
      "iteration: 59800 loss: 0.0016 lr: 0.02\n",
      "iteration: 59900 loss: 0.0019 lr: 0.02\n",
      "iteration: 60000 loss: 0.0017 lr: 0.02\n",
      "iteration: 60100 loss: 0.0014 lr: 0.02\n",
      "iteration: 60200 loss: 0.0020 lr: 0.02\n",
      "iteration: 60300 loss: 0.0018 lr: 0.02\n",
      "iteration: 60400 loss: 0.0017 lr: 0.02\n",
      "iteration: 60500 loss: 0.0017 lr: 0.02\n",
      "iteration: 60600 loss: 0.0016 lr: 0.02\n",
      "iteration: 60700 loss: 0.0019 lr: 0.02\n",
      "iteration: 60800 loss: 0.0017 lr: 0.02\n",
      "iteration: 60900 loss: 0.0016 lr: 0.02\n",
      "iteration: 61000 loss: 0.0018 lr: 0.02\n",
      "iteration: 61100 loss: 0.0017 lr: 0.02\n",
      "iteration: 61200 loss: 0.0015 lr: 0.02\n",
      "iteration: 61300 loss: 0.0016 lr: 0.02\n",
      "iteration: 61400 loss: 0.0017 lr: 0.02\n",
      "iteration: 61500 loss: 0.0017 lr: 0.02\n",
      "iteration: 61600 loss: 0.0018 lr: 0.02\n",
      "iteration: 61700 loss: 0.0016 lr: 0.02\n",
      "iteration: 61800 loss: 0.0016 lr: 0.02\n",
      "iteration: 61900 loss: 0.0015 lr: 0.02\n",
      "iteration: 62000 loss: 0.0019 lr: 0.02\n",
      "iteration: 62100 loss: 0.0017 lr: 0.02\n",
      "iteration: 62200 loss: 0.0016 lr: 0.02\n",
      "iteration: 62300 loss: 0.0015 lr: 0.02\n",
      "iteration: 62400 loss: 0.0015 lr: 0.02\n",
      "iteration: 62500 loss: 0.0017 lr: 0.02\n",
      "iteration: 62600 loss: 0.0019 lr: 0.02\n",
      "iteration: 62700 loss: 0.0017 lr: 0.02\n",
      "iteration: 62800 loss: 0.0017 lr: 0.02\n",
      "iteration: 62900 loss: 0.0017 lr: 0.02\n",
      "iteration: 63000 loss: 0.0016 lr: 0.02\n",
      "iteration: 63100 loss: 0.0018 lr: 0.02\n",
      "iteration: 63200 loss: 0.0015 lr: 0.02\n",
      "iteration: 63300 loss: 0.0017 lr: 0.02\n",
      "iteration: 63400 loss: 0.0018 lr: 0.02\n",
      "iteration: 63500 loss: 0.0017 lr: 0.02\n",
      "iteration: 63600 loss: 0.0018 lr: 0.02\n",
      "iteration: 63700 loss: 0.0015 lr: 0.02\n",
      "iteration: 63800 loss: 0.0017 lr: 0.02\n",
      "iteration: 63900 loss: 0.0018 lr: 0.02\n",
      "iteration: 64000 loss: 0.0016 lr: 0.02\n",
      "iteration: 64100 loss: 0.0016 lr: 0.02\n",
      "iteration: 64200 loss: 0.0017 lr: 0.02\n",
      "iteration: 64300 loss: 0.0019 lr: 0.02\n",
      "iteration: 64400 loss: 0.0015 lr: 0.02\n",
      "iteration: 64500 loss: 0.0017 lr: 0.02\n",
      "iteration: 64600 loss: 0.0016 lr: 0.02\n",
      "iteration: 64700 loss: 0.0019 lr: 0.02\n",
      "iteration: 64800 loss: 0.0016 lr: 0.02\n",
      "iteration: 64900 loss: 0.0017 lr: 0.02\n",
      "iteration: 65000 loss: 0.0018 lr: 0.02\n",
      "iteration: 65100 loss: 0.0017 lr: 0.02\n",
      "iteration: 65200 loss: 0.0016 lr: 0.02\n",
      "iteration: 65300 loss: 0.0020 lr: 0.02\n",
      "iteration: 65400 loss: 0.0016 lr: 0.02\n",
      "iteration: 65500 loss: 0.0018 lr: 0.02\n",
      "iteration: 65600 loss: 0.0016 lr: 0.02\n",
      "iteration: 65700 loss: 0.0015 lr: 0.02\n",
      "iteration: 65800 loss: 0.0015 lr: 0.02\n",
      "iteration: 65900 loss: 0.0014 lr: 0.02\n",
      "iteration: 66000 loss: 0.0016 lr: 0.02\n",
      "iteration: 66100 loss: 0.0015 lr: 0.02\n",
      "iteration: 66200 loss: 0.0018 lr: 0.02\n",
      "iteration: 66300 loss: 0.0018 lr: 0.02\n",
      "iteration: 66400 loss: 0.0023 lr: 0.02\n",
      "iteration: 66500 loss: 0.0018 lr: 0.02\n",
      "iteration: 66600 loss: 0.0017 lr: 0.02\n",
      "iteration: 66700 loss: 0.0017 lr: 0.02\n",
      "iteration: 66800 loss: 0.0016 lr: 0.02\n",
      "iteration: 66900 loss: 0.0018 lr: 0.02\n",
      "iteration: 67000 loss: 0.0019 lr: 0.02\n",
      "iteration: 67100 loss: 0.0016 lr: 0.02\n",
      "iteration: 67200 loss: 0.0017 lr: 0.02\n",
      "iteration: 67300 loss: 0.0017 lr: 0.02\n",
      "iteration: 67400 loss: 0.0015 lr: 0.02\n",
      "iteration: 67500 loss: 0.0016 lr: 0.02\n",
      "iteration: 67600 loss: 0.0016 lr: 0.02\n",
      "iteration: 67700 loss: 0.0015 lr: 0.02\n",
      "iteration: 67800 loss: 0.0013 lr: 0.02\n",
      "iteration: 67900 loss: 0.0014 lr: 0.02\n",
      "iteration: 68000 loss: 0.0021 lr: 0.02\n",
      "iteration: 68100 loss: 0.0018 lr: 0.02\n",
      "iteration: 68200 loss: 0.0017 lr: 0.02\n",
      "iteration: 68300 loss: 0.0018 lr: 0.02\n",
      "iteration: 68400 loss: 0.0019 lr: 0.02\n",
      "iteration: 68500 loss: 0.0016 lr: 0.02\n",
      "iteration: 68600 loss: 0.0017 lr: 0.02\n",
      "iteration: 68700 loss: 0.0018 lr: 0.02\n",
      "iteration: 68800 loss: 0.0020 lr: 0.02\n",
      "iteration: 68900 loss: 0.0017 lr: 0.02\n",
      "iteration: 69000 loss: 0.0016 lr: 0.02\n",
      "iteration: 69100 loss: 0.0013 lr: 0.02\n",
      "iteration: 69200 loss: 0.0014 lr: 0.02\n",
      "iteration: 69300 loss: 0.0015 lr: 0.02\n",
      "iteration: 69400 loss: 0.0016 lr: 0.02\n",
      "iteration: 69500 loss: 0.0016 lr: 0.02\n",
      "iteration: 69600 loss: 0.0018 lr: 0.02\n",
      "iteration: 69700 loss: 0.0017 lr: 0.02\n",
      "iteration: 69800 loss: 0.0017 lr: 0.02\n",
      "iteration: 69900 loss: 0.0015 lr: 0.02\n",
      "iteration: 70000 loss: 0.0015 lr: 0.02\n",
      "iteration: 70100 loss: 0.0014 lr: 0.02\n",
      "iteration: 70200 loss: 0.0017 lr: 0.02\n",
      "iteration: 70300 loss: 0.0015 lr: 0.02\n",
      "iteration: 70400 loss: 0.0018 lr: 0.02\n",
      "iteration: 70500 loss: 0.0016 lr: 0.02\n",
      "iteration: 70600 loss: 0.0017 lr: 0.02\n",
      "iteration: 70700 loss: 0.0018 lr: 0.02\n",
      "iteration: 70800 loss: 0.0016 lr: 0.02\n",
      "iteration: 70900 loss: 0.0015 lr: 0.02\n",
      "iteration: 71000 loss: 0.0015 lr: 0.02\n",
      "iteration: 71100 loss: 0.0016 lr: 0.02\n",
      "iteration: 71200 loss: 0.0017 lr: 0.02\n",
      "iteration: 71300 loss: 0.0015 lr: 0.02\n",
      "iteration: 71400 loss: 0.0015 lr: 0.02\n",
      "iteration: 71500 loss: 0.0016 lr: 0.02\n",
      "iteration: 71600 loss: 0.0018 lr: 0.02\n",
      "iteration: 71700 loss: 0.0016 lr: 0.02\n",
      "iteration: 71800 loss: 0.0014 lr: 0.02\n",
      "iteration: 71900 loss: 0.0019 lr: 0.02\n",
      "iteration: 72000 loss: 0.0015 lr: 0.02\n",
      "iteration: 72100 loss: 0.0014 lr: 0.02\n",
      "iteration: 72200 loss: 0.0021 lr: 0.02\n",
      "iteration: 72300 loss: 0.0018 lr: 0.02\n",
      "iteration: 72400 loss: 0.0017 lr: 0.02\n",
      "iteration: 72500 loss: 0.0016 lr: 0.02\n",
      "iteration: 72600 loss: 0.0023 lr: 0.02\n",
      "iteration: 72700 loss: 0.0018 lr: 0.02\n",
      "iteration: 72800 loss: 0.0015 lr: 0.02\n",
      "iteration: 72900 loss: 0.0014 lr: 0.02\n",
      "iteration: 73000 loss: 0.0014 lr: 0.02\n",
      "iteration: 73100 loss: 0.0015 lr: 0.02\n",
      "iteration: 73200 loss: 0.0013 lr: 0.02\n",
      "iteration: 73300 loss: 0.0018 lr: 0.02\n",
      "iteration: 73400 loss: 0.0015 lr: 0.02\n",
      "iteration: 73500 loss: 0.0016 lr: 0.02\n",
      "iteration: 73600 loss: 0.0014 lr: 0.02\n",
      "iteration: 73700 loss: 0.0016 lr: 0.02\n",
      "iteration: 73800 loss: 0.0018 lr: 0.02\n",
      "iteration: 73900 loss: 0.0017 lr: 0.02\n",
      "iteration: 74000 loss: 0.0015 lr: 0.02\n",
      "iteration: 74100 loss: 0.0015 lr: 0.02\n",
      "iteration: 74200 loss: 0.0015 lr: 0.02\n",
      "iteration: 74300 loss: 0.0020 lr: 0.02\n",
      "iteration: 74400 loss: 0.0018 lr: 0.02\n",
      "iteration: 74500 loss: 0.0016 lr: 0.02\n",
      "iteration: 74600 loss: 0.0017 lr: 0.02\n",
      "iteration: 74700 loss: 0.0015 lr: 0.02\n",
      "iteration: 74800 loss: 0.0013 lr: 0.02\n",
      "iteration: 74900 loss: 0.0015 lr: 0.02\n",
      "iteration: 75000 loss: 0.0016 lr: 0.02\n",
      "iteration: 75100 loss: 0.0015 lr: 0.02\n",
      "iteration: 75200 loss: 0.0016 lr: 0.02\n",
      "iteration: 75300 loss: 0.0016 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 75400 loss: 0.0015 lr: 0.02\n",
      "iteration: 75500 loss: 0.0014 lr: 0.02\n",
      "iteration: 75600 loss: 0.0016 lr: 0.02\n",
      "iteration: 75700 loss: 0.0016 lr: 0.02\n",
      "iteration: 75800 loss: 0.0015 lr: 0.02\n",
      "iteration: 75900 loss: 0.0016 lr: 0.02\n",
      "iteration: 76000 loss: 0.0015 lr: 0.02\n",
      "iteration: 76100 loss: 0.0018 lr: 0.02\n",
      "iteration: 76200 loss: 0.0016 lr: 0.02\n",
      "iteration: 76300 loss: 0.0014 lr: 0.02\n",
      "iteration: 76400 loss: 0.0016 lr: 0.02\n",
      "iteration: 76500 loss: 0.0016 lr: 0.02\n",
      "iteration: 76600 loss: 0.0015 lr: 0.02\n",
      "iteration: 76700 loss: 0.0014 lr: 0.02\n",
      "iteration: 76800 loss: 0.0015 lr: 0.02\n",
      "iteration: 76900 loss: 0.0016 lr: 0.02\n",
      "iteration: 77000 loss: 0.0017 lr: 0.02\n",
      "iteration: 77100 loss: 0.0016 lr: 0.02\n",
      "iteration: 77200 loss: 0.0015 lr: 0.02\n",
      "iteration: 77300 loss: 0.0014 lr: 0.02\n",
      "iteration: 77400 loss: 0.0015 lr: 0.02\n",
      "iteration: 77500 loss: 0.0014 lr: 0.02\n",
      "iteration: 77600 loss: 0.0014 lr: 0.02\n",
      "iteration: 77700 loss: 0.0014 lr: 0.02\n",
      "iteration: 77800 loss: 0.0015 lr: 0.02\n",
      "iteration: 77900 loss: 0.0015 lr: 0.02\n",
      "iteration: 78000 loss: 0.0016 lr: 0.02\n",
      "iteration: 78100 loss: 0.0013 lr: 0.02\n",
      "iteration: 78200 loss: 0.0015 lr: 0.02\n",
      "iteration: 78300 loss: 0.0017 lr: 0.02\n",
      "iteration: 78400 loss: 0.0015 lr: 0.02\n",
      "iteration: 78500 loss: 0.0016 lr: 0.02\n",
      "iteration: 78600 loss: 0.0016 lr: 0.02\n",
      "iteration: 78700 loss: 0.0015 lr: 0.02\n",
      "iteration: 78800 loss: 0.0013 lr: 0.02\n",
      "iteration: 78900 loss: 0.0013 lr: 0.02\n",
      "iteration: 79000 loss: 0.0015 lr: 0.02\n",
      "iteration: 79100 loss: 0.0015 lr: 0.02\n",
      "iteration: 79200 loss: 0.0016 lr: 0.02\n",
      "iteration: 79300 loss: 0.0014 lr: 0.02\n",
      "iteration: 79400 loss: 0.0015 lr: 0.02\n",
      "iteration: 79500 loss: 0.0015 lr: 0.02\n",
      "iteration: 79600 loss: 0.0014 lr: 0.02\n",
      "iteration: 79700 loss: 0.0019 lr: 0.02\n",
      "iteration: 79800 loss: 0.0015 lr: 0.02\n",
      "iteration: 79900 loss: 0.0014 lr: 0.02\n",
      "iteration: 80000 loss: 0.0013 lr: 0.02\n",
      "iteration: 80100 loss: 0.0014 lr: 0.02\n",
      "iteration: 80200 loss: 0.0017 lr: 0.02\n",
      "iteration: 80300 loss: 0.0015 lr: 0.02\n",
      "iteration: 80400 loss: 0.0015 lr: 0.02\n",
      "iteration: 80500 loss: 0.0014 lr: 0.02\n",
      "iteration: 80600 loss: 0.0016 lr: 0.02\n",
      "iteration: 80700 loss: 0.0013 lr: 0.02\n",
      "iteration: 80800 loss: 0.0016 lr: 0.02\n",
      "iteration: 80900 loss: 0.0014 lr: 0.02\n",
      "iteration: 81000 loss: 0.0015 lr: 0.02\n",
      "iteration: 81100 loss: 0.0014 lr: 0.02\n",
      "iteration: 81200 loss: 0.0015 lr: 0.02\n",
      "iteration: 81300 loss: 0.0015 lr: 0.02\n",
      "iteration: 81400 loss: 0.0014 lr: 0.02\n",
      "iteration: 81500 loss: 0.0014 lr: 0.02\n",
      "iteration: 81600 loss: 0.0016 lr: 0.02\n",
      "iteration: 81700 loss: 0.0014 lr: 0.02\n",
      "iteration: 81800 loss: 0.0017 lr: 0.02\n",
      "iteration: 81900 loss: 0.0015 lr: 0.02\n",
      "iteration: 82000 loss: 0.0014 lr: 0.02\n",
      "iteration: 82100 loss: 0.0016 lr: 0.02\n",
      "iteration: 82200 loss: 0.0014 lr: 0.02\n",
      "iteration: 82300 loss: 0.0015 lr: 0.02\n",
      "iteration: 82400 loss: 0.0014 lr: 0.02\n",
      "iteration: 82500 loss: 0.0017 lr: 0.02\n",
      "iteration: 82600 loss: 0.0016 lr: 0.02\n",
      "iteration: 82700 loss: 0.0017 lr: 0.02\n",
      "iteration: 82800 loss: 0.0017 lr: 0.02\n",
      "iteration: 82900 loss: 0.0015 lr: 0.02\n",
      "iteration: 83000 loss: 0.0014 lr: 0.02\n",
      "iteration: 83100 loss: 0.0012 lr: 0.02\n",
      "iteration: 83200 loss: 0.0015 lr: 0.02\n",
      "iteration: 83300 loss: 0.0016 lr: 0.02\n",
      "iteration: 83400 loss: 0.0016 lr: 0.02\n",
      "iteration: 83500 loss: 0.0014 lr: 0.02\n",
      "iteration: 83600 loss: 0.0015 lr: 0.02\n",
      "iteration: 83700 loss: 0.0014 lr: 0.02\n",
      "iteration: 83800 loss: 0.0015 lr: 0.02\n",
      "iteration: 83900 loss: 0.0013 lr: 0.02\n",
      "iteration: 84000 loss: 0.0015 lr: 0.02\n",
      "iteration: 84100 loss: 0.0013 lr: 0.02\n",
      "iteration: 84200 loss: 0.0014 lr: 0.02\n",
      "iteration: 84300 loss: 0.0013 lr: 0.02\n",
      "iteration: 84400 loss: 0.0013 lr: 0.02\n",
      "iteration: 84500 loss: 0.0015 lr: 0.02\n",
      "iteration: 84600 loss: 0.0014 lr: 0.02\n",
      "iteration: 84700 loss: 0.0014 lr: 0.02\n",
      "iteration: 84800 loss: 0.0015 lr: 0.02\n",
      "iteration: 84900 loss: 0.0016 lr: 0.02\n",
      "iteration: 85000 loss: 0.0015 lr: 0.02\n",
      "iteration: 85100 loss: 0.0016 lr: 0.02\n",
      "iteration: 85200 loss: 0.0015 lr: 0.02\n",
      "iteration: 85300 loss: 0.0016 lr: 0.02\n",
      "iteration: 85400 loss: 0.0014 lr: 0.02\n",
      "iteration: 85500 loss: 0.0016 lr: 0.02\n",
      "iteration: 85600 loss: 0.0018 lr: 0.02\n",
      "iteration: 85700 loss: 0.0015 lr: 0.02\n",
      "iteration: 85800 loss: 0.0015 lr: 0.02\n",
      "iteration: 85900 loss: 0.0014 lr: 0.02\n",
      "iteration: 86000 loss: 0.0018 lr: 0.02\n",
      "iteration: 86100 loss: 0.0016 lr: 0.02\n",
      "iteration: 86200 loss: 0.0014 lr: 0.02\n",
      "iteration: 86300 loss: 0.0016 lr: 0.02\n",
      "iteration: 86400 loss: 0.0016 lr: 0.02\n",
      "iteration: 86500 loss: 0.0013 lr: 0.02\n",
      "iteration: 86600 loss: 0.0012 lr: 0.02\n",
      "iteration: 86700 loss: 0.0012 lr: 0.02\n",
      "iteration: 86800 loss: 0.0013 lr: 0.02\n",
      "iteration: 86900 loss: 0.0012 lr: 0.02\n",
      "iteration: 87000 loss: 0.0014 lr: 0.02\n",
      "iteration: 87100 loss: 0.0017 lr: 0.02\n",
      "iteration: 87200 loss: 0.0015 lr: 0.02\n",
      "iteration: 87300 loss: 0.0014 lr: 0.02\n",
      "iteration: 87400 loss: 0.0013 lr: 0.02\n",
      "iteration: 87500 loss: 0.0015 lr: 0.02\n",
      "iteration: 87600 loss: 0.0013 lr: 0.02\n",
      "iteration: 87700 loss: 0.0015 lr: 0.02\n",
      "iteration: 87800 loss: 0.0014 lr: 0.02\n",
      "iteration: 87900 loss: 0.0016 lr: 0.02\n",
      "iteration: 88000 loss: 0.0013 lr: 0.02\n",
      "iteration: 88100 loss: 0.0014 lr: 0.02\n",
      "iteration: 88200 loss: 0.0017 lr: 0.02\n",
      "iteration: 88300 loss: 0.0017 lr: 0.02\n",
      "iteration: 88400 loss: 0.0019 lr: 0.02\n",
      "iteration: 88500 loss: 0.0013 lr: 0.02\n",
      "iteration: 88600 loss: 0.0017 lr: 0.02\n",
      "iteration: 88700 loss: 0.0014 lr: 0.02\n",
      "iteration: 88800 loss: 0.0013 lr: 0.02\n",
      "iteration: 88900 loss: 0.0014 lr: 0.02\n",
      "iteration: 89000 loss: 0.0015 lr: 0.02\n",
      "iteration: 89100 loss: 0.0017 lr: 0.02\n",
      "iteration: 89200 loss: 0.0014 lr: 0.02\n",
      "iteration: 89300 loss: 0.0013 lr: 0.02\n",
      "iteration: 89400 loss: 0.0013 lr: 0.02\n",
      "iteration: 89500 loss: 0.0012 lr: 0.02\n",
      "iteration: 89600 loss: 0.0013 lr: 0.02\n",
      "iteration: 89700 loss: 0.0015 lr: 0.02\n",
      "iteration: 89800 loss: 0.0013 lr: 0.02\n",
      "iteration: 89900 loss: 0.0015 lr: 0.02\n",
      "iteration: 90000 loss: 0.0016 lr: 0.02\n",
      "iteration: 90100 loss: 0.0015 lr: 0.02\n",
      "iteration: 90200 loss: 0.0014 lr: 0.02\n",
      "iteration: 90300 loss: 0.0013 lr: 0.02\n",
      "iteration: 90400 loss: 0.0013 lr: 0.02\n",
      "iteration: 90500 loss: 0.0015 lr: 0.02\n",
      "iteration: 90600 loss: 0.0014 lr: 0.02\n",
      "iteration: 90700 loss: 0.0015 lr: 0.02\n",
      "iteration: 90800 loss: 0.0013 lr: 0.02\n",
      "iteration: 90900 loss: 0.0014 lr: 0.02\n",
      "iteration: 91000 loss: 0.0013 lr: 0.02\n",
      "iteration: 91100 loss: 0.0012 lr: 0.02\n",
      "iteration: 91200 loss: 0.0014 lr: 0.02\n",
      "iteration: 91300 loss: 0.0013 lr: 0.02\n",
      "iteration: 91400 loss: 0.0013 lr: 0.02\n",
      "iteration: 91500 loss: 0.0013 lr: 0.02\n",
      "iteration: 91600 loss: 0.0011 lr: 0.02\n",
      "iteration: 91700 loss: 0.0018 lr: 0.02\n",
      "iteration: 91800 loss: 0.0015 lr: 0.02\n",
      "iteration: 91900 loss: 0.0016 lr: 0.02\n",
      "iteration: 92000 loss: 0.0016 lr: 0.02\n",
      "iteration: 92100 loss: 0.0015 lr: 0.02\n",
      "iteration: 92200 loss: 0.0014 lr: 0.02\n",
      "iteration: 92300 loss: 0.0014 lr: 0.02\n",
      "iteration: 92400 loss: 0.0015 lr: 0.02\n",
      "iteration: 92500 loss: 0.0015 lr: 0.02\n",
      "iteration: 92600 loss: 0.0014 lr: 0.02\n",
      "iteration: 92700 loss: 0.0012 lr: 0.02\n",
      "iteration: 92800 loss: 0.0014 lr: 0.02\n",
      "iteration: 92900 loss: 0.0012 lr: 0.02\n",
      "iteration: 93000 loss: 0.0014 lr: 0.02\n",
      "iteration: 93100 loss: 0.0012 lr: 0.02\n",
      "iteration: 93200 loss: 0.0012 lr: 0.02\n",
      "iteration: 93300 loss: 0.0014 lr: 0.02\n",
      "iteration: 93400 loss: 0.0016 lr: 0.02\n",
      "iteration: 93500 loss: 0.0013 lr: 0.02\n",
      "iteration: 93600 loss: 0.0016 lr: 0.02\n",
      "iteration: 93700 loss: 0.0016 lr: 0.02\n",
      "iteration: 93800 loss: 0.0015 lr: 0.02\n",
      "iteration: 93900 loss: 0.0013 lr: 0.02\n",
      "iteration: 94000 loss: 0.0013 lr: 0.02\n",
      "iteration: 94100 loss: 0.0012 lr: 0.02\n",
      "iteration: 94200 loss: 0.0014 lr: 0.02\n",
      "iteration: 94300 loss: 0.0014 lr: 0.02\n",
      "iteration: 94400 loss: 0.0016 lr: 0.02\n",
      "iteration: 94500 loss: 0.0014 lr: 0.02\n",
      "iteration: 94600 loss: 0.0013 lr: 0.02\n",
      "iteration: 94700 loss: 0.0013 lr: 0.02\n",
      "iteration: 94800 loss: 0.0013 lr: 0.02\n",
      "iteration: 94900 loss: 0.0016 lr: 0.02\n",
      "iteration: 95000 loss: 0.0014 lr: 0.02\n",
      "iteration: 95100 loss: 0.0013 lr: 0.02\n",
      "iteration: 95200 loss: 0.0014 lr: 0.02\n",
      "iteration: 95300 loss: 0.0012 lr: 0.02\n",
      "iteration: 95400 loss: 0.0013 lr: 0.02\n",
      "iteration: 95500 loss: 0.0014 lr: 0.02\n",
      "iteration: 95600 loss: 0.0013 lr: 0.02\n",
      "iteration: 95700 loss: 0.0014 lr: 0.02\n",
      "iteration: 95800 loss: 0.0013 lr: 0.02\n",
      "iteration: 95900 loss: 0.0012 lr: 0.02\n",
      "iteration: 96000 loss: 0.0013 lr: 0.02\n",
      "iteration: 96100 loss: 0.0012 lr: 0.02\n",
      "iteration: 96200 loss: 0.0013 lr: 0.02\n",
      "iteration: 96300 loss: 0.0014 lr: 0.02\n",
      "iteration: 96400 loss: 0.0016 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 96500 loss: 0.0016 lr: 0.02\n",
      "iteration: 96600 loss: 0.0013 lr: 0.02\n",
      "iteration: 96700 loss: 0.0012 lr: 0.02\n",
      "iteration: 96800 loss: 0.0013 lr: 0.02\n",
      "iteration: 96900 loss: 0.0013 lr: 0.02\n",
      "iteration: 97000 loss: 0.0012 lr: 0.02\n",
      "iteration: 97100 loss: 0.0013 lr: 0.02\n",
      "iteration: 97200 loss: 0.0012 lr: 0.02\n",
      "iteration: 97300 loss: 0.0012 lr: 0.02\n",
      "iteration: 97400 loss: 0.0012 lr: 0.02\n",
      "iteration: 97500 loss: 0.0011 lr: 0.02\n",
      "iteration: 97600 loss: 0.0014 lr: 0.02\n",
      "iteration: 97700 loss: 0.0014 lr: 0.02\n",
      "iteration: 97800 loss: 0.0013 lr: 0.02\n",
      "iteration: 97900 loss: 0.0012 lr: 0.02\n",
      "iteration: 98000 loss: 0.0015 lr: 0.02\n",
      "iteration: 98100 loss: 0.0016 lr: 0.02\n",
      "iteration: 98200 loss: 0.0013 lr: 0.02\n",
      "iteration: 98300 loss: 0.0013 lr: 0.02\n",
      "iteration: 98400 loss: 0.0014 lr: 0.02\n",
      "iteration: 98500 loss: 0.0016 lr: 0.02\n",
      "iteration: 98600 loss: 0.0015 lr: 0.02\n",
      "iteration: 98700 loss: 0.0015 lr: 0.02\n",
      "iteration: 98800 loss: 0.0013 lr: 0.02\n",
      "iteration: 98900 loss: 0.0012 lr: 0.02\n",
      "iteration: 99000 loss: 0.0016 lr: 0.02\n",
      "iteration: 99100 loss: 0.0017 lr: 0.02\n",
      "iteration: 99200 loss: 0.0013 lr: 0.02\n",
      "iteration: 99300 loss: 0.0012 lr: 0.02\n",
      "iteration: 99400 loss: 0.0014 lr: 0.02\n",
      "iteration: 99500 loss: 0.0010 lr: 0.02\n",
      "iteration: 99600 loss: 0.0012 lr: 0.02\n",
      "iteration: 99700 loss: 0.0012 lr: 0.02\n",
      "iteration: 99800 loss: 0.0014 lr: 0.02\n",
      "iteration: 99900 loss: 0.0013 lr: 0.02\n",
      "iteration: 100000 loss: 0.0012 lr: 0.02\n",
      "iteration: 100100 loss: 0.0013 lr: 0.02\n",
      "iteration: 100200 loss: 0.0013 lr: 0.02\n",
      "iteration: 100300 loss: 0.0012 lr: 0.02\n",
      "iteration: 100400 loss: 0.0011 lr: 0.02\n",
      "iteration: 100500 loss: 0.0014 lr: 0.02\n",
      "iteration: 100600 loss: 0.0014 lr: 0.02\n",
      "iteration: 100700 loss: 0.0015 lr: 0.02\n",
      "iteration: 100800 loss: 0.0015 lr: 0.02\n",
      "iteration: 100900 loss: 0.0013 lr: 0.02\n",
      "iteration: 101000 loss: 0.0012 lr: 0.02\n",
      "iteration: 101100 loss: 0.0014 lr: 0.02\n",
      "iteration: 101200 loss: 0.0011 lr: 0.02\n",
      "iteration: 101300 loss: 0.0013 lr: 0.02\n",
      "iteration: 101400 loss: 0.0015 lr: 0.02\n",
      "iteration: 101500 loss: 0.0016 lr: 0.02\n",
      "iteration: 101600 loss: 0.0014 lr: 0.02\n",
      "iteration: 101700 loss: 0.0013 lr: 0.02\n",
      "iteration: 101800 loss: 0.0012 lr: 0.02\n",
      "iteration: 101900 loss: 0.0013 lr: 0.02\n",
      "iteration: 102000 loss: 0.0014 lr: 0.02\n",
      "iteration: 102100 loss: 0.0013 lr: 0.02\n",
      "iteration: 102200 loss: 0.0015 lr: 0.02\n",
      "iteration: 102300 loss: 0.0014 lr: 0.02\n",
      "iteration: 102400 loss: 0.0014 lr: 0.02\n",
      "iteration: 102500 loss: 0.0016 lr: 0.02\n",
      "iteration: 102600 loss: 0.0012 lr: 0.02\n",
      "iteration: 102700 loss: 0.0013 lr: 0.02\n",
      "iteration: 102800 loss: 0.0015 lr: 0.02\n",
      "iteration: 102900 loss: 0.0011 lr: 0.02\n",
      "iteration: 103000 loss: 0.0011 lr: 0.02\n",
      "iteration: 103100 loss: 0.0011 lr: 0.02\n",
      "iteration: 103200 loss: 0.0013 lr: 0.02\n",
      "iteration: 103300 loss: 0.0014 lr: 0.02\n",
      "iteration: 103400 loss: 0.0014 lr: 0.02\n",
      "iteration: 103500 loss: 0.0012 lr: 0.02\n",
      "iteration: 103600 loss: 0.0011 lr: 0.02\n",
      "iteration: 103700 loss: 0.0014 lr: 0.02\n",
      "iteration: 103800 loss: 0.0014 lr: 0.02\n",
      "iteration: 103900 loss: 0.0015 lr: 0.02\n",
      "iteration: 104000 loss: 0.0012 lr: 0.02\n",
      "iteration: 104100 loss: 0.0013 lr: 0.02\n",
      "iteration: 104200 loss: 0.0015 lr: 0.02\n",
      "iteration: 104300 loss: 0.0013 lr: 0.02\n",
      "iteration: 104400 loss: 0.0013 lr: 0.02\n",
      "iteration: 104500 loss: 0.0012 lr: 0.02\n",
      "iteration: 104600 loss: 0.0014 lr: 0.02\n",
      "iteration: 104700 loss: 0.0012 lr: 0.02\n",
      "iteration: 104800 loss: 0.0012 lr: 0.02\n",
      "iteration: 104900 loss: 0.0015 lr: 0.02\n",
      "iteration: 105000 loss: 0.0013 lr: 0.02\n",
      "iteration: 105100 loss: 0.0013 lr: 0.02\n",
      "iteration: 105200 loss: 0.0011 lr: 0.02\n",
      "iteration: 105300 loss: 0.0012 lr: 0.02\n",
      "iteration: 105400 loss: 0.0013 lr: 0.02\n",
      "iteration: 105500 loss: 0.0013 lr: 0.02\n",
      "iteration: 105600 loss: 0.0014 lr: 0.02\n",
      "iteration: 105700 loss: 0.0013 lr: 0.02\n",
      "iteration: 105800 loss: 0.0012 lr: 0.02\n",
      "iteration: 105900 loss: 0.0012 lr: 0.02\n",
      "iteration: 106000 loss: 0.0012 lr: 0.02\n",
      "iteration: 106100 loss: 0.0013 lr: 0.02\n",
      "iteration: 106200 loss: 0.0012 lr: 0.02\n",
      "iteration: 106300 loss: 0.0014 lr: 0.02\n",
      "iteration: 106400 loss: 0.0011 lr: 0.02\n",
      "iteration: 106500 loss: 0.0010 lr: 0.02\n",
      "iteration: 106600 loss: 0.0013 lr: 0.02\n",
      "iteration: 106700 loss: 0.0012 lr: 0.02\n",
      "iteration: 106800 loss: 0.0015 lr: 0.02\n",
      "iteration: 106900 loss: 0.0016 lr: 0.02\n",
      "iteration: 107000 loss: 0.0013 lr: 0.02\n",
      "iteration: 107100 loss: 0.0012 lr: 0.02\n",
      "iteration: 107200 loss: 0.0013 lr: 0.02\n",
      "iteration: 107300 loss: 0.0011 lr: 0.02\n",
      "iteration: 107400 loss: 0.0012 lr: 0.02\n",
      "iteration: 107500 loss: 0.0010 lr: 0.02\n",
      "iteration: 107600 loss: 0.0013 lr: 0.02\n",
      "iteration: 107700 loss: 0.0011 lr: 0.02\n",
      "iteration: 107800 loss: 0.0012 lr: 0.02\n",
      "iteration: 107900 loss: 0.0016 lr: 0.02\n",
      "iteration: 108000 loss: 0.0012 lr: 0.02\n",
      "iteration: 108100 loss: 0.0012 lr: 0.02\n",
      "iteration: 108200 loss: 0.0012 lr: 0.02\n",
      "iteration: 108300 loss: 0.0013 lr: 0.02\n",
      "iteration: 108400 loss: 0.0014 lr: 0.02\n",
      "iteration: 108500 loss: 0.0014 lr: 0.02\n",
      "iteration: 108600 loss: 0.0012 lr: 0.02\n",
      "iteration: 108700 loss: 0.0016 lr: 0.02\n",
      "iteration: 108800 loss: 0.0012 lr: 0.02\n",
      "iteration: 108900 loss: 0.0013 lr: 0.02\n",
      "iteration: 109000 loss: 0.0012 lr: 0.02\n",
      "iteration: 109100 loss: 0.0015 lr: 0.02\n",
      "iteration: 109200 loss: 0.0012 lr: 0.02\n",
      "iteration: 109300 loss: 0.0010 lr: 0.02\n",
      "iteration: 109400 loss: 0.0011 lr: 0.02\n",
      "iteration: 109500 loss: 0.0015 lr: 0.02\n",
      "iteration: 109600 loss: 0.0016 lr: 0.02\n",
      "iteration: 109700 loss: 0.0015 lr: 0.02\n",
      "iteration: 109800 loss: 0.0012 lr: 0.02\n",
      "iteration: 109900 loss: 0.0013 lr: 0.02\n",
      "iteration: 110000 loss: 0.0012 lr: 0.02\n",
      "iteration: 110100 loss: 0.0013 lr: 0.02\n",
      "iteration: 110200 loss: 0.0014 lr: 0.02\n",
      "iteration: 110300 loss: 0.0011 lr: 0.02\n",
      "iteration: 110400 loss: 0.0013 lr: 0.02\n",
      "iteration: 110500 loss: 0.0013 lr: 0.02\n",
      "iteration: 110600 loss: 0.0012 lr: 0.02\n",
      "iteration: 110700 loss: 0.0012 lr: 0.02\n",
      "iteration: 110800 loss: 0.0013 lr: 0.02\n",
      "iteration: 110900 loss: 0.0012 lr: 0.02\n",
      "iteration: 111000 loss: 0.0012 lr: 0.02\n",
      "iteration: 111100 loss: 0.0011 lr: 0.02\n",
      "iteration: 111200 loss: 0.0011 lr: 0.02\n",
      "iteration: 111300 loss: 0.0013 lr: 0.02\n",
      "iteration: 111400 loss: 0.0012 lr: 0.02\n",
      "iteration: 111500 loss: 0.0014 lr: 0.02\n",
      "iteration: 111600 loss: 0.0012 lr: 0.02\n",
      "iteration: 111700 loss: 0.0013 lr: 0.02\n",
      "iteration: 111800 loss: 0.0013 lr: 0.02\n",
      "iteration: 111900 loss: 0.0012 lr: 0.02\n",
      "iteration: 112000 loss: 0.0013 lr: 0.02\n",
      "iteration: 112100 loss: 0.0012 lr: 0.02\n",
      "iteration: 112200 loss: 0.0012 lr: 0.02\n",
      "iteration: 112300 loss: 0.0012 lr: 0.02\n",
      "iteration: 112400 loss: 0.0011 lr: 0.02\n",
      "iteration: 112500 loss: 0.0012 lr: 0.02\n",
      "iteration: 112600 loss: 0.0011 lr: 0.02\n",
      "iteration: 112700 loss: 0.0012 lr: 0.02\n",
      "iteration: 112800 loss: 0.0012 lr: 0.02\n",
      "iteration: 112900 loss: 0.0013 lr: 0.02\n",
      "iteration: 113000 loss: 0.0013 lr: 0.02\n",
      "iteration: 113100 loss: 0.0013 lr: 0.02\n",
      "iteration: 113200 loss: 0.0011 lr: 0.02\n",
      "iteration: 113300 loss: 0.0012 lr: 0.02\n",
      "iteration: 113400 loss: 0.0011 lr: 0.02\n",
      "iteration: 113500 loss: 0.0013 lr: 0.02\n",
      "iteration: 113600 loss: 0.0011 lr: 0.02\n",
      "iteration: 113700 loss: 0.0013 lr: 0.02\n",
      "iteration: 113800 loss: 0.0011 lr: 0.02\n",
      "iteration: 113900 loss: 0.0013 lr: 0.02\n",
      "iteration: 114000 loss: 0.0011 lr: 0.02\n",
      "iteration: 114100 loss: 0.0014 lr: 0.02\n",
      "iteration: 114200 loss: 0.0012 lr: 0.02\n",
      "iteration: 114300 loss: 0.0016 lr: 0.02\n",
      "iteration: 114400 loss: 0.0014 lr: 0.02\n",
      "iteration: 114500 loss: 0.0013 lr: 0.02\n",
      "iteration: 114600 loss: 0.0013 lr: 0.02\n",
      "iteration: 114700 loss: 0.0012 lr: 0.02\n",
      "iteration: 114800 loss: 0.0011 lr: 0.02\n",
      "iteration: 114900 loss: 0.0013 lr: 0.02\n",
      "iteration: 115000 loss: 0.0011 lr: 0.02\n",
      "iteration: 115100 loss: 0.0011 lr: 0.02\n",
      "iteration: 115200 loss: 0.0015 lr: 0.02\n",
      "iteration: 115300 loss: 0.0013 lr: 0.02\n",
      "iteration: 115400 loss: 0.0015 lr: 0.02\n",
      "iteration: 115500 loss: 0.0014 lr: 0.02\n",
      "iteration: 115600 loss: 0.0016 lr: 0.02\n",
      "iteration: 115700 loss: 0.0014 lr: 0.02\n",
      "iteration: 115800 loss: 0.0013 lr: 0.02\n",
      "iteration: 115900 loss: 0.0014 lr: 0.02\n",
      "iteration: 116000 loss: 0.0014 lr: 0.02\n",
      "iteration: 116100 loss: 0.0013 lr: 0.02\n",
      "iteration: 116200 loss: 0.0013 lr: 0.02\n",
      "iteration: 116300 loss: 0.0013 lr: 0.02\n",
      "iteration: 116400 loss: 0.0013 lr: 0.02\n",
      "iteration: 116500 loss: 0.0012 lr: 0.02\n",
      "iteration: 116600 loss: 0.0012 lr: 0.02\n",
      "iteration: 116700 loss: 0.0013 lr: 0.02\n",
      "iteration: 116800 loss: 0.0014 lr: 0.02\n",
      "iteration: 116900 loss: 0.0015 lr: 0.02\n",
      "iteration: 117000 loss: 0.0014 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 117100 loss: 0.0012 lr: 0.02\n",
      "iteration: 117200 loss: 0.0013 lr: 0.02\n",
      "iteration: 117300 loss: 0.0011 lr: 0.02\n",
      "iteration: 117400 loss: 0.0012 lr: 0.02\n",
      "iteration: 117500 loss: 0.0012 lr: 0.02\n",
      "iteration: 117600 loss: 0.0014 lr: 0.02\n",
      "iteration: 117700 loss: 0.0013 lr: 0.02\n",
      "iteration: 117800 loss: 0.0015 lr: 0.02\n",
      "iteration: 117900 loss: 0.0013 lr: 0.02\n",
      "iteration: 118000 loss: 0.0013 lr: 0.02\n",
      "iteration: 118100 loss: 0.0014 lr: 0.02\n",
      "iteration: 118200 loss: 0.0014 lr: 0.02\n",
      "iteration: 118300 loss: 0.0015 lr: 0.02\n",
      "iteration: 118400 loss: 0.0013 lr: 0.02\n",
      "iteration: 118500 loss: 0.0011 lr: 0.02\n",
      "iteration: 118600 loss: 0.0013 lr: 0.02\n",
      "iteration: 118700 loss: 0.0012 lr: 0.02\n",
      "iteration: 118800 loss: 0.0013 lr: 0.02\n",
      "iteration: 118900 loss: 0.0013 lr: 0.02\n",
      "iteration: 119000 loss: 0.0013 lr: 0.02\n",
      "iteration: 119100 loss: 0.0012 lr: 0.02\n",
      "iteration: 119200 loss: 0.0011 lr: 0.02\n",
      "iteration: 119300 loss: 0.0014 lr: 0.02\n",
      "iteration: 119400 loss: 0.0014 lr: 0.02\n",
      "iteration: 119500 loss: 0.0012 lr: 0.02\n",
      "iteration: 119600 loss: 0.0013 lr: 0.02\n",
      "iteration: 119700 loss: 0.0014 lr: 0.02\n",
      "iteration: 119800 loss: 0.0015 lr: 0.02\n",
      "iteration: 119900 loss: 0.0012 lr: 0.02\n",
      "iteration: 120000 loss: 0.0011 lr: 0.02\n",
      "iteration: 120100 loss: 0.0012 lr: 0.02\n",
      "iteration: 120200 loss: 0.0011 lr: 0.02\n",
      "iteration: 120300 loss: 0.0011 lr: 0.02\n",
      "iteration: 120400 loss: 0.0010 lr: 0.02\n",
      "iteration: 120500 loss: 0.0012 lr: 0.02\n",
      "iteration: 120600 loss: 0.0012 lr: 0.02\n",
      "iteration: 120700 loss: 0.0011 lr: 0.02\n",
      "iteration: 120800 loss: 0.0010 lr: 0.02\n",
      "iteration: 120900 loss: 0.0011 lr: 0.02\n",
      "iteration: 121000 loss: 0.0012 lr: 0.02\n",
      "iteration: 121100 loss: 0.0010 lr: 0.02\n",
      "iteration: 121200 loss: 0.0013 lr: 0.02\n",
      "iteration: 121300 loss: 0.0012 lr: 0.02\n",
      "iteration: 121400 loss: 0.0014 lr: 0.02\n",
      "iteration: 121500 loss: 0.0013 lr: 0.02\n",
      "iteration: 121600 loss: 0.0013 lr: 0.02\n",
      "iteration: 121700 loss: 0.0012 lr: 0.02\n",
      "iteration: 121800 loss: 0.0011 lr: 0.02\n",
      "iteration: 121900 loss: 0.0014 lr: 0.02\n",
      "iteration: 122000 loss: 0.0010 lr: 0.02\n",
      "iteration: 122100 loss: 0.0013 lr: 0.02\n",
      "iteration: 122200 loss: 0.0011 lr: 0.02\n",
      "iteration: 122300 loss: 0.0012 lr: 0.02\n",
      "iteration: 122400 loss: 0.0013 lr: 0.02\n",
      "iteration: 122500 loss: 0.0011 lr: 0.02\n",
      "iteration: 122600 loss: 0.0011 lr: 0.02\n",
      "iteration: 122700 loss: 0.0011 lr: 0.02\n",
      "iteration: 122800 loss: 0.0011 lr: 0.02\n",
      "iteration: 122900 loss: 0.0012 lr: 0.02\n",
      "iteration: 123000 loss: 0.0011 lr: 0.02\n",
      "iteration: 123100 loss: 0.0011 lr: 0.02\n",
      "iteration: 123200 loss: 0.0011 lr: 0.02\n",
      "iteration: 123300 loss: 0.0013 lr: 0.02\n",
      "iteration: 123400 loss: 0.0012 lr: 0.02\n",
      "iteration: 123500 loss: 0.0013 lr: 0.02\n",
      "iteration: 123600 loss: 0.0011 lr: 0.02\n",
      "iteration: 123700 loss: 0.0013 lr: 0.02\n",
      "iteration: 123800 loss: 0.0011 lr: 0.02\n",
      "iteration: 123900 loss: 0.0013 lr: 0.02\n",
      "iteration: 124000 loss: 0.0014 lr: 0.02\n",
      "iteration: 124100 loss: 0.0011 lr: 0.02\n",
      "iteration: 124200 loss: 0.0012 lr: 0.02\n",
      "iteration: 124300 loss: 0.0010 lr: 0.02\n",
      "iteration: 124400 loss: 0.0009 lr: 0.02\n",
      "iteration: 124500 loss: 0.0011 lr: 0.02\n",
      "iteration: 124600 loss: 0.0011 lr: 0.02\n",
      "iteration: 124700 loss: 0.0011 lr: 0.02\n",
      "iteration: 124800 loss: 0.0014 lr: 0.02\n",
      "iteration: 124900 loss: 0.0012 lr: 0.02\n",
      "iteration: 125000 loss: 0.0012 lr: 0.02\n",
      "iteration: 125100 loss: 0.0012 lr: 0.02\n",
      "iteration: 125200 loss: 0.0012 lr: 0.02\n",
      "iteration: 125300 loss: 0.0010 lr: 0.02\n",
      "iteration: 125400 loss: 0.0011 lr: 0.02\n",
      "iteration: 125500 loss: 0.0011 lr: 0.02\n",
      "iteration: 125600 loss: 0.0010 lr: 0.02\n",
      "iteration: 125700 loss: 0.0014 lr: 0.02\n",
      "iteration: 125800 loss: 0.0013 lr: 0.02\n",
      "iteration: 125900 loss: 0.0012 lr: 0.02\n",
      "iteration: 126000 loss: 0.0011 lr: 0.02\n",
      "iteration: 126100 loss: 0.0011 lr: 0.02\n",
      "iteration: 126200 loss: 0.0012 lr: 0.02\n",
      "iteration: 126300 loss: 0.0013 lr: 0.02\n",
      "iteration: 126400 loss: 0.0014 lr: 0.02\n",
      "iteration: 126500 loss: 0.0012 lr: 0.02\n",
      "iteration: 126600 loss: 0.0014 lr: 0.02\n",
      "iteration: 126700 loss: 0.0012 lr: 0.02\n",
      "iteration: 126800 loss: 0.0011 lr: 0.02\n",
      "iteration: 126900 loss: 0.0013 lr: 0.02\n",
      "iteration: 127000 loss: 0.0011 lr: 0.02\n",
      "iteration: 127100 loss: 0.0011 lr: 0.02\n",
      "iteration: 127200 loss: 0.0011 lr: 0.02\n",
      "iteration: 127300 loss: 0.0010 lr: 0.02\n",
      "iteration: 127400 loss: 0.0010 lr: 0.02\n",
      "iteration: 127500 loss: 0.0013 lr: 0.02\n",
      "iteration: 127600 loss: 0.0012 lr: 0.02\n",
      "iteration: 127700 loss: 0.0011 lr: 0.02\n",
      "iteration: 127800 loss: 0.0011 lr: 0.02\n",
      "iteration: 127900 loss: 0.0013 lr: 0.02\n",
      "iteration: 128000 loss: 0.0012 lr: 0.02\n",
      "iteration: 128100 loss: 0.0011 lr: 0.02\n",
      "iteration: 128200 loss: 0.0011 lr: 0.02\n",
      "iteration: 128300 loss: 0.0011 lr: 0.02\n",
      "iteration: 128400 loss: 0.0010 lr: 0.02\n",
      "iteration: 128500 loss: 0.0013 lr: 0.02\n",
      "iteration: 128600 loss: 0.0012 lr: 0.02\n",
      "iteration: 128700 loss: 0.0012 lr: 0.02\n",
      "iteration: 128800 loss: 0.0012 lr: 0.02\n",
      "iteration: 128900 loss: 0.0011 lr: 0.02\n",
      "iteration: 129000 loss: 0.0012 lr: 0.02\n",
      "iteration: 129100 loss: 0.0011 lr: 0.02\n",
      "iteration: 129200 loss: 0.0011 lr: 0.02\n",
      "iteration: 129300 loss: 0.0012 lr: 0.02\n",
      "iteration: 129400 loss: 0.0011 lr: 0.02\n",
      "iteration: 129500 loss: 0.0011 lr: 0.02\n",
      "iteration: 129600 loss: 0.0014 lr: 0.02\n",
      "iteration: 129700 loss: 0.0012 lr: 0.02\n",
      "iteration: 129800 loss: 0.0010 lr: 0.02\n",
      "iteration: 129900 loss: 0.0011 lr: 0.02\n",
      "iteration: 130000 loss: 0.0013 lr: 0.02\n",
      "iteration: 130100 loss: 0.0012 lr: 0.02\n",
      "iteration: 130200 loss: 0.0010 lr: 0.02\n",
      "iteration: 130300 loss: 0.0012 lr: 0.02\n",
      "iteration: 130400 loss: 0.0012 lr: 0.02\n",
      "iteration: 130500 loss: 0.0011 lr: 0.02\n",
      "iteration: 130600 loss: 0.0012 lr: 0.02\n",
      "iteration: 130700 loss: 0.0011 lr: 0.02\n",
      "iteration: 130800 loss: 0.0010 lr: 0.02\n",
      "iteration: 130900 loss: 0.0011 lr: 0.02\n",
      "iteration: 131000 loss: 0.0012 lr: 0.02\n",
      "iteration: 131100 loss: 0.0013 lr: 0.02\n",
      "iteration: 131200 loss: 0.0012 lr: 0.02\n",
      "iteration: 131300 loss: 0.0010 lr: 0.02\n",
      "iteration: 131400 loss: 0.0011 lr: 0.02\n",
      "iteration: 131500 loss: 0.0012 lr: 0.02\n",
      "iteration: 131600 loss: 0.0013 lr: 0.02\n",
      "iteration: 131700 loss: 0.0012 lr: 0.02\n",
      "iteration: 131800 loss: 0.0015 lr: 0.02\n",
      "iteration: 131900 loss: 0.0012 lr: 0.02\n",
      "iteration: 132000 loss: 0.0011 lr: 0.02\n",
      "iteration: 132100 loss: 0.0012 lr: 0.02\n",
      "iteration: 132200 loss: 0.0011 lr: 0.02\n",
      "iteration: 132300 loss: 0.0012 lr: 0.02\n",
      "iteration: 132400 loss: 0.0014 lr: 0.02\n",
      "iteration: 132500 loss: 0.0011 lr: 0.02\n",
      "iteration: 132600 loss: 0.0012 lr: 0.02\n",
      "iteration: 132700 loss: 0.0011 lr: 0.02\n",
      "iteration: 132800 loss: 0.0012 lr: 0.02\n",
      "iteration: 132900 loss: 0.0021 lr: 0.02\n",
      "iteration: 133000 loss: 0.0015 lr: 0.02\n",
      "iteration: 133100 loss: 0.0013 lr: 0.02\n",
      "iteration: 133200 loss: 0.0012 lr: 0.02\n",
      "iteration: 133300 loss: 0.0037 lr: 0.02\n",
      "iteration: 133400 loss: 0.0013 lr: 0.02\n",
      "iteration: 133500 loss: 0.0015 lr: 0.02\n",
      "iteration: 133600 loss: 0.0013 lr: 0.02\n",
      "iteration: 133700 loss: 0.0015 lr: 0.02\n",
      "iteration: 133800 loss: 0.0015 lr: 0.02\n",
      "iteration: 133900 loss: 0.0011 lr: 0.02\n",
      "iteration: 134000 loss: 0.0009 lr: 0.02\n",
      "iteration: 134100 loss: 0.0015 lr: 0.02\n",
      "iteration: 134200 loss: 0.0011 lr: 0.02\n",
      "iteration: 134300 loss: 0.0012 lr: 0.02\n",
      "iteration: 134400 loss: 0.0012 lr: 0.02\n",
      "iteration: 134500 loss: 0.0011 lr: 0.02\n",
      "iteration: 134600 loss: 0.0010 lr: 0.02\n",
      "iteration: 134700 loss: 0.0011 lr: 0.02\n",
      "iteration: 134800 loss: 0.0012 lr: 0.02\n",
      "iteration: 134900 loss: 0.0010 lr: 0.02\n",
      "iteration: 135000 loss: 0.0010 lr: 0.02\n",
      "iteration: 135100 loss: 0.0011 lr: 0.02\n",
      "iteration: 135200 loss: 0.0011 lr: 0.02\n",
      "iteration: 135300 loss: 0.0012 lr: 0.02\n",
      "iteration: 135400 loss: 0.0011 lr: 0.02\n",
      "iteration: 135500 loss: 0.0013 lr: 0.02\n",
      "iteration: 135600 loss: 0.0012 lr: 0.02\n",
      "iteration: 135700 loss: 0.0013 lr: 0.02\n",
      "iteration: 135800 loss: 0.0011 lr: 0.02\n",
      "iteration: 135900 loss: 0.0012 lr: 0.02\n",
      "iteration: 136000 loss: 0.0010 lr: 0.02\n",
      "iteration: 136100 loss: 0.0012 lr: 0.02\n",
      "iteration: 136200 loss: 0.0013 lr: 0.02\n",
      "iteration: 136300 loss: 0.0012 lr: 0.02\n",
      "iteration: 136400 loss: 0.0012 lr: 0.02\n",
      "iteration: 136500 loss: 0.0013 lr: 0.02\n",
      "iteration: 136600 loss: 0.0011 lr: 0.02\n",
      "iteration: 136700 loss: 0.0012 lr: 0.02\n",
      "iteration: 136800 loss: 0.0011 lr: 0.02\n",
      "iteration: 136900 loss: 0.0011 lr: 0.02\n",
      "iteration: 137000 loss: 0.0012 lr: 0.02\n",
      "iteration: 137100 loss: 0.0012 lr: 0.02\n",
      "iteration: 137200 loss: 0.0011 lr: 0.02\n",
      "iteration: 137300 loss: 0.0011 lr: 0.02\n",
      "iteration: 137400 loss: 0.0011 lr: 0.02\n",
      "iteration: 137500 loss: 0.0013 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 137600 loss: 0.0013 lr: 0.02\n",
      "iteration: 137700 loss: 0.0013 lr: 0.02\n",
      "iteration: 137800 loss: 0.0012 lr: 0.02\n",
      "iteration: 137900 loss: 0.0014 lr: 0.02\n",
      "iteration: 138000 loss: 0.0013 lr: 0.02\n",
      "iteration: 138100 loss: 0.0010 lr: 0.02\n",
      "iteration: 138200 loss: 0.0011 lr: 0.02\n",
      "iteration: 138300 loss: 0.0013 lr: 0.02\n",
      "iteration: 138400 loss: 0.0012 lr: 0.02\n",
      "iteration: 138500 loss: 0.0012 lr: 0.02\n",
      "iteration: 138600 loss: 0.0011 lr: 0.02\n",
      "iteration: 138700 loss: 0.0012 lr: 0.02\n",
      "iteration: 138800 loss: 0.0011 lr: 0.02\n",
      "iteration: 138900 loss: 0.0011 lr: 0.02\n",
      "iteration: 139000 loss: 0.0012 lr: 0.02\n",
      "iteration: 139100 loss: 0.0011 lr: 0.02\n",
      "iteration: 139200 loss: 0.0010 lr: 0.02\n",
      "iteration: 139300 loss: 0.0010 lr: 0.02\n",
      "iteration: 139400 loss: 0.0012 lr: 0.02\n",
      "iteration: 139500 loss: 0.0010 lr: 0.02\n",
      "iteration: 139600 loss: 0.0010 lr: 0.02\n",
      "iteration: 139700 loss: 0.0011 lr: 0.02\n",
      "iteration: 139800 loss: 0.0012 lr: 0.02\n",
      "iteration: 139900 loss: 0.0010 lr: 0.02\n",
      "iteration: 140000 loss: 0.0010 lr: 0.02\n",
      "iteration: 140100 loss: 0.0010 lr: 0.02\n",
      "iteration: 140200 loss: 0.0010 lr: 0.02\n",
      "iteration: 140300 loss: 0.0011 lr: 0.02\n",
      "iteration: 140400 loss: 0.0013 lr: 0.02\n",
      "iteration: 140500 loss: 0.0011 lr: 0.02\n",
      "iteration: 140600 loss: 0.0011 lr: 0.02\n",
      "iteration: 140700 loss: 0.0011 lr: 0.02\n",
      "iteration: 140800 loss: 0.0011 lr: 0.02\n",
      "iteration: 140900 loss: 0.0013 lr: 0.02\n",
      "iteration: 141000 loss: 0.0011 lr: 0.02\n",
      "iteration: 141100 loss: 0.0013 lr: 0.02\n",
      "iteration: 141200 loss: 0.0011 lr: 0.02\n",
      "iteration: 141300 loss: 0.0011 lr: 0.02\n",
      "iteration: 141400 loss: 0.0014 lr: 0.02\n",
      "iteration: 141500 loss: 0.0011 lr: 0.02\n",
      "iteration: 141600 loss: 0.0011 lr: 0.02\n",
      "iteration: 141700 loss: 0.0011 lr: 0.02\n",
      "iteration: 141800 loss: 0.0011 lr: 0.02\n",
      "iteration: 141900 loss: 0.0014 lr: 0.02\n",
      "iteration: 142000 loss: 0.0012 lr: 0.02\n",
      "iteration: 142100 loss: 0.0010 lr: 0.02\n",
      "iteration: 142200 loss: 0.0010 lr: 0.02\n",
      "iteration: 142300 loss: 0.0011 lr: 0.02\n",
      "iteration: 142400 loss: 0.0011 lr: 0.02\n",
      "iteration: 142500 loss: 0.0010 lr: 0.02\n",
      "iteration: 142600 loss: 0.0012 lr: 0.02\n",
      "iteration: 142700 loss: 0.0013 lr: 0.02\n",
      "iteration: 142800 loss: 0.0010 lr: 0.02\n",
      "iteration: 142900 loss: 0.0010 lr: 0.02\n",
      "iteration: 143000 loss: 0.0010 lr: 0.02\n",
      "iteration: 143100 loss: 0.0011 lr: 0.02\n",
      "iteration: 143200 loss: 0.0010 lr: 0.02\n",
      "iteration: 143300 loss: 0.0012 lr: 0.02\n",
      "iteration: 143400 loss: 0.0010 lr: 0.02\n",
      "iteration: 143500 loss: 0.0010 lr: 0.02\n",
      "iteration: 143600 loss: 0.0012 lr: 0.02\n",
      "iteration: 143700 loss: 0.0014 lr: 0.02\n",
      "iteration: 143800 loss: 0.0013 lr: 0.02\n",
      "iteration: 143900 loss: 0.0013 lr: 0.02\n",
      "iteration: 144000 loss: 0.0013 lr: 0.02\n",
      "iteration: 144100 loss: 0.0010 lr: 0.02\n",
      "iteration: 144200 loss: 0.0011 lr: 0.02\n",
      "iteration: 144300 loss: 0.0011 lr: 0.02\n",
      "iteration: 144400 loss: 0.0011 lr: 0.02\n",
      "iteration: 144500 loss: 0.0010 lr: 0.02\n",
      "iteration: 144600 loss: 0.0011 lr: 0.02\n",
      "iteration: 144700 loss: 0.0009 lr: 0.02\n",
      "iteration: 144800 loss: 0.0011 lr: 0.02\n",
      "iteration: 144900 loss: 0.0012 lr: 0.02\n",
      "iteration: 145000 loss: 0.0009 lr: 0.02\n",
      "iteration: 145100 loss: 0.0011 lr: 0.02\n",
      "iteration: 145200 loss: 0.0014 lr: 0.02\n",
      "iteration: 145300 loss: 0.0010 lr: 0.02\n",
      "iteration: 145400 loss: 0.0012 lr: 0.02\n",
      "iteration: 145500 loss: 0.0011 lr: 0.02\n",
      "iteration: 145600 loss: 0.0010 lr: 0.02\n",
      "iteration: 145700 loss: 0.0011 lr: 0.02\n",
      "iteration: 145800 loss: 0.0011 lr: 0.02\n",
      "iteration: 145900 loss: 0.0011 lr: 0.02\n",
      "iteration: 146000 loss: 0.0011 lr: 0.02\n",
      "iteration: 146100 loss: 0.0013 lr: 0.02\n",
      "iteration: 146200 loss: 0.0010 lr: 0.02\n",
      "iteration: 146300 loss: 0.0011 lr: 0.02\n",
      "iteration: 146400 loss: 0.0012 lr: 0.02\n",
      "iteration: 146500 loss: 0.0010 lr: 0.02\n",
      "iteration: 146600 loss: 0.0011 lr: 0.02\n",
      "iteration: 146700 loss: 0.0010 lr: 0.02\n",
      "iteration: 146800 loss: 0.0012 lr: 0.02\n",
      "iteration: 146900 loss: 0.0011 lr: 0.02\n",
      "iteration: 147000 loss: 0.0011 lr: 0.02\n",
      "iteration: 147100 loss: 0.0011 lr: 0.02\n",
      "iteration: 147200 loss: 0.0011 lr: 0.02\n",
      "iteration: 147300 loss: 0.0010 lr: 0.02\n",
      "iteration: 147400 loss: 0.0009 lr: 0.02\n",
      "iteration: 147500 loss: 0.0012 lr: 0.02\n",
      "iteration: 147600 loss: 0.0010 lr: 0.02\n",
      "iteration: 147700 loss: 0.0010 lr: 0.02\n",
      "iteration: 147800 loss: 0.0014 lr: 0.02\n",
      "iteration: 147900 loss: 0.0010 lr: 0.02\n",
      "iteration: 148000 loss: 0.0012 lr: 0.02\n",
      "iteration: 148100 loss: 0.0012 lr: 0.02\n",
      "iteration: 148200 loss: 0.0011 lr: 0.02\n",
      "iteration: 148300 loss: 0.0012 lr: 0.02\n",
      "iteration: 148400 loss: 0.0010 lr: 0.02\n",
      "iteration: 148500 loss: 0.0011 lr: 0.02\n",
      "iteration: 148600 loss: 0.0011 lr: 0.02\n",
      "iteration: 148700 loss: 0.0010 lr: 0.02\n",
      "iteration: 148800 loss: 0.0012 lr: 0.02\n",
      "iteration: 148900 loss: 0.0012 lr: 0.02\n",
      "iteration: 149000 loss: 0.0011 lr: 0.02\n",
      "iteration: 149100 loss: 0.0011 lr: 0.02\n",
      "iteration: 149200 loss: 0.0010 lr: 0.02\n",
      "iteration: 149300 loss: 0.0012 lr: 0.02\n",
      "iteration: 149400 loss: 0.0012 lr: 0.02\n",
      "iteration: 149500 loss: 0.0014 lr: 0.02\n",
      "iteration: 149600 loss: 0.0011 lr: 0.02\n",
      "iteration: 149700 loss: 0.0011 lr: 0.02\n",
      "iteration: 149800 loss: 0.0011 lr: 0.02\n",
      "iteration: 149900 loss: 0.0010 lr: 0.02\n",
      "iteration: 150000 loss: 0.0012 lr: 0.02\n",
      "iteration: 150100 loss: 0.0012 lr: 0.02\n",
      "iteration: 150200 loss: 0.0009 lr: 0.02\n",
      "iteration: 150300 loss: 0.0012 lr: 0.02\n",
      "iteration: 150400 loss: 0.0010 lr: 0.02\n",
      "iteration: 150500 loss: 0.0011 lr: 0.02\n",
      "iteration: 150600 loss: 0.0012 lr: 0.02\n",
      "iteration: 150700 loss: 0.0010 lr: 0.02\n",
      "iteration: 150800 loss: 0.0012 lr: 0.02\n",
      "iteration: 150900 loss: 0.0011 lr: 0.02\n",
      "iteration: 151000 loss: 0.0011 lr: 0.02\n",
      "iteration: 151100 loss: 0.0011 lr: 0.02\n",
      "iteration: 151200 loss: 0.0011 lr: 0.02\n",
      "iteration: 151300 loss: 0.0011 lr: 0.02\n",
      "iteration: 151400 loss: 0.0011 lr: 0.02\n",
      "iteration: 151500 loss: 0.0012 lr: 0.02\n",
      "iteration: 151600 loss: 0.0010 lr: 0.02\n",
      "iteration: 151700 loss: 0.0012 lr: 0.02\n",
      "iteration: 151800 loss: 0.0011 lr: 0.02\n",
      "iteration: 151900 loss: 0.0010 lr: 0.02\n",
      "iteration: 152000 loss: 0.0011 lr: 0.02\n",
      "iteration: 152100 loss: 0.0011 lr: 0.02\n",
      "iteration: 152200 loss: 0.0012 lr: 0.02\n",
      "iteration: 152300 loss: 0.0011 lr: 0.02\n",
      "iteration: 152400 loss: 0.0011 lr: 0.02\n",
      "iteration: 152500 loss: 0.0008 lr: 0.02\n",
      "iteration: 152600 loss: 0.0010 lr: 0.02\n",
      "iteration: 152700 loss: 0.0011 lr: 0.02\n",
      "iteration: 152800 loss: 0.0010 lr: 0.02\n",
      "iteration: 152900 loss: 0.0012 lr: 0.02\n",
      "iteration: 153000 loss: 0.0011 lr: 0.02\n",
      "iteration: 153100 loss: 0.0009 lr: 0.02\n",
      "iteration: 153200 loss: 0.0012 lr: 0.02\n",
      "iteration: 153300 loss: 0.0010 lr: 0.02\n",
      "iteration: 153400 loss: 0.0012 lr: 0.02\n",
      "iteration: 153500 loss: 0.0011 lr: 0.02\n",
      "iteration: 153600 loss: 0.0011 lr: 0.02\n",
      "iteration: 153700 loss: 0.0011 lr: 0.02\n",
      "iteration: 153800 loss: 0.0012 lr: 0.02\n",
      "iteration: 153900 loss: 0.0012 lr: 0.02\n",
      "iteration: 154000 loss: 0.0011 lr: 0.02\n",
      "iteration: 154100 loss: 0.0009 lr: 0.02\n",
      "iteration: 154200 loss: 0.0012 lr: 0.02\n",
      "iteration: 154300 loss: 0.0012 lr: 0.02\n",
      "iteration: 154400 loss: 0.0010 lr: 0.02\n",
      "iteration: 154500 loss: 0.0011 lr: 0.02\n",
      "iteration: 154600 loss: 0.0010 lr: 0.02\n",
      "iteration: 154700 loss: 0.0010 lr: 0.02\n",
      "iteration: 154800 loss: 0.0012 lr: 0.02\n",
      "iteration: 154900 loss: 0.0012 lr: 0.02\n",
      "iteration: 155000 loss: 0.0012 lr: 0.02\n",
      "iteration: 155100 loss: 0.0011 lr: 0.02\n",
      "iteration: 155200 loss: 0.0010 lr: 0.02\n",
      "iteration: 155300 loss: 0.0010 lr: 0.02\n",
      "iteration: 155400 loss: 0.0011 lr: 0.02\n",
      "iteration: 155500 loss: 0.0011 lr: 0.02\n",
      "iteration: 155600 loss: 0.0011 lr: 0.02\n",
      "iteration: 155700 loss: 0.0010 lr: 0.02\n",
      "iteration: 155800 loss: 0.0012 lr: 0.02\n",
      "iteration: 155900 loss: 0.0010 lr: 0.02\n",
      "iteration: 156000 loss: 0.0010 lr: 0.02\n",
      "iteration: 156100 loss: 0.0011 lr: 0.02\n",
      "iteration: 156200 loss: 0.0010 lr: 0.02\n",
      "iteration: 156300 loss: 0.0014 lr: 0.02\n",
      "iteration: 156400 loss: 0.0011 lr: 0.02\n",
      "iteration: 156500 loss: 0.0012 lr: 0.02\n",
      "iteration: 156600 loss: 0.0011 lr: 0.02\n",
      "iteration: 156700 loss: 0.0010 lr: 0.02\n",
      "iteration: 156800 loss: 0.0012 lr: 0.02\n",
      "iteration: 156900 loss: 0.0011 lr: 0.02\n",
      "iteration: 157000 loss: 0.0012 lr: 0.02\n",
      "iteration: 157100 loss: 0.0013 lr: 0.02\n",
      "iteration: 157200 loss: 0.0012 lr: 0.02\n",
      "iteration: 157300 loss: 0.0010 lr: 0.02\n",
      "iteration: 157400 loss: 0.0010 lr: 0.02\n",
      "iteration: 157500 loss: 0.0010 lr: 0.02\n",
      "iteration: 157600 loss: 0.0011 lr: 0.02\n",
      "iteration: 157700 loss: 0.0010 lr: 0.02\n",
      "iteration: 157800 loss: 0.0010 lr: 0.02\n",
      "iteration: 157900 loss: 0.0010 lr: 0.02\n",
      "iteration: 158000 loss: 0.0009 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 158100 loss: 0.0009 lr: 0.02\n",
      "iteration: 158200 loss: 0.0011 lr: 0.02\n",
      "iteration: 158300 loss: 0.0009 lr: 0.02\n",
      "iteration: 158400 loss: 0.0013 lr: 0.02\n",
      "iteration: 158500 loss: 0.0012 lr: 0.02\n",
      "iteration: 158600 loss: 0.0010 lr: 0.02\n",
      "iteration: 158700 loss: 0.0014 lr: 0.02\n",
      "iteration: 158800 loss: 0.0012 lr: 0.02\n",
      "iteration: 158900 loss: 0.0012 lr: 0.02\n",
      "iteration: 159000 loss: 0.0014 lr: 0.02\n",
      "iteration: 159100 loss: 0.0012 lr: 0.02\n",
      "iteration: 159200 loss: 0.0013 lr: 0.02\n",
      "iteration: 159300 loss: 0.0010 lr: 0.02\n",
      "iteration: 159400 loss: 0.0012 lr: 0.02\n",
      "iteration: 159500 loss: 0.0010 lr: 0.02\n",
      "iteration: 159600 loss: 0.0009 lr: 0.02\n",
      "iteration: 159700 loss: 0.0010 lr: 0.02\n",
      "iteration: 159800 loss: 0.0010 lr: 0.02\n",
      "iteration: 159900 loss: 0.0010 lr: 0.02\n",
      "iteration: 160000 loss: 0.0010 lr: 0.02\n",
      "iteration: 160100 loss: 0.0011 lr: 0.02\n",
      "iteration: 160200 loss: 0.0012 lr: 0.02\n",
      "iteration: 160300 loss: 0.0011 lr: 0.02\n",
      "iteration: 160400 loss: 0.0012 lr: 0.02\n",
      "iteration: 160500 loss: 0.0012 lr: 0.02\n",
      "iteration: 160600 loss: 0.0011 lr: 0.02\n",
      "iteration: 160700 loss: 0.0011 lr: 0.02\n",
      "iteration: 160800 loss: 0.0010 lr: 0.02\n",
      "iteration: 160900 loss: 0.0011 lr: 0.02\n",
      "iteration: 161000 loss: 0.0011 lr: 0.02\n",
      "iteration: 161100 loss: 0.0012 lr: 0.02\n",
      "iteration: 161200 loss: 0.0013 lr: 0.02\n",
      "iteration: 161300 loss: 0.0010 lr: 0.02\n",
      "iteration: 161400 loss: 0.0010 lr: 0.02\n",
      "iteration: 161500 loss: 0.0009 lr: 0.02\n",
      "iteration: 161600 loss: 0.0011 lr: 0.02\n",
      "iteration: 161700 loss: 0.0011 lr: 0.02\n",
      "iteration: 161800 loss: 0.0010 lr: 0.02\n",
      "iteration: 161900 loss: 0.0012 lr: 0.02\n",
      "iteration: 162000 loss: 0.0010 lr: 0.02\n",
      "iteration: 162100 loss: 0.0011 lr: 0.02\n",
      "iteration: 162200 loss: 0.0011 lr: 0.02\n",
      "iteration: 162300 loss: 0.0012 lr: 0.02\n",
      "iteration: 162400 loss: 0.0011 lr: 0.02\n",
      "iteration: 162500 loss: 0.0010 lr: 0.02\n",
      "iteration: 162600 loss: 0.0012 lr: 0.02\n",
      "iteration: 162700 loss: 0.0009 lr: 0.02\n",
      "iteration: 162800 loss: 0.0011 lr: 0.02\n",
      "iteration: 162900 loss: 0.0010 lr: 0.02\n",
      "iteration: 163000 loss: 0.0009 lr: 0.02\n",
      "iteration: 163100 loss: 0.0010 lr: 0.02\n",
      "iteration: 163200 loss: 0.0012 lr: 0.02\n",
      "iteration: 163300 loss: 0.0011 lr: 0.02\n",
      "iteration: 163400 loss: 0.0010 lr: 0.02\n",
      "iteration: 163500 loss: 0.0011 lr: 0.02\n",
      "iteration: 163600 loss: 0.0011 lr: 0.02\n",
      "iteration: 163700 loss: 0.0010 lr: 0.02\n",
      "iteration: 163800 loss: 0.0010 lr: 0.02\n",
      "iteration: 163900 loss: 0.0009 lr: 0.02\n",
      "iteration: 164000 loss: 0.0014 lr: 0.02\n",
      "iteration: 164100 loss: 0.0011 lr: 0.02\n",
      "iteration: 164200 loss: 0.0011 lr: 0.02\n",
      "iteration: 164300 loss: 0.0010 lr: 0.02\n",
      "iteration: 164400 loss: 0.0012 lr: 0.02\n",
      "iteration: 164500 loss: 0.0012 lr: 0.02\n",
      "iteration: 164600 loss: 0.0011 lr: 0.02\n",
      "iteration: 164700 loss: 0.0013 lr: 0.02\n",
      "iteration: 164800 loss: 0.0012 lr: 0.02\n",
      "iteration: 164900 loss: 0.0011 lr: 0.02\n",
      "iteration: 165000 loss: 0.0010 lr: 0.02\n",
      "iteration: 165100 loss: 0.0009 lr: 0.02\n",
      "iteration: 165200 loss: 0.0008 lr: 0.02\n",
      "iteration: 165300 loss: 0.0011 lr: 0.02\n",
      "iteration: 165400 loss: 0.0009 lr: 0.02\n",
      "iteration: 165500 loss: 0.0009 lr: 0.02\n",
      "iteration: 165600 loss: 0.0009 lr: 0.02\n",
      "iteration: 165700 loss: 0.0010 lr: 0.02\n",
      "iteration: 165800 loss: 0.0009 lr: 0.02\n",
      "iteration: 165900 loss: 0.0010 lr: 0.02\n",
      "iteration: 166000 loss: 0.0010 lr: 0.02\n",
      "iteration: 166100 loss: 0.0011 lr: 0.02\n",
      "iteration: 166200 loss: 0.0009 lr: 0.02\n",
      "iteration: 166300 loss: 0.0010 lr: 0.02\n",
      "iteration: 166400 loss: 0.0011 lr: 0.02\n",
      "iteration: 166500 loss: 0.0010 lr: 0.02\n",
      "iteration: 166600 loss: 0.0010 lr: 0.02\n",
      "iteration: 166700 loss: 0.0009 lr: 0.02\n",
      "iteration: 166800 loss: 0.0010 lr: 0.02\n",
      "iteration: 166900 loss: 0.0010 lr: 0.02\n",
      "iteration: 167000 loss: 0.0009 lr: 0.02\n",
      "iteration: 167100 loss: 0.0011 lr: 0.02\n",
      "iteration: 167200 loss: 0.0010 lr: 0.02\n",
      "iteration: 167300 loss: 0.0010 lr: 0.02\n",
      "iteration: 167400 loss: 0.0010 lr: 0.02\n",
      "iteration: 167500 loss: 0.0010 lr: 0.02\n",
      "iteration: 167600 loss: 0.0010 lr: 0.02\n",
      "iteration: 167700 loss: 0.0010 lr: 0.02\n",
      "iteration: 167800 loss: 0.0010 lr: 0.02\n",
      "iteration: 167900 loss: 0.0011 lr: 0.02\n",
      "iteration: 168000 loss: 0.0012 lr: 0.02\n",
      "iteration: 168100 loss: 0.0012 lr: 0.02\n",
      "iteration: 168200 loss: 0.0010 lr: 0.02\n",
      "iteration: 168300 loss: 0.0010 lr: 0.02\n",
      "iteration: 168400 loss: 0.0009 lr: 0.02\n",
      "iteration: 168500 loss: 0.0009 lr: 0.02\n",
      "iteration: 168600 loss: 0.0010 lr: 0.02\n",
      "iteration: 168700 loss: 0.0010 lr: 0.02\n",
      "iteration: 168800 loss: 0.0010 lr: 0.02\n",
      "iteration: 168900 loss: 0.0009 lr: 0.02\n",
      "iteration: 169000 loss: 0.0009 lr: 0.02\n",
      "iteration: 169100 loss: 0.0009 lr: 0.02\n",
      "iteration: 169200 loss: 0.0010 lr: 0.02\n",
      "iteration: 169300 loss: 0.0009 lr: 0.02\n",
      "iteration: 169400 loss: 0.0013 lr: 0.02\n",
      "iteration: 169500 loss: 0.0010 lr: 0.02\n",
      "iteration: 169600 loss: 0.0011 lr: 0.02\n",
      "iteration: 169700 loss: 0.0012 lr: 0.02\n",
      "iteration: 169800 loss: 0.0011 lr: 0.02\n",
      "iteration: 169900 loss: 0.0010 lr: 0.02\n",
      "iteration: 170000 loss: 0.0010 lr: 0.02\n",
      "iteration: 170100 loss: 0.0010 lr: 0.02\n",
      "iteration: 170200 loss: 0.0009 lr: 0.02\n",
      "iteration: 170300 loss: 0.0009 lr: 0.02\n",
      "iteration: 170400 loss: 0.0012 lr: 0.02\n",
      "iteration: 170500 loss: 0.0012 lr: 0.02\n",
      "iteration: 170600 loss: 0.0011 lr: 0.02\n",
      "iteration: 170700 loss: 0.0010 lr: 0.02\n",
      "iteration: 170800 loss: 0.0010 lr: 0.02\n",
      "iteration: 170900 loss: 0.0011 lr: 0.02\n",
      "iteration: 171000 loss: 0.0010 lr: 0.02\n",
      "iteration: 171100 loss: 0.0010 lr: 0.02\n",
      "iteration: 171200 loss: 0.0009 lr: 0.02\n",
      "iteration: 171300 loss: 0.0010 lr: 0.02\n",
      "iteration: 171400 loss: 0.0010 lr: 0.02\n",
      "iteration: 171500 loss: 0.0010 lr: 0.02\n",
      "iteration: 171600 loss: 0.0011 lr: 0.02\n",
      "iteration: 171700 loss: 0.0011 lr: 0.02\n",
      "iteration: 171800 loss: 0.0009 lr: 0.02\n",
      "iteration: 171900 loss: 0.0010 lr: 0.02\n",
      "iteration: 172000 loss: 0.0011 lr: 0.02\n",
      "iteration: 172100 loss: 0.0009 lr: 0.02\n",
      "iteration: 172200 loss: 0.0010 lr: 0.02\n",
      "iteration: 172300 loss: 0.0010 lr: 0.02\n",
      "iteration: 172400 loss: 0.0010 lr: 0.02\n",
      "iteration: 172500 loss: 0.0010 lr: 0.02\n",
      "iteration: 172600 loss: 0.0010 lr: 0.02\n",
      "iteration: 172700 loss: 0.0010 lr: 0.02\n",
      "iteration: 172800 loss: 0.0011 lr: 0.02\n",
      "iteration: 172900 loss: 0.0010 lr: 0.02\n",
      "iteration: 173000 loss: 0.0010 lr: 0.02\n",
      "iteration: 173100 loss: 0.0009 lr: 0.02\n",
      "iteration: 173200 loss: 0.0011 lr: 0.02\n",
      "iteration: 173300 loss: 0.0011 lr: 0.02\n",
      "iteration: 173400 loss: 0.0011 lr: 0.02\n",
      "iteration: 173500 loss: 0.0011 lr: 0.02\n",
      "iteration: 173600 loss: 0.0011 lr: 0.02\n",
      "iteration: 173700 loss: 0.0012 lr: 0.02\n",
      "iteration: 173800 loss: 0.0009 lr: 0.02\n",
      "iteration: 173900 loss: 0.0009 lr: 0.02\n",
      "iteration: 174000 loss: 0.0009 lr: 0.02\n",
      "iteration: 174100 loss: 0.0010 lr: 0.02\n",
      "iteration: 174200 loss: 0.0011 lr: 0.02\n",
      "iteration: 174300 loss: 0.0012 lr: 0.02\n",
      "iteration: 174400 loss: 0.0011 lr: 0.02\n",
      "iteration: 174500 loss: 0.0010 lr: 0.02\n",
      "iteration: 174600 loss: 0.0009 lr: 0.02\n",
      "iteration: 174700 loss: 0.0009 lr: 0.02\n",
      "iteration: 174800 loss: 0.0011 lr: 0.02\n",
      "iteration: 174900 loss: 0.0011 lr: 0.02\n",
      "iteration: 175000 loss: 0.0011 lr: 0.02\n",
      "iteration: 175100 loss: 0.0009 lr: 0.02\n",
      "iteration: 175200 loss: 0.0011 lr: 0.02\n",
      "iteration: 175300 loss: 0.0011 lr: 0.02\n",
      "iteration: 175400 loss: 0.0010 lr: 0.02\n",
      "iteration: 175500 loss: 0.0011 lr: 0.02\n",
      "iteration: 175600 loss: 0.0011 lr: 0.02\n",
      "iteration: 175700 loss: 0.0010 lr: 0.02\n",
      "iteration: 175800 loss: 0.0011 lr: 0.02\n",
      "iteration: 175900 loss: 0.0011 lr: 0.02\n",
      "iteration: 176000 loss: 0.0010 lr: 0.02\n",
      "iteration: 176100 loss: 0.0010 lr: 0.02\n",
      "iteration: 176200 loss: 0.0011 lr: 0.02\n",
      "iteration: 176300 loss: 0.0012 lr: 0.02\n",
      "iteration: 176400 loss: 0.0011 lr: 0.02\n",
      "iteration: 176500 loss: 0.0010 lr: 0.02\n",
      "iteration: 176600 loss: 0.0011 lr: 0.02\n",
      "iteration: 176700 loss: 0.0010 lr: 0.02\n",
      "iteration: 176800 loss: 0.0012 lr: 0.02\n",
      "iteration: 176900 loss: 0.0010 lr: 0.02\n",
      "iteration: 177000 loss: 0.0009 lr: 0.02\n",
      "iteration: 177100 loss: 0.0011 lr: 0.02\n",
      "iteration: 177200 loss: 0.0009 lr: 0.02\n",
      "iteration: 177300 loss: 0.0009 lr: 0.02\n",
      "iteration: 177400 loss: 0.0011 lr: 0.02\n",
      "iteration: 177500 loss: 0.0011 lr: 0.02\n",
      "iteration: 177600 loss: 0.0010 lr: 0.02\n",
      "iteration: 177700 loss: 0.0012 lr: 0.02\n",
      "iteration: 177800 loss: 0.0009 lr: 0.02\n",
      "iteration: 177900 loss: 0.0010 lr: 0.02\n",
      "iteration: 178000 loss: 0.0010 lr: 0.02\n",
      "iteration: 178100 loss: 0.0010 lr: 0.02\n",
      "iteration: 178200 loss: 0.0009 lr: 0.02\n",
      "iteration: 178300 loss: 0.0012 lr: 0.02\n",
      "iteration: 178400 loss: 0.0011 lr: 0.02\n",
      "iteration: 178500 loss: 0.0009 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 178600 loss: 0.0011 lr: 0.02\n",
      "iteration: 178700 loss: 0.0012 lr: 0.02\n",
      "iteration: 178800 loss: 0.0011 lr: 0.02\n",
      "iteration: 178900 loss: 0.0011 lr: 0.02\n",
      "iteration: 179000 loss: 0.0010 lr: 0.02\n",
      "iteration: 179100 loss: 0.0009 lr: 0.02\n",
      "iteration: 179200 loss: 0.0011 lr: 0.02\n",
      "iteration: 179300 loss: 0.0011 lr: 0.02\n",
      "iteration: 179400 loss: 0.0010 lr: 0.02\n",
      "iteration: 179500 loss: 0.0011 lr: 0.02\n",
      "iteration: 179600 loss: 0.0010 lr: 0.02\n",
      "iteration: 179700 loss: 0.0012 lr: 0.02\n",
      "iteration: 179800 loss: 0.0010 lr: 0.02\n",
      "iteration: 179900 loss: 0.0009 lr: 0.02\n",
      "iteration: 180000 loss: 0.0010 lr: 0.02\n",
      "iteration: 180100 loss: 0.0010 lr: 0.02\n",
      "iteration: 180200 loss: 0.0011 lr: 0.02\n",
      "iteration: 180300 loss: 0.0011 lr: 0.02\n",
      "iteration: 180400 loss: 0.0009 lr: 0.02\n",
      "iteration: 180500 loss: 0.0010 lr: 0.02\n",
      "iteration: 180600 loss: 0.0010 lr: 0.02\n",
      "iteration: 180700 loss: 0.0010 lr: 0.02\n",
      "iteration: 180800 loss: 0.0010 lr: 0.02\n",
      "iteration: 180900 loss: 0.0009 lr: 0.02\n",
      "iteration: 181000 loss: 0.0008 lr: 0.02\n",
      "iteration: 181100 loss: 0.0010 lr: 0.02\n",
      "iteration: 181200 loss: 0.0012 lr: 0.02\n",
      "iteration: 181300 loss: 0.0010 lr: 0.02\n",
      "iteration: 181400 loss: 0.0011 lr: 0.02\n",
      "iteration: 181500 loss: 0.0009 lr: 0.02\n",
      "iteration: 181600 loss: 0.0011 lr: 0.02\n",
      "iteration: 181700 loss: 0.0012 lr: 0.02\n",
      "iteration: 181800 loss: 0.0011 lr: 0.02\n",
      "iteration: 181900 loss: 0.0011 lr: 0.02\n",
      "iteration: 182000 loss: 0.0010 lr: 0.02\n",
      "iteration: 182100 loss: 0.0010 lr: 0.02\n",
      "iteration: 182200 loss: 0.0010 lr: 0.02\n",
      "iteration: 182300 loss: 0.0010 lr: 0.02\n",
      "iteration: 182400 loss: 0.0011 lr: 0.02\n",
      "iteration: 182500 loss: 0.0011 lr: 0.02\n",
      "iteration: 182600 loss: 0.0010 lr: 0.02\n",
      "iteration: 182700 loss: 0.0011 lr: 0.02\n",
      "iteration: 182800 loss: 0.0010 lr: 0.02\n",
      "iteration: 182900 loss: 0.0010 lr: 0.02\n",
      "iteration: 183000 loss: 0.0010 lr: 0.02\n",
      "iteration: 183100 loss: 0.0010 lr: 0.02\n",
      "iteration: 183200 loss: 0.0009 lr: 0.02\n",
      "iteration: 183300 loss: 0.0010 lr: 0.02\n",
      "iteration: 183400 loss: 0.0012 lr: 0.02\n",
      "iteration: 183500 loss: 0.0012 lr: 0.02\n",
      "iteration: 183600 loss: 0.0010 lr: 0.02\n",
      "iteration: 183700 loss: 0.0012 lr: 0.02\n",
      "iteration: 183800 loss: 0.0011 lr: 0.02\n",
      "iteration: 183900 loss: 0.0011 lr: 0.02\n",
      "iteration: 184000 loss: 0.0010 lr: 0.02\n",
      "iteration: 184100 loss: 0.0011 lr: 0.02\n",
      "iteration: 184200 loss: 0.0008 lr: 0.02\n",
      "iteration: 184300 loss: 0.0011 lr: 0.02\n",
      "iteration: 184400 loss: 0.0011 lr: 0.02\n",
      "iteration: 184500 loss: 0.0009 lr: 0.02\n",
      "iteration: 184600 loss: 0.0010 lr: 0.02\n",
      "iteration: 184700 loss: 0.0011 lr: 0.02\n",
      "iteration: 184800 loss: 0.0009 lr: 0.02\n",
      "iteration: 184900 loss: 0.0009 lr: 0.02\n",
      "iteration: 185000 loss: 0.0009 lr: 0.02\n",
      "iteration: 185100 loss: 0.0010 lr: 0.02\n",
      "iteration: 185200 loss: 0.0010 lr: 0.02\n",
      "iteration: 185300 loss: 0.0011 lr: 0.02\n",
      "iteration: 185400 loss: 0.0008 lr: 0.02\n",
      "iteration: 185500 loss: 0.0010 lr: 0.02\n",
      "iteration: 185600 loss: 0.0009 lr: 0.02\n",
      "iteration: 185700 loss: 0.0010 lr: 0.02\n",
      "iteration: 185800 loss: 0.0009 lr: 0.02\n",
      "iteration: 185900 loss: 0.0015 lr: 0.02\n",
      "iteration: 186000 loss: 0.0011 lr: 0.02\n",
      "iteration: 186100 loss: 0.0013 lr: 0.02\n",
      "iteration: 186200 loss: 0.0012 lr: 0.02\n",
      "iteration: 186300 loss: 0.0013 lr: 0.02\n",
      "iteration: 186400 loss: 0.0013 lr: 0.02\n",
      "iteration: 186500 loss: 0.0014 lr: 0.02\n",
      "iteration: 186600 loss: 0.0010 lr: 0.02\n",
      "iteration: 186700 loss: 0.0010 lr: 0.02\n",
      "iteration: 186800 loss: 0.0012 lr: 0.02\n",
      "iteration: 186900 loss: 0.0009 lr: 0.02\n",
      "iteration: 187000 loss: 0.0010 lr: 0.02\n",
      "iteration: 187100 loss: 0.0009 lr: 0.02\n",
      "iteration: 187200 loss: 0.0010 lr: 0.02\n",
      "iteration: 187300 loss: 0.0011 lr: 0.02\n",
      "iteration: 187400 loss: 0.0009 lr: 0.02\n",
      "iteration: 187500 loss: 0.0010 lr: 0.02\n",
      "iteration: 187600 loss: 0.0010 lr: 0.02\n",
      "iteration: 187700 loss: 0.0009 lr: 0.02\n",
      "iteration: 187800 loss: 0.0010 lr: 0.02\n",
      "iteration: 187900 loss: 0.0012 lr: 0.02\n",
      "iteration: 188000 loss: 0.0012 lr: 0.02\n",
      "iteration: 188100 loss: 0.0009 lr: 0.02\n",
      "iteration: 188200 loss: 0.0010 lr: 0.02\n",
      "iteration: 188300 loss: 0.0011 lr: 0.02\n",
      "iteration: 188400 loss: 0.0010 lr: 0.02\n",
      "iteration: 188500 loss: 0.0010 lr: 0.02\n",
      "iteration: 188600 loss: 0.0010 lr: 0.02\n",
      "iteration: 188700 loss: 0.0010 lr: 0.02\n",
      "iteration: 188800 loss: 0.0010 lr: 0.02\n",
      "iteration: 188900 loss: 0.0010 lr: 0.02\n",
      "iteration: 189000 loss: 0.0011 lr: 0.02\n",
      "iteration: 189100 loss: 0.0010 lr: 0.02\n",
      "iteration: 189200 loss: 0.0010 lr: 0.02\n",
      "iteration: 189300 loss: 0.0010 lr: 0.02\n",
      "iteration: 189400 loss: 0.0010 lr: 0.02\n",
      "iteration: 189500 loss: 0.0009 lr: 0.02\n",
      "iteration: 189600 loss: 0.0010 lr: 0.02\n",
      "iteration: 189700 loss: 0.0010 lr: 0.02\n",
      "iteration: 189800 loss: 0.0009 lr: 0.02\n",
      "iteration: 189900 loss: 0.0009 lr: 0.02\n",
      "iteration: 190000 loss: 0.0010 lr: 0.02\n",
      "iteration: 190100 loss: 0.0010 lr: 0.02\n",
      "iteration: 190200 loss: 0.0010 lr: 0.02\n",
      "iteration: 190300 loss: 0.0009 lr: 0.02\n",
      "iteration: 190400 loss: 0.0010 lr: 0.02\n",
      "iteration: 190500 loss: 0.0010 lr: 0.02\n",
      "iteration: 190600 loss: 0.0010 lr: 0.02\n",
      "iteration: 190700 loss: 0.0010 lr: 0.02\n",
      "iteration: 190800 loss: 0.0010 lr: 0.02\n",
      "iteration: 190900 loss: 0.0008 lr: 0.02\n",
      "iteration: 191000 loss: 0.0009 lr: 0.02\n",
      "iteration: 191100 loss: 0.0010 lr: 0.02\n",
      "iteration: 191200 loss: 0.0011 lr: 0.02\n",
      "iteration: 191300 loss: 0.0010 lr: 0.02\n",
      "iteration: 191400 loss: 0.0011 lr: 0.02\n",
      "iteration: 191500 loss: 0.0010 lr: 0.02\n",
      "iteration: 191600 loss: 0.0011 lr: 0.02\n",
      "iteration: 191700 loss: 0.0009 lr: 0.02\n",
      "iteration: 191800 loss: 0.0010 lr: 0.02\n",
      "iteration: 191900 loss: 0.0010 lr: 0.02\n",
      "iteration: 192000 loss: 0.0010 lr: 0.02\n",
      "iteration: 192100 loss: 0.0010 lr: 0.02\n",
      "iteration: 192200 loss: 0.0009 lr: 0.02\n",
      "iteration: 192300 loss: 0.0011 lr: 0.02\n",
      "iteration: 192400 loss: 0.0010 lr: 0.02\n",
      "iteration: 192500 loss: 0.0011 lr: 0.02\n",
      "iteration: 192600 loss: 0.0010 lr: 0.02\n",
      "iteration: 192700 loss: 0.0010 lr: 0.02\n",
      "iteration: 192800 loss: 0.0010 lr: 0.02\n",
      "iteration: 192900 loss: 0.0012 lr: 0.02\n",
      "iteration: 193000 loss: 0.0010 lr: 0.02\n",
      "iteration: 193100 loss: 0.0010 lr: 0.02\n",
      "iteration: 193200 loss: 0.0010 lr: 0.02\n",
      "iteration: 193300 loss: 0.0011 lr: 0.02\n",
      "iteration: 193400 loss: 0.0010 lr: 0.02\n",
      "iteration: 193500 loss: 0.0009 lr: 0.02\n",
      "iteration: 193600 loss: 0.0009 lr: 0.02\n",
      "iteration: 193700 loss: 0.0009 lr: 0.02\n",
      "iteration: 193800 loss: 0.0012 lr: 0.02\n",
      "iteration: 193900 loss: 0.0009 lr: 0.02\n",
      "iteration: 194000 loss: 0.0009 lr: 0.02\n",
      "iteration: 194100 loss: 0.0010 lr: 0.02\n",
      "iteration: 194200 loss: 0.0009 lr: 0.02\n",
      "iteration: 194300 loss: 0.0009 lr: 0.02\n",
      "iteration: 194400 loss: 0.0009 lr: 0.02\n",
      "iteration: 194500 loss: 0.0008 lr: 0.02\n",
      "iteration: 194600 loss: 0.0011 lr: 0.02\n",
      "iteration: 194700 loss: 0.0010 lr: 0.02\n",
      "iteration: 194800 loss: 0.0009 lr: 0.02\n",
      "iteration: 194900 loss: 0.0011 lr: 0.02\n",
      "iteration: 195000 loss: 0.0010 lr: 0.02\n",
      "iteration: 195100 loss: 0.0010 lr: 0.02\n",
      "iteration: 195200 loss: 0.0011 lr: 0.02\n",
      "iteration: 195300 loss: 0.0010 lr: 0.02\n",
      "iteration: 195400 loss: 0.0011 lr: 0.02\n",
      "iteration: 195500 loss: 0.0011 lr: 0.02\n",
      "iteration: 195600 loss: 0.0009 lr: 0.02\n",
      "iteration: 195700 loss: 0.0009 lr: 0.02\n",
      "iteration: 195800 loss: 0.0007 lr: 0.02\n",
      "iteration: 195900 loss: 0.0011 lr: 0.02\n",
      "iteration: 196000 loss: 0.0012 lr: 0.02\n",
      "iteration: 196100 loss: 0.0012 lr: 0.02\n",
      "iteration: 196200 loss: 0.0011 lr: 0.02\n",
      "iteration: 196300 loss: 0.0010 lr: 0.02\n",
      "iteration: 196400 loss: 0.0012 lr: 0.02\n",
      "iteration: 196500 loss: 0.0010 lr: 0.02\n",
      "iteration: 196600 loss: 0.0010 lr: 0.02\n",
      "iteration: 196700 loss: 0.0010 lr: 0.02\n",
      "iteration: 196800 loss: 0.0007 lr: 0.02\n",
      "iteration: 196900 loss: 0.0010 lr: 0.02\n",
      "iteration: 197000 loss: 0.0011 lr: 0.02\n",
      "iteration: 197100 loss: 0.0009 lr: 0.02\n",
      "iteration: 197200 loss: 0.0008 lr: 0.02\n",
      "iteration: 197300 loss: 0.0010 lr: 0.02\n",
      "iteration: 197400 loss: 0.0008 lr: 0.02\n",
      "iteration: 197500 loss: 0.0009 lr: 0.02\n",
      "iteration: 197600 loss: 0.0011 lr: 0.02\n",
      "iteration: 197700 loss: 0.0010 lr: 0.02\n",
      "iteration: 197800 loss: 0.0009 lr: 0.02\n",
      "iteration: 197900 loss: 0.0010 lr: 0.02\n",
      "iteration: 198000 loss: 0.0011 lr: 0.02\n",
      "iteration: 198100 loss: 0.0011 lr: 0.02\n",
      "iteration: 198200 loss: 0.0009 lr: 0.02\n",
      "iteration: 198300 loss: 0.0009 lr: 0.02\n",
      "iteration: 198400 loss: 0.0010 lr: 0.02\n",
      "iteration: 198500 loss: 0.0010 lr: 0.02\n",
      "iteration: 198600 loss: 0.0011 lr: 0.02\n",
      "iteration: 198700 loss: 0.0008 lr: 0.02\n",
      "iteration: 198800 loss: 0.0009 lr: 0.02\n",
      "iteration: 198900 loss: 0.0011 lr: 0.02\n",
      "iteration: 199000 loss: 0.0009 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 199100 loss: 0.0009 lr: 0.02\n",
      "iteration: 199200 loss: 0.0010 lr: 0.02\n",
      "iteration: 199300 loss: 0.0009 lr: 0.02\n",
      "iteration: 199400 loss: 0.0010 lr: 0.02\n",
      "iteration: 199500 loss: 0.0010 lr: 0.02\n",
      "iteration: 199600 loss: 0.0011 lr: 0.02\n",
      "iteration: 199700 loss: 0.0010 lr: 0.02\n",
      "iteration: 199800 loss: 0.0010 lr: 0.02\n",
      "iteration: 199900 loss: 0.0009 lr: 0.02\n",
      "iteration: 200000 loss: 0.0009 lr: 0.02\n",
      "iteration: 200100 loss: 0.0010 lr: 0.02\n",
      "iteration: 200200 loss: 0.0011 lr: 0.02\n",
      "iteration: 200300 loss: 0.0009 lr: 0.02\n",
      "iteration: 200400 loss: 0.0008 lr: 0.02\n",
      "iteration: 200500 loss: 0.0009 lr: 0.02\n",
      "iteration: 200600 loss: 0.0010 lr: 0.02\n",
      "iteration: 200700 loss: 0.0010 lr: 0.02\n",
      "iteration: 200800 loss: 0.0010 lr: 0.02\n",
      "iteration: 200900 loss: 0.0010 lr: 0.02\n",
      "iteration: 201000 loss: 0.0009 lr: 0.02\n",
      "iteration: 201100 loss: 0.0011 lr: 0.02\n",
      "iteration: 201200 loss: 0.0009 lr: 0.02\n",
      "iteration: 201300 loss: 0.0010 lr: 0.02\n",
      "iteration: 201400 loss: 0.0011 lr: 0.02\n",
      "iteration: 201500 loss: 0.0010 lr: 0.02\n",
      "iteration: 201600 loss: 0.0010 lr: 0.02\n",
      "iteration: 201700 loss: 0.0010 lr: 0.02\n",
      "iteration: 201800 loss: 0.0009 lr: 0.02\n",
      "iteration: 201900 loss: 0.0009 lr: 0.02\n",
      "iteration: 202000 loss: 0.0012 lr: 0.02\n",
      "iteration: 202100 loss: 0.0011 lr: 0.02\n",
      "iteration: 202200 loss: 0.0009 lr: 0.02\n",
      "iteration: 202300 loss: 0.0009 lr: 0.02\n",
      "iteration: 202400 loss: 0.0014 lr: 0.02\n",
      "iteration: 202500 loss: 0.0010 lr: 0.02\n",
      "iteration: 202600 loss: 0.0009 lr: 0.02\n",
      "iteration: 202700 loss: 0.0009 lr: 0.02\n",
      "iteration: 202800 loss: 0.0010 lr: 0.02\n",
      "iteration: 202900 loss: 0.0009 lr: 0.02\n",
      "iteration: 203000 loss: 0.0009 lr: 0.02\n",
      "iteration: 203100 loss: 0.0010 lr: 0.02\n",
      "iteration: 203200 loss: 0.0008 lr: 0.02\n",
      "iteration: 203300 loss: 0.0009 lr: 0.02\n",
      "iteration: 203400 loss: 0.0011 lr: 0.02\n",
      "iteration: 203500 loss: 0.0010 lr: 0.02\n",
      "iteration: 203600 loss: 0.0008 lr: 0.02\n",
      "iteration: 203700 loss: 0.0010 lr: 0.02\n",
      "iteration: 203800 loss: 0.0009 lr: 0.02\n",
      "iteration: 203900 loss: 0.0008 lr: 0.02\n",
      "iteration: 204000 loss: 0.0010 lr: 0.02\n",
      "iteration: 204100 loss: 0.0009 lr: 0.02\n",
      "iteration: 204200 loss: 0.0010 lr: 0.02\n",
      "iteration: 204300 loss: 0.0009 lr: 0.02\n",
      "iteration: 204400 loss: 0.0009 lr: 0.02\n",
      "iteration: 204500 loss: 0.0009 lr: 0.02\n",
      "iteration: 204600 loss: 0.0009 lr: 0.02\n",
      "iteration: 204700 loss: 0.0009 lr: 0.02\n",
      "iteration: 204800 loss: 0.0008 lr: 0.02\n",
      "iteration: 204900 loss: 0.0008 lr: 0.02\n",
      "iteration: 205000 loss: 0.0010 lr: 0.02\n",
      "iteration: 205100 loss: 0.0009 lr: 0.02\n",
      "iteration: 205200 loss: 0.0008 lr: 0.02\n",
      "iteration: 205300 loss: 0.0009 lr: 0.02\n",
      "iteration: 205400 loss: 0.0011 lr: 0.02\n",
      "iteration: 205500 loss: 0.0011 lr: 0.02\n",
      "iteration: 205600 loss: 0.0011 lr: 0.02\n",
      "iteration: 205700 loss: 0.0009 lr: 0.02\n",
      "iteration: 205800 loss: 0.0009 lr: 0.02\n",
      "iteration: 205900 loss: 0.0010 lr: 0.02\n",
      "iteration: 206000 loss: 0.0010 lr: 0.02\n",
      "iteration: 206100 loss: 0.0009 lr: 0.02\n",
      "iteration: 206200 loss: 0.0010 lr: 0.02\n",
      "iteration: 206300 loss: 0.0011 lr: 0.02\n",
      "iteration: 206400 loss: 0.0009 lr: 0.02\n",
      "iteration: 206500 loss: 0.0011 lr: 0.02\n",
      "iteration: 206600 loss: 0.0009 lr: 0.02\n",
      "iteration: 206700 loss: 0.0011 lr: 0.02\n",
      "iteration: 206800 loss: 0.0010 lr: 0.02\n",
      "iteration: 206900 loss: 0.0010 lr: 0.02\n",
      "iteration: 207000 loss: 0.0010 lr: 0.02\n",
      "iteration: 207100 loss: 0.0008 lr: 0.02\n",
      "iteration: 207200 loss: 0.0009 lr: 0.02\n",
      "iteration: 207300 loss: 0.0011 lr: 0.02\n",
      "iteration: 207400 loss: 0.0009 lr: 0.02\n",
      "iteration: 207500 loss: 0.0008 lr: 0.02\n",
      "iteration: 207600 loss: 0.0010 lr: 0.02\n",
      "iteration: 207700 loss: 0.0010 lr: 0.02\n",
      "iteration: 207800 loss: 0.0009 lr: 0.02\n",
      "iteration: 207900 loss: 0.0010 lr: 0.02\n",
      "iteration: 208000 loss: 0.0013 lr: 0.02\n",
      "iteration: 208100 loss: 0.0009 lr: 0.02\n",
      "iteration: 208200 loss: 0.0010 lr: 0.02\n",
      "iteration: 208300 loss: 0.0009 lr: 0.02\n",
      "iteration: 208400 loss: 0.0009 lr: 0.02\n",
      "iteration: 208500 loss: 0.0010 lr: 0.02\n",
      "iteration: 208600 loss: 0.0010 lr: 0.02\n",
      "iteration: 208700 loss: 0.0010 lr: 0.02\n",
      "iteration: 208800 loss: 0.0009 lr: 0.02\n",
      "iteration: 208900 loss: 0.0009 lr: 0.02\n",
      "iteration: 209000 loss: 0.0010 lr: 0.02\n",
      "iteration: 209100 loss: 0.0009 lr: 0.02\n",
      "iteration: 209200 loss: 0.0009 lr: 0.02\n",
      "iteration: 209300 loss: 0.0009 lr: 0.02\n",
      "iteration: 209400 loss: 0.0009 lr: 0.02\n",
      "iteration: 209500 loss: 0.0010 lr: 0.02\n",
      "iteration: 209600 loss: 0.0009 lr: 0.02\n",
      "iteration: 209700 loss: 0.0009 lr: 0.02\n",
      "iteration: 209800 loss: 0.0009 lr: 0.02\n",
      "iteration: 209900 loss: 0.0010 lr: 0.02\n",
      "iteration: 210000 loss: 0.0010 lr: 0.02\n",
      "iteration: 210100 loss: 0.0008 lr: 0.02\n",
      "iteration: 210200 loss: 0.0008 lr: 0.02\n",
      "iteration: 210300 loss: 0.0009 lr: 0.02\n",
      "iteration: 210400 loss: 0.0009 lr: 0.02\n",
      "iteration: 210500 loss: 0.0009 lr: 0.02\n",
      "iteration: 210600 loss: 0.0010 lr: 0.02\n",
      "iteration: 210700 loss: 0.0010 lr: 0.02\n",
      "iteration: 210800 loss: 0.0010 lr: 0.02\n",
      "iteration: 210900 loss: 0.0008 lr: 0.02\n",
      "iteration: 211000 loss: 0.0009 lr: 0.02\n",
      "iteration: 211100 loss: 0.0009 lr: 0.02\n",
      "iteration: 211200 loss: 0.0009 lr: 0.02\n",
      "iteration: 211300 loss: 0.0010 lr: 0.02\n",
      "iteration: 211400 loss: 0.0010 lr: 0.02\n",
      "iteration: 211500 loss: 0.0010 lr: 0.02\n",
      "iteration: 211600 loss: 0.0009 lr: 0.02\n",
      "iteration: 211700 loss: 0.0010 lr: 0.02\n",
      "iteration: 211800 loss: 0.0011 lr: 0.02\n",
      "iteration: 211900 loss: 0.0010 lr: 0.02\n",
      "iteration: 212000 loss: 0.0012 lr: 0.02\n",
      "iteration: 212100 loss: 0.0010 lr: 0.02\n",
      "iteration: 212200 loss: 0.0008 lr: 0.02\n",
      "iteration: 212300 loss: 0.0010 lr: 0.02\n",
      "iteration: 212400 loss: 0.0010 lr: 0.02\n",
      "iteration: 212500 loss: 0.0010 lr: 0.02\n",
      "iteration: 212600 loss: 0.0008 lr: 0.02\n",
      "iteration: 212700 loss: 0.0010 lr: 0.02\n",
      "iteration: 212800 loss: 0.0009 lr: 0.02\n",
      "iteration: 212900 loss: 0.0009 lr: 0.02\n",
      "iteration: 213000 loss: 0.0008 lr: 0.02\n",
      "iteration: 213100 loss: 0.0008 lr: 0.02\n",
      "iteration: 213200 loss: 0.0009 lr: 0.02\n",
      "iteration: 213300 loss: 0.0008 lr: 0.02\n",
      "iteration: 213400 loss: 0.0010 lr: 0.02\n",
      "iteration: 213500 loss: 0.0011 lr: 0.02\n",
      "iteration: 213600 loss: 0.0009 lr: 0.02\n",
      "iteration: 213700 loss: 0.0009 lr: 0.02\n",
      "iteration: 213800 loss: 0.0010 lr: 0.02\n",
      "iteration: 213900 loss: 0.0008 lr: 0.02\n",
      "iteration: 214000 loss: 0.0009 lr: 0.02\n",
      "iteration: 214100 loss: 0.0010 lr: 0.02\n",
      "iteration: 214200 loss: 0.0009 lr: 0.02\n",
      "iteration: 214300 loss: 0.0008 lr: 0.02\n",
      "iteration: 214400 loss: 0.0008 lr: 0.02\n",
      "iteration: 214500 loss: 0.0011 lr: 0.02\n",
      "iteration: 214600 loss: 0.0009 lr: 0.02\n",
      "iteration: 214700 loss: 0.0011 lr: 0.02\n",
      "iteration: 214800 loss: 0.0010 lr: 0.02\n",
      "iteration: 214900 loss: 0.0009 lr: 0.02\n",
      "iteration: 215000 loss: 0.0010 lr: 0.02\n",
      "iteration: 215100 loss: 0.0008 lr: 0.02\n",
      "iteration: 215200 loss: 0.0009 lr: 0.02\n",
      "iteration: 215300 loss: 0.0011 lr: 0.02\n",
      "iteration: 215400 loss: 0.0010 lr: 0.02\n",
      "iteration: 215500 loss: 0.0012 lr: 0.02\n",
      "iteration: 215600 loss: 0.0014 lr: 0.02\n",
      "iteration: 215700 loss: 0.0011 lr: 0.02\n",
      "iteration: 215800 loss: 0.0009 lr: 0.02\n",
      "iteration: 215900 loss: 0.0011 lr: 0.02\n",
      "iteration: 216000 loss: 0.0009 lr: 0.02\n",
      "iteration: 216100 loss: 0.0009 lr: 0.02\n",
      "iteration: 216200 loss: 0.0008 lr: 0.02\n",
      "iteration: 216300 loss: 0.0009 lr: 0.02\n",
      "iteration: 216400 loss: 0.0008 lr: 0.02\n",
      "iteration: 216500 loss: 0.0010 lr: 0.02\n",
      "iteration: 216600 loss: 0.0008 lr: 0.02\n",
      "iteration: 216700 loss: 0.0010 lr: 0.02\n",
      "iteration: 216800 loss: 0.0010 lr: 0.02\n",
      "iteration: 216900 loss: 0.0010 lr: 0.02\n",
      "iteration: 217000 loss: 0.0010 lr: 0.02\n",
      "iteration: 217100 loss: 0.0011 lr: 0.02\n",
      "iteration: 217200 loss: 0.0010 lr: 0.02\n",
      "iteration: 217300 loss: 0.0010 lr: 0.02\n",
      "iteration: 217400 loss: 0.0009 lr: 0.02\n",
      "iteration: 217500 loss: 0.0009 lr: 0.02\n",
      "iteration: 217600 loss: 0.0008 lr: 0.02\n",
      "iteration: 217700 loss: 0.0009 lr: 0.02\n",
      "iteration: 217800 loss: 0.0009 lr: 0.02\n",
      "iteration: 217900 loss: 0.0010 lr: 0.02\n",
      "iteration: 218000 loss: 0.0008 lr: 0.02\n",
      "iteration: 218100 loss: 0.0009 lr: 0.02\n",
      "iteration: 218200 loss: 0.0009 lr: 0.02\n",
      "iteration: 218300 loss: 0.0010 lr: 0.02\n",
      "iteration: 218400 loss: 0.0010 lr: 0.02\n",
      "iteration: 218500 loss: 0.0008 lr: 0.02\n",
      "iteration: 218600 loss: 0.0009 lr: 0.02\n",
      "iteration: 218700 loss: 0.0008 lr: 0.02\n",
      "iteration: 218800 loss: 0.0009 lr: 0.02\n",
      "iteration: 218900 loss: 0.0010 lr: 0.02\n",
      "iteration: 219000 loss: 0.0009 lr: 0.02\n",
      "iteration: 219100 loss: 0.0009 lr: 0.02\n",
      "iteration: 219200 loss: 0.0010 lr: 0.02\n",
      "iteration: 219300 loss: 0.0012 lr: 0.02\n",
      "iteration: 219400 loss: 0.0010 lr: 0.02\n",
      "iteration: 219500 loss: 0.0009 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 219600 loss: 0.0008 lr: 0.02\n",
      "iteration: 219700 loss: 0.0011 lr: 0.02\n",
      "iteration: 219800 loss: 0.0008 lr: 0.02\n",
      "iteration: 219900 loss: 0.0008 lr: 0.02\n",
      "iteration: 220000 loss: 0.0009 lr: 0.02\n",
      "iteration: 220100 loss: 0.0009 lr: 0.02\n",
      "iteration: 220200 loss: 0.0009 lr: 0.02\n",
      "iteration: 220300 loss: 0.0008 lr: 0.02\n",
      "iteration: 220400 loss: 0.0009 lr: 0.02\n",
      "iteration: 220500 loss: 0.0009 lr: 0.02\n",
      "iteration: 220600 loss: 0.0010 lr: 0.02\n",
      "iteration: 220700 loss: 0.0010 lr: 0.02\n",
      "iteration: 220800 loss: 0.0012 lr: 0.02\n",
      "iteration: 220900 loss: 0.0009 lr: 0.02\n",
      "iteration: 221000 loss: 0.0010 lr: 0.02\n",
      "iteration: 221100 loss: 0.0010 lr: 0.02\n",
      "iteration: 221200 loss: 0.0008 lr: 0.02\n",
      "iteration: 221300 loss: 0.0010 lr: 0.02\n",
      "iteration: 221400 loss: 0.0009 lr: 0.02\n",
      "iteration: 221500 loss: 0.0007 lr: 0.02\n",
      "iteration: 221600 loss: 0.0008 lr: 0.02\n",
      "iteration: 221700 loss: 0.0007 lr: 0.02\n",
      "iteration: 221800 loss: 0.0009 lr: 0.02\n",
      "iteration: 221900 loss: 0.0010 lr: 0.02\n",
      "iteration: 222000 loss: 0.0009 lr: 0.02\n",
      "iteration: 222100 loss: 0.0010 lr: 0.02\n",
      "iteration: 222200 loss: 0.0011 lr: 0.02\n",
      "iteration: 222300 loss: 0.0009 lr: 0.02\n",
      "iteration: 222400 loss: 0.0009 lr: 0.02\n",
      "iteration: 222500 loss: 0.0011 lr: 0.02\n",
      "iteration: 222600 loss: 0.0012 lr: 0.02\n",
      "iteration: 222700 loss: 0.0010 lr: 0.02\n",
      "iteration: 222800 loss: 0.0010 lr: 0.02\n",
      "iteration: 222900 loss: 0.0010 lr: 0.02\n",
      "iteration: 223000 loss: 0.0010 lr: 0.02\n",
      "iteration: 223100 loss: 0.0011 lr: 0.02\n",
      "iteration: 223200 loss: 0.0010 lr: 0.02\n",
      "iteration: 223300 loss: 0.0011 lr: 0.02\n",
      "iteration: 223400 loss: 0.0010 lr: 0.02\n",
      "iteration: 223500 loss: 0.0008 lr: 0.02\n",
      "iteration: 223600 loss: 0.0010 lr: 0.02\n",
      "iteration: 223700 loss: 0.0009 lr: 0.02\n",
      "iteration: 223800 loss: 0.0011 lr: 0.02\n",
      "iteration: 223900 loss: 0.0011 lr: 0.02\n",
      "iteration: 224000 loss: 0.0008 lr: 0.02\n",
      "iteration: 224100 loss: 0.0010 lr: 0.02\n",
      "iteration: 224200 loss: 0.0008 lr: 0.02\n",
      "iteration: 224300 loss: 0.0007 lr: 0.02\n",
      "iteration: 224400 loss: 0.0008 lr: 0.02\n",
      "iteration: 224500 loss: 0.0009 lr: 0.02\n",
      "iteration: 224600 loss: 0.0009 lr: 0.02\n",
      "iteration: 224700 loss: 0.0009 lr: 0.02\n",
      "iteration: 224800 loss: 0.0008 lr: 0.02\n",
      "iteration: 224900 loss: 0.0007 lr: 0.02\n",
      "iteration: 225000 loss: 0.0008 lr: 0.02\n",
      "iteration: 225100 loss: 0.0008 lr: 0.02\n",
      "iteration: 225200 loss: 0.0009 lr: 0.02\n",
      "iteration: 225300 loss: 0.0010 lr: 0.02\n",
      "iteration: 225400 loss: 0.0010 lr: 0.02\n",
      "iteration: 225500 loss: 0.0009 lr: 0.02\n",
      "iteration: 225600 loss: 0.0009 lr: 0.02\n",
      "iteration: 225700 loss: 0.0009 lr: 0.02\n",
      "iteration: 225800 loss: 0.0009 lr: 0.02\n",
      "iteration: 225900 loss: 0.0010 lr: 0.02\n",
      "iteration: 226000 loss: 0.0008 lr: 0.02\n",
      "iteration: 226100 loss: 0.0009 lr: 0.02\n",
      "iteration: 226200 loss: 0.0007 lr: 0.02\n",
      "iteration: 226300 loss: 0.0008 lr: 0.02\n",
      "iteration: 226400 loss: 0.0008 lr: 0.02\n",
      "iteration: 226500 loss: 0.0009 lr: 0.02\n",
      "iteration: 226600 loss: 0.0008 lr: 0.02\n",
      "iteration: 226700 loss: 0.0009 lr: 0.02\n",
      "iteration: 226800 loss: 0.0010 lr: 0.02\n",
      "iteration: 226900 loss: 0.0010 lr: 0.02\n",
      "iteration: 227000 loss: 0.0010 lr: 0.02\n",
      "iteration: 227100 loss: 0.0010 lr: 0.02\n",
      "iteration: 227200 loss: 0.0011 lr: 0.02\n",
      "iteration: 227300 loss: 0.0010 lr: 0.02\n",
      "iteration: 227400 loss: 0.0009 lr: 0.02\n",
      "iteration: 227500 loss: 0.0008 lr: 0.02\n",
      "iteration: 227600 loss: 0.0010 lr: 0.02\n",
      "iteration: 227700 loss: 0.0009 lr: 0.02\n",
      "iteration: 227800 loss: 0.0009 lr: 0.02\n",
      "iteration: 227900 loss: 0.0009 lr: 0.02\n",
      "iteration: 228000 loss: 0.0009 lr: 0.02\n",
      "iteration: 228100 loss: 0.0009 lr: 0.02\n",
      "iteration: 228200 loss: 0.0009 lr: 0.02\n",
      "iteration: 228300 loss: 0.0008 lr: 0.02\n",
      "iteration: 228400 loss: 0.0008 lr: 0.02\n",
      "iteration: 228500 loss: 0.0011 lr: 0.02\n",
      "iteration: 228600 loss: 0.0011 lr: 0.02\n",
      "iteration: 228700 loss: 0.0008 lr: 0.02\n",
      "iteration: 228800 loss: 0.0010 lr: 0.02\n",
      "iteration: 228900 loss: 0.0009 lr: 0.02\n",
      "iteration: 229000 loss: 0.0009 lr: 0.02\n",
      "iteration: 229100 loss: 0.0011 lr: 0.02\n",
      "iteration: 229200 loss: 0.0007 lr: 0.02\n",
      "iteration: 229300 loss: 0.0008 lr: 0.02\n",
      "iteration: 229400 loss: 0.0008 lr: 0.02\n",
      "iteration: 229500 loss: 0.0009 lr: 0.02\n",
      "iteration: 229600 loss: 0.0009 lr: 0.02\n",
      "iteration: 229700 loss: 0.0010 lr: 0.02\n",
      "iteration: 229800 loss: 0.0009 lr: 0.02\n",
      "iteration: 229900 loss: 0.0008 lr: 0.02\n",
      "iteration: 230000 loss: 0.0008 lr: 0.02\n",
      "iteration: 230100 loss: 0.0009 lr: 0.02\n",
      "iteration: 230200 loss: 0.0010 lr: 0.02\n",
      "iteration: 230300 loss: 0.0010 lr: 0.02\n",
      "iteration: 230400 loss: 0.0010 lr: 0.02\n",
      "iteration: 230500 loss: 0.0009 lr: 0.02\n",
      "iteration: 230600 loss: 0.0009 lr: 0.02\n",
      "iteration: 230700 loss: 0.0010 lr: 0.02\n",
      "iteration: 230800 loss: 0.0010 lr: 0.02\n",
      "iteration: 230900 loss: 0.0009 lr: 0.02\n",
      "iteration: 231000 loss: 0.0011 lr: 0.02\n",
      "iteration: 231100 loss: 0.0009 lr: 0.02\n",
      "iteration: 231200 loss: 0.0011 lr: 0.02\n",
      "iteration: 231300 loss: 0.0009 lr: 0.02\n",
      "iteration: 231400 loss: 0.0011 lr: 0.02\n",
      "iteration: 231500 loss: 0.0010 lr: 0.02\n",
      "iteration: 231600 loss: 0.0009 lr: 0.02\n",
      "iteration: 231700 loss: 0.0009 lr: 0.02\n",
      "iteration: 231800 loss: 0.0010 lr: 0.02\n",
      "iteration: 231900 loss: 0.0008 lr: 0.02\n",
      "iteration: 232000 loss: 0.0008 lr: 0.02\n",
      "iteration: 232100 loss: 0.0008 lr: 0.02\n",
      "iteration: 232200 loss: 0.0008 lr: 0.02\n",
      "iteration: 232300 loss: 0.0010 lr: 0.02\n",
      "iteration: 232400 loss: 0.0008 lr: 0.02\n",
      "iteration: 232500 loss: 0.0008 lr: 0.02\n",
      "iteration: 232600 loss: 0.0010 lr: 0.02\n",
      "iteration: 232700 loss: 0.0008 lr: 0.02\n",
      "iteration: 232800 loss: 0.0009 lr: 0.02\n",
      "iteration: 232900 loss: 0.0008 lr: 0.02\n",
      "iteration: 233000 loss: 0.0010 lr: 0.02\n",
      "iteration: 233100 loss: 0.0008 lr: 0.02\n",
      "iteration: 233200 loss: 0.0009 lr: 0.02\n",
      "iteration: 233300 loss: 0.0009 lr: 0.02\n",
      "iteration: 233400 loss: 0.0011 lr: 0.02\n",
      "iteration: 233500 loss: 0.0009 lr: 0.02\n",
      "iteration: 233600 loss: 0.0010 lr: 0.02\n",
      "iteration: 233700 loss: 0.0011 lr: 0.02\n",
      "iteration: 233800 loss: 0.0008 lr: 0.02\n",
      "iteration: 233900 loss: 0.0009 lr: 0.02\n",
      "iteration: 234000 loss: 0.0009 lr: 0.02\n",
      "iteration: 234100 loss: 0.0010 lr: 0.02\n",
      "iteration: 234200 loss: 0.0009 lr: 0.02\n",
      "iteration: 234300 loss: 0.0009 lr: 0.02\n",
      "iteration: 234400 loss: 0.0010 lr: 0.02\n",
      "iteration: 234500 loss: 0.0008 lr: 0.02\n",
      "iteration: 234600 loss: 0.0009 lr: 0.02\n",
      "iteration: 234700 loss: 0.0010 lr: 0.02\n",
      "iteration: 234800 loss: 0.0010 lr: 0.02\n",
      "iteration: 234900 loss: 0.0009 lr: 0.02\n",
      "iteration: 235000 loss: 0.0009 lr: 0.02\n",
      "iteration: 235100 loss: 0.0008 lr: 0.02\n",
      "iteration: 235200 loss: 0.0011 lr: 0.02\n",
      "iteration: 235300 loss: 0.0009 lr: 0.02\n",
      "iteration: 235400 loss: 0.0007 lr: 0.02\n",
      "iteration: 235500 loss: 0.0010 lr: 0.02\n",
      "iteration: 235600 loss: 0.0011 lr: 0.02\n",
      "iteration: 235700 loss: 0.0012 lr: 0.02\n",
      "iteration: 235800 loss: 0.0009 lr: 0.02\n",
      "iteration: 235900 loss: 0.0009 lr: 0.02\n",
      "iteration: 236000 loss: 0.0008 lr: 0.02\n",
      "iteration: 236100 loss: 0.0008 lr: 0.02\n",
      "iteration: 236200 loss: 0.0009 lr: 0.02\n",
      "iteration: 236300 loss: 0.0009 lr: 0.02\n",
      "iteration: 236400 loss: 0.0010 lr: 0.02\n",
      "iteration: 236500 loss: 0.0009 lr: 0.02\n",
      "iteration: 236600 loss: 0.0009 lr: 0.02\n",
      "iteration: 236700 loss: 0.0008 lr: 0.02\n",
      "iteration: 236800 loss: 0.0009 lr: 0.02\n",
      "iteration: 236900 loss: 0.0008 lr: 0.02\n",
      "iteration: 237000 loss: 0.0009 lr: 0.02\n",
      "iteration: 237100 loss: 0.0009 lr: 0.02\n",
      "iteration: 237200 loss: 0.0011 lr: 0.02\n",
      "iteration: 237300 loss: 0.0010 lr: 0.02\n",
      "iteration: 237400 loss: 0.0008 lr: 0.02\n",
      "iteration: 237500 loss: 0.0008 lr: 0.02\n",
      "iteration: 237600 loss: 0.0010 lr: 0.02\n",
      "iteration: 237700 loss: 0.0011 lr: 0.02\n",
      "iteration: 237800 loss: 0.0009 lr: 0.02\n",
      "iteration: 237900 loss: 0.0010 lr: 0.02\n",
      "iteration: 238000 loss: 0.0010 lr: 0.02\n",
      "iteration: 238100 loss: 0.0009 lr: 0.02\n",
      "iteration: 238200 loss: 0.0011 lr: 0.02\n",
      "iteration: 238300 loss: 0.0009 lr: 0.02\n",
      "iteration: 238400 loss: 0.0009 lr: 0.02\n",
      "iteration: 238500 loss: 0.0009 lr: 0.02\n",
      "iteration: 238600 loss: 0.0009 lr: 0.02\n",
      "iteration: 238700 loss: 0.0010 lr: 0.02\n",
      "iteration: 238800 loss: 0.0008 lr: 0.02\n",
      "iteration: 238900 loss: 0.0008 lr: 0.02\n",
      "iteration: 239000 loss: 0.0010 lr: 0.02\n",
      "iteration: 239100 loss: 0.0008 lr: 0.02\n",
      "iteration: 239200 loss: 0.0010 lr: 0.02\n",
      "iteration: 239300 loss: 0.0008 lr: 0.02\n",
      "iteration: 239400 loss: 0.0008 lr: 0.02\n",
      "iteration: 239500 loss: 0.0010 lr: 0.02\n",
      "iteration: 239600 loss: 0.0008 lr: 0.02\n",
      "iteration: 239700 loss: 0.0010 lr: 0.02\n",
      "iteration: 239800 loss: 0.0009 lr: 0.02\n",
      "iteration: 239900 loss: 0.0009 lr: 0.02\n",
      "iteration: 240000 loss: 0.0009 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 240100 loss: 0.0011 lr: 0.02\n",
      "iteration: 240200 loss: 0.0009 lr: 0.02\n",
      "iteration: 240300 loss: 0.0010 lr: 0.02\n",
      "iteration: 240400 loss: 0.0009 lr: 0.02\n",
      "iteration: 240500 loss: 0.0009 lr: 0.02\n",
      "iteration: 240600 loss: 0.0010 lr: 0.02\n",
      "iteration: 240700 loss: 0.0009 lr: 0.02\n",
      "iteration: 240800 loss: 0.0010 lr: 0.02\n",
      "iteration: 240900 loss: 0.0010 lr: 0.02\n",
      "iteration: 241000 loss: 0.0008 lr: 0.02\n",
      "iteration: 241100 loss: 0.0009 lr: 0.02\n",
      "iteration: 241200 loss: 0.0008 lr: 0.02\n",
      "iteration: 241300 loss: 0.0009 lr: 0.02\n",
      "iteration: 241400 loss: 0.0010 lr: 0.02\n",
      "iteration: 241500 loss: 0.0010 lr: 0.02\n",
      "iteration: 241600 loss: 0.0009 lr: 0.02\n",
      "iteration: 241700 loss: 0.0008 lr: 0.02\n",
      "iteration: 241800 loss: 0.0008 lr: 0.02\n",
      "iteration: 241900 loss: 0.0009 lr: 0.02\n",
      "iteration: 242000 loss: 0.0008 lr: 0.02\n",
      "iteration: 242100 loss: 0.0010 lr: 0.02\n",
      "iteration: 242200 loss: 0.0011 lr: 0.02\n",
      "iteration: 242300 loss: 0.0010 lr: 0.02\n",
      "iteration: 242400 loss: 0.0009 lr: 0.02\n",
      "iteration: 242500 loss: 0.0010 lr: 0.02\n",
      "iteration: 242600 loss: 0.0012 lr: 0.02\n",
      "iteration: 242700 loss: 0.0009 lr: 0.02\n",
      "iteration: 242800 loss: 0.0011 lr: 0.02\n",
      "iteration: 242900 loss: 0.0009 lr: 0.02\n",
      "iteration: 243000 loss: 0.0010 lr: 0.02\n",
      "iteration: 243100 loss: 0.0009 lr: 0.02\n",
      "iteration: 243200 loss: 0.0008 lr: 0.02\n",
      "iteration: 243300 loss: 0.0009 lr: 0.02\n",
      "iteration: 243400 loss: 0.0009 lr: 0.02\n",
      "iteration: 243500 loss: 0.0010 lr: 0.02\n",
      "iteration: 243600 loss: 0.0009 lr: 0.02\n",
      "iteration: 243700 loss: 0.0009 lr: 0.02\n",
      "iteration: 243800 loss: 0.0009 lr: 0.02\n",
      "iteration: 243900 loss: 0.0008 lr: 0.02\n",
      "iteration: 244000 loss: 0.0009 lr: 0.02\n",
      "iteration: 244100 loss: 0.0008 lr: 0.02\n",
      "iteration: 244200 loss: 0.0009 lr: 0.02\n",
      "iteration: 244300 loss: 0.0008 lr: 0.02\n",
      "iteration: 244400 loss: 0.0008 lr: 0.02\n",
      "iteration: 244500 loss: 0.0009 lr: 0.02\n",
      "iteration: 244600 loss: 0.0009 lr: 0.02\n",
      "iteration: 244700 loss: 0.0008 lr: 0.02\n",
      "iteration: 244800 loss: 0.0008 lr: 0.02\n",
      "iteration: 244900 loss: 0.0010 lr: 0.02\n",
      "iteration: 245000 loss: 0.0012 lr: 0.02\n",
      "iteration: 245100 loss: 0.0010 lr: 0.02\n",
      "iteration: 245200 loss: 0.0009 lr: 0.02\n",
      "iteration: 245300 loss: 0.0009 lr: 0.02\n",
      "iteration: 245400 loss: 0.0009 lr: 0.02\n",
      "iteration: 245500 loss: 0.0010 lr: 0.02\n",
      "iteration: 245600 loss: 0.0009 lr: 0.02\n",
      "iteration: 245700 loss: 0.0008 lr: 0.02\n",
      "iteration: 245800 loss: 0.0009 lr: 0.02\n",
      "iteration: 245900 loss: 0.0009 lr: 0.02\n",
      "iteration: 246000 loss: 0.0008 lr: 0.02\n",
      "iteration: 246100 loss: 0.0008 lr: 0.02\n",
      "iteration: 246200 loss: 0.0010 lr: 0.02\n",
      "iteration: 246300 loss: 0.0009 lr: 0.02\n",
      "iteration: 246400 loss: 0.0009 lr: 0.02\n",
      "iteration: 246500 loss: 0.0009 lr: 0.02\n",
      "iteration: 246600 loss: 0.0007 lr: 0.02\n",
      "iteration: 246700 loss: 0.0008 lr: 0.02\n",
      "iteration: 246800 loss: 0.0009 lr: 0.02\n",
      "iteration: 246900 loss: 0.0009 lr: 0.02\n",
      "iteration: 247000 loss: 0.0008 lr: 0.02\n",
      "iteration: 247100 loss: 0.0009 lr: 0.02\n",
      "iteration: 247200 loss: 0.0012 lr: 0.02\n",
      "iteration: 247300 loss: 0.0009 lr: 0.02\n",
      "iteration: 247400 loss: 0.0011 lr: 0.02\n",
      "iteration: 247500 loss: 0.0010 lr: 0.02\n",
      "iteration: 247600 loss: 0.0008 lr: 0.02\n",
      "iteration: 247700 loss: 0.0008 lr: 0.02\n",
      "iteration: 247800 loss: 0.0008 lr: 0.02\n",
      "iteration: 247900 loss: 0.0010 lr: 0.02\n",
      "iteration: 248000 loss: 0.0009 lr: 0.02\n",
      "iteration: 248100 loss: 0.0009 lr: 0.02\n",
      "iteration: 248200 loss: 0.0010 lr: 0.02\n",
      "iteration: 248300 loss: 0.0010 lr: 0.02\n",
      "iteration: 248400 loss: 0.0012 lr: 0.02\n",
      "iteration: 248500 loss: 0.0009 lr: 0.02\n",
      "iteration: 248600 loss: 0.0008 lr: 0.02\n",
      "iteration: 248700 loss: 0.0009 lr: 0.02\n",
      "iteration: 248800 loss: 0.0008 lr: 0.02\n",
      "iteration: 248900 loss: 0.0011 lr: 0.02\n",
      "iteration: 249000 loss: 0.0008 lr: 0.02\n",
      "iteration: 249100 loss: 0.0009 lr: 0.02\n",
      "iteration: 249200 loss: 0.0009 lr: 0.02\n",
      "iteration: 249300 loss: 0.0010 lr: 0.02\n",
      "iteration: 249400 loss: 0.0010 lr: 0.02\n",
      "iteration: 249500 loss: 0.0011 lr: 0.02\n",
      "iteration: 249600 loss: 0.0008 lr: 0.02\n",
      "iteration: 249700 loss: 0.0009 lr: 0.02\n",
      "iteration: 249800 loss: 0.0011 lr: 0.02\n",
      "iteration: 249900 loss: 0.0011 lr: 0.02\n",
      "iteration: 250000 loss: 0.0010 lr: 0.02\n",
      "iteration: 250100 loss: 0.0009 lr: 0.02\n",
      "iteration: 250200 loss: 0.0009 lr: 0.02\n",
      "iteration: 250300 loss: 0.0009 lr: 0.02\n",
      "iteration: 250400 loss: 0.0008 lr: 0.02\n",
      "iteration: 250500 loss: 0.0011 lr: 0.02\n",
      "iteration: 250600 loss: 0.0009 lr: 0.02\n",
      "iteration: 250700 loss: 0.0009 lr: 0.02\n",
      "iteration: 250800 loss: 0.0010 lr: 0.02\n",
      "iteration: 250900 loss: 0.0009 lr: 0.02\n",
      "iteration: 251000 loss: 0.0008 lr: 0.02\n",
      "iteration: 251100 loss: 0.0008 lr: 0.02\n",
      "iteration: 251200 loss: 0.0009 lr: 0.02\n",
      "iteration: 251300 loss: 0.0008 lr: 0.02\n",
      "iteration: 251400 loss: 0.0008 lr: 0.02\n",
      "iteration: 251500 loss: 0.0010 lr: 0.02\n",
      "iteration: 251600 loss: 0.0009 lr: 0.02\n",
      "iteration: 251700 loss: 0.0006 lr: 0.02\n",
      "iteration: 251800 loss: 0.0008 lr: 0.02\n",
      "iteration: 251900 loss: 0.0011 lr: 0.02\n",
      "iteration: 252000 loss: 0.0008 lr: 0.02\n",
      "iteration: 252100 loss: 0.0008 lr: 0.02\n",
      "iteration: 252200 loss: 0.0008 lr: 0.02\n",
      "iteration: 252300 loss: 0.0009 lr: 0.02\n",
      "iteration: 252400 loss: 0.0008 lr: 0.02\n",
      "iteration: 252500 loss: 0.0012 lr: 0.02\n",
      "iteration: 252600 loss: 0.0010 lr: 0.02\n",
      "iteration: 252700 loss: 0.0009 lr: 0.02\n",
      "iteration: 252800 loss: 0.0011 lr: 0.02\n",
      "iteration: 252900 loss: 0.0009 lr: 0.02\n",
      "iteration: 253000 loss: 0.0011 lr: 0.02\n",
      "iteration: 253100 loss: 0.0008 lr: 0.02\n",
      "iteration: 253200 loss: 0.0010 lr: 0.02\n",
      "iteration: 253300 loss: 0.0008 lr: 0.02\n",
      "iteration: 253400 loss: 0.0008 lr: 0.02\n",
      "iteration: 253500 loss: 0.0009 lr: 0.02\n",
      "iteration: 253600 loss: 0.0010 lr: 0.02\n",
      "iteration: 253700 loss: 0.0009 lr: 0.02\n",
      "iteration: 253800 loss: 0.0008 lr: 0.02\n",
      "iteration: 253900 loss: 0.0009 lr: 0.02\n",
      "iteration: 254000 loss: 0.0008 lr: 0.02\n",
      "iteration: 254100 loss: 0.0010 lr: 0.02\n",
      "iteration: 254200 loss: 0.0009 lr: 0.02\n",
      "iteration: 254300 loss: 0.0009 lr: 0.02\n",
      "iteration: 254400 loss: 0.0008 lr: 0.02\n",
      "iteration: 254500 loss: 0.0008 lr: 0.02\n",
      "iteration: 254600 loss: 0.0008 lr: 0.02\n",
      "iteration: 254700 loss: 0.0008 lr: 0.02\n",
      "iteration: 254800 loss: 0.0008 lr: 0.02\n",
      "iteration: 254900 loss: 0.0008 lr: 0.02\n",
      "iteration: 255000 loss: 0.0009 lr: 0.02\n",
      "iteration: 255100 loss: 0.0009 lr: 0.02\n",
      "iteration: 255200 loss: 0.0008 lr: 0.02\n",
      "iteration: 255300 loss: 0.0008 lr: 0.02\n",
      "iteration: 255400 loss: 0.0011 lr: 0.02\n",
      "iteration: 255500 loss: 0.0008 lr: 0.02\n",
      "iteration: 255600 loss: 0.0008 lr: 0.02\n",
      "iteration: 255700 loss: 0.0009 lr: 0.02\n",
      "iteration: 255800 loss: 0.0009 lr: 0.02\n",
      "iteration: 255900 loss: 0.0008 lr: 0.02\n",
      "iteration: 256000 loss: 0.0010 lr: 0.02\n",
      "iteration: 256100 loss: 0.0009 lr: 0.02\n",
      "iteration: 256200 loss: 0.0008 lr: 0.02\n",
      "iteration: 256300 loss: 0.0010 lr: 0.02\n",
      "iteration: 256400 loss: 0.0009 lr: 0.02\n",
      "iteration: 256500 loss: 0.0009 lr: 0.02\n",
      "iteration: 256600 loss: 0.0008 lr: 0.02\n",
      "iteration: 256700 loss: 0.0010 lr: 0.02\n",
      "iteration: 256800 loss: 0.0008 lr: 0.02\n",
      "iteration: 256900 loss: 0.0009 lr: 0.02\n",
      "iteration: 257000 loss: 0.0009 lr: 0.02\n",
      "iteration: 257100 loss: 0.0008 lr: 0.02\n",
      "iteration: 257200 loss: 0.0009 lr: 0.02\n",
      "iteration: 257300 loss: 0.0010 lr: 0.02\n",
      "iteration: 257400 loss: 0.0008 lr: 0.02\n",
      "iteration: 257500 loss: 0.0011 lr: 0.02\n",
      "iteration: 257600 loss: 0.0012 lr: 0.02\n",
      "iteration: 257700 loss: 0.0009 lr: 0.02\n",
      "iteration: 257800 loss: 0.0009 lr: 0.02\n",
      "iteration: 257900 loss: 0.0008 lr: 0.02\n",
      "iteration: 258000 loss: 0.0009 lr: 0.02\n",
      "iteration: 258100 loss: 0.0008 lr: 0.02\n",
      "iteration: 258200 loss: 0.0010 lr: 0.02\n",
      "iteration: 258300 loss: 0.0010 lr: 0.02\n",
      "iteration: 258400 loss: 0.0009 lr: 0.02\n",
      "iteration: 258500 loss: 0.0009 lr: 0.02\n",
      "iteration: 258600 loss: 0.0011 lr: 0.02\n",
      "iteration: 258700 loss: 0.0010 lr: 0.02\n",
      "iteration: 258800 loss: 0.0010 lr: 0.02\n",
      "iteration: 258900 loss: 0.0008 lr: 0.02\n",
      "iteration: 259000 loss: 0.0008 lr: 0.02\n",
      "iteration: 259100 loss: 0.0008 lr: 0.02\n",
      "iteration: 259200 loss: 0.0008 lr: 0.02\n",
      "iteration: 259300 loss: 0.0008 lr: 0.02\n",
      "iteration: 259400 loss: 0.0010 lr: 0.02\n",
      "iteration: 259500 loss: 0.0011 lr: 0.02\n",
      "iteration: 259600 loss: 0.0010 lr: 0.02\n",
      "iteration: 259700 loss: 0.0008 lr: 0.02\n",
      "iteration: 259800 loss: 0.0009 lr: 0.02\n",
      "iteration: 259900 loss: 0.0007 lr: 0.02\n",
      "iteration: 260000 loss: 0.0010 lr: 0.02\n",
      "iteration: 260100 loss: 0.0009 lr: 0.02\n",
      "iteration: 260200 loss: 0.0010 lr: 0.02\n",
      "iteration: 260300 loss: 0.0009 lr: 0.02\n",
      "iteration: 260400 loss: 0.0007 lr: 0.02\n",
      "iteration: 260500 loss: 0.0011 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 260600 loss: 0.0010 lr: 0.02\n",
      "iteration: 260700 loss: 0.0008 lr: 0.02\n",
      "iteration: 260800 loss: 0.0008 lr: 0.02\n",
      "iteration: 260900 loss: 0.0009 lr: 0.02\n",
      "iteration: 261000 loss: 0.0007 lr: 0.02\n",
      "iteration: 261100 loss: 0.0009 lr: 0.02\n",
      "iteration: 261200 loss: 0.0008 lr: 0.02\n",
      "iteration: 261300 loss: 0.0010 lr: 0.02\n",
      "iteration: 261400 loss: 0.0008 lr: 0.02\n",
      "iteration: 261500 loss: 0.0009 lr: 0.02\n",
      "iteration: 261600 loss: 0.0010 lr: 0.02\n",
      "iteration: 261700 loss: 0.0009 lr: 0.02\n",
      "iteration: 261800 loss: 0.0009 lr: 0.02\n",
      "iteration: 261900 loss: 0.0010 lr: 0.02\n",
      "iteration: 262000 loss: 0.0010 lr: 0.02\n",
      "iteration: 262100 loss: 0.0010 lr: 0.02\n",
      "iteration: 262200 loss: 0.0009 lr: 0.02\n",
      "iteration: 262300 loss: 0.0009 lr: 0.02\n",
      "iteration: 262400 loss: 0.0010 lr: 0.02\n",
      "iteration: 262500 loss: 0.0012 lr: 0.02\n",
      "iteration: 262600 loss: 0.0009 lr: 0.02\n",
      "iteration: 262700 loss: 0.0008 lr: 0.02\n",
      "iteration: 262800 loss: 0.0007 lr: 0.02\n",
      "iteration: 262900 loss: 0.0007 lr: 0.02\n",
      "iteration: 263000 loss: 0.0008 lr: 0.02\n",
      "iteration: 263100 loss: 0.0008 lr: 0.02\n",
      "iteration: 263200 loss: 0.0009 lr: 0.02\n",
      "iteration: 263300 loss: 0.0007 lr: 0.02\n",
      "iteration: 263400 loss: 0.0008 lr: 0.02\n",
      "iteration: 263500 loss: 0.0008 lr: 0.02\n",
      "iteration: 263600 loss: 0.0012 lr: 0.02\n",
      "iteration: 263700 loss: 0.0008 lr: 0.02\n",
      "iteration: 263800 loss: 0.0009 lr: 0.02\n",
      "iteration: 263900 loss: 0.0010 lr: 0.02\n",
      "iteration: 264000 loss: 0.0009 lr: 0.02\n",
      "iteration: 264100 loss: 0.0010 lr: 0.02\n",
      "iteration: 264200 loss: 0.0011 lr: 0.02\n",
      "iteration: 264300 loss: 0.0010 lr: 0.02\n",
      "iteration: 264400 loss: 0.0008 lr: 0.02\n",
      "iteration: 264500 loss: 0.0009 lr: 0.02\n",
      "iteration: 264600 loss: 0.0009 lr: 0.02\n",
      "iteration: 264700 loss: 0.0007 lr: 0.02\n",
      "iteration: 264800 loss: 0.0007 lr: 0.02\n",
      "iteration: 264900 loss: 0.0009 lr: 0.02\n",
      "iteration: 265000 loss: 0.0007 lr: 0.02\n",
      "iteration: 265100 loss: 0.0008 lr: 0.02\n",
      "iteration: 265200 loss: 0.0007 lr: 0.02\n",
      "iteration: 265300 loss: 0.0008 lr: 0.02\n",
      "iteration: 265400 loss: 0.0009 lr: 0.02\n",
      "iteration: 265500 loss: 0.0009 lr: 0.02\n",
      "iteration: 265600 loss: 0.0008 lr: 0.02\n",
      "iteration: 265700 loss: 0.0009 lr: 0.02\n",
      "iteration: 265800 loss: 0.0008 lr: 0.02\n",
      "iteration: 265900 loss: 0.0008 lr: 0.02\n",
      "iteration: 266000 loss: 0.0010 lr: 0.02\n",
      "iteration: 266100 loss: 0.0010 lr: 0.02\n",
      "iteration: 266200 loss: 0.0009 lr: 0.02\n",
      "iteration: 266300 loss: 0.0010 lr: 0.02\n",
      "iteration: 266400 loss: 0.0009 lr: 0.02\n",
      "iteration: 266500 loss: 0.0009 lr: 0.02\n",
      "iteration: 266600 loss: 0.0008 lr: 0.02\n",
      "iteration: 266700 loss: 0.0008 lr: 0.02\n",
      "iteration: 266800 loss: 0.0008 lr: 0.02\n",
      "iteration: 266900 loss: 0.0008 lr: 0.02\n",
      "iteration: 267000 loss: 0.0010 lr: 0.02\n",
      "iteration: 267100 loss: 0.0011 lr: 0.02\n",
      "iteration: 267200 loss: 0.0009 lr: 0.02\n",
      "iteration: 267300 loss: 0.0011 lr: 0.02\n",
      "iteration: 267400 loss: 0.0008 lr: 0.02\n",
      "iteration: 267500 loss: 0.0009 lr: 0.02\n",
      "iteration: 267600 loss: 0.0009 lr: 0.02\n",
      "iteration: 267700 loss: 0.0008 lr: 0.02\n",
      "iteration: 267800 loss: 0.0008 lr: 0.02\n",
      "iteration: 267900 loss: 0.0009 lr: 0.02\n",
      "iteration: 268000 loss: 0.0009 lr: 0.02\n",
      "iteration: 268100 loss: 0.0010 lr: 0.02\n",
      "iteration: 268200 loss: 0.0008 lr: 0.02\n",
      "iteration: 268300 loss: 0.0011 lr: 0.02\n",
      "iteration: 268400 loss: 0.0010 lr: 0.02\n",
      "iteration: 268500 loss: 0.0011 lr: 0.02\n",
      "iteration: 268600 loss: 0.0008 lr: 0.02\n",
      "iteration: 268700 loss: 0.0008 lr: 0.02\n",
      "iteration: 268800 loss: 0.0009 lr: 0.02\n",
      "iteration: 268900 loss: 0.0008 lr: 0.02\n",
      "iteration: 269000 loss: 0.0010 lr: 0.02\n",
      "iteration: 269100 loss: 0.0009 lr: 0.02\n",
      "iteration: 269200 loss: 0.0007 lr: 0.02\n",
      "iteration: 269300 loss: 0.0010 lr: 0.02\n",
      "iteration: 269400 loss: 0.0008 lr: 0.02\n",
      "iteration: 269500 loss: 0.0010 lr: 0.02\n",
      "iteration: 269600 loss: 0.0008 lr: 0.02\n",
      "iteration: 269700 loss: 0.0008 lr: 0.02\n",
      "iteration: 269800 loss: 0.0008 lr: 0.02\n",
      "iteration: 269900 loss: 0.0008 lr: 0.02\n",
      "iteration: 270000 loss: 0.0008 lr: 0.02\n",
      "iteration: 270100 loss: 0.0008 lr: 0.02\n",
      "iteration: 270200 loss: 0.0008 lr: 0.02\n",
      "iteration: 270300 loss: 0.0008 lr: 0.02\n",
      "iteration: 270400 loss: 0.0007 lr: 0.02\n",
      "iteration: 270500 loss: 0.0008 lr: 0.02\n",
      "iteration: 270600 loss: 0.0008 lr: 0.02\n",
      "iteration: 270700 loss: 0.0009 lr: 0.02\n",
      "iteration: 270800 loss: 0.0008 lr: 0.02\n",
      "iteration: 270900 loss: 0.0009 lr: 0.02\n",
      "iteration: 271000 loss: 0.0010 lr: 0.02\n",
      "iteration: 271100 loss: 0.0007 lr: 0.02\n",
      "iteration: 271200 loss: 0.0008 lr: 0.02\n",
      "iteration: 271300 loss: 0.0009 lr: 0.02\n",
      "iteration: 271400 loss: 0.0008 lr: 0.02\n",
      "iteration: 271500 loss: 0.0011 lr: 0.02\n",
      "iteration: 271600 loss: 0.0009 lr: 0.02\n",
      "iteration: 271700 loss: 0.0008 lr: 0.02\n",
      "iteration: 271800 loss: 0.0009 lr: 0.02\n",
      "iteration: 271900 loss: 0.0009 lr: 0.02\n",
      "iteration: 272000 loss: 0.0008 lr: 0.02\n",
      "iteration: 272100 loss: 0.0009 lr: 0.02\n",
      "iteration: 272200 loss: 0.0010 lr: 0.02\n",
      "iteration: 272300 loss: 0.0009 lr: 0.02\n",
      "iteration: 272400 loss: 0.0009 lr: 0.02\n",
      "iteration: 272500 loss: 0.0009 lr: 0.02\n",
      "iteration: 272600 loss: 0.0009 lr: 0.02\n",
      "iteration: 272700 loss: 0.0008 lr: 0.02\n",
      "iteration: 272800 loss: 0.0009 lr: 0.02\n",
      "iteration: 272900 loss: 0.0008 lr: 0.02\n",
      "iteration: 273000 loss: 0.0007 lr: 0.02\n",
      "iteration: 273100 loss: 0.0007 lr: 0.02\n",
      "iteration: 273200 loss: 0.0007 lr: 0.02\n",
      "iteration: 273300 loss: 0.0008 lr: 0.02\n",
      "iteration: 273400 loss: 0.0009 lr: 0.02\n",
      "iteration: 273500 loss: 0.0008 lr: 0.02\n",
      "iteration: 273600 loss: 0.0008 lr: 0.02\n",
      "iteration: 273700 loss: 0.0008 lr: 0.02\n",
      "iteration: 273800 loss: 0.0007 lr: 0.02\n",
      "iteration: 273900 loss: 0.0009 lr: 0.02\n",
      "iteration: 274000 loss: 0.0008 lr: 0.02\n",
      "iteration: 274100 loss: 0.0009 lr: 0.02\n",
      "iteration: 274200 loss: 0.0009 lr: 0.02\n",
      "iteration: 274300 loss: 0.0009 lr: 0.02\n",
      "iteration: 274400 loss: 0.0009 lr: 0.02\n",
      "iteration: 274500 loss: 0.0010 lr: 0.02\n",
      "iteration: 274600 loss: 0.0011 lr: 0.02\n",
      "iteration: 274700 loss: 0.0010 lr: 0.02\n",
      "iteration: 274800 loss: 0.0009 lr: 0.02\n",
      "iteration: 274900 loss: 0.0009 lr: 0.02\n",
      "iteration: 275000 loss: 0.0008 lr: 0.02\n",
      "iteration: 275100 loss: 0.0009 lr: 0.02\n",
      "iteration: 275200 loss: 0.0008 lr: 0.02\n",
      "iteration: 275300 loss: 0.0008 lr: 0.02\n",
      "iteration: 275400 loss: 0.0007 lr: 0.02\n",
      "iteration: 275500 loss: 0.0009 lr: 0.02\n",
      "iteration: 275600 loss: 0.0008 lr: 0.02\n",
      "iteration: 275700 loss: 0.0009 lr: 0.02\n",
      "iteration: 275800 loss: 0.0010 lr: 0.02\n",
      "iteration: 275900 loss: 0.0009 lr: 0.02\n",
      "iteration: 276000 loss: 0.0010 lr: 0.02\n",
      "iteration: 276100 loss: 0.0009 lr: 0.02\n",
      "iteration: 276200 loss: 0.0010 lr: 0.02\n",
      "iteration: 276300 loss: 0.0010 lr: 0.02\n",
      "iteration: 276400 loss: 0.0009 lr: 0.02\n",
      "iteration: 276500 loss: 0.0008 lr: 0.02\n",
      "iteration: 276600 loss: 0.0008 lr: 0.02\n",
      "iteration: 276700 loss: 0.0008 lr: 0.02\n",
      "iteration: 276800 loss: 0.0008 lr: 0.02\n",
      "iteration: 276900 loss: 0.0009 lr: 0.02\n",
      "iteration: 277000 loss: 0.0009 lr: 0.02\n",
      "iteration: 277100 loss: 0.0007 lr: 0.02\n",
      "iteration: 277200 loss: 0.0008 lr: 0.02\n",
      "iteration: 277300 loss: 0.0007 lr: 0.02\n",
      "iteration: 277400 loss: 0.0006 lr: 0.02\n",
      "iteration: 277500 loss: 0.0008 lr: 0.02\n",
      "iteration: 277600 loss: 0.0007 lr: 0.02\n",
      "iteration: 277700 loss: 0.0008 lr: 0.02\n",
      "iteration: 277800 loss: 0.0010 lr: 0.02\n",
      "iteration: 277900 loss: 0.0010 lr: 0.02\n",
      "iteration: 278000 loss: 0.0008 lr: 0.02\n",
      "iteration: 278100 loss: 0.0007 lr: 0.02\n",
      "iteration: 278200 loss: 0.0009 lr: 0.02\n",
      "iteration: 278300 loss: 0.0009 lr: 0.02\n",
      "iteration: 278400 loss: 0.0007 lr: 0.02\n",
      "iteration: 278500 loss: 0.0009 lr: 0.02\n",
      "iteration: 278600 loss: 0.0008 lr: 0.02\n",
      "iteration: 278700 loss: 0.0008 lr: 0.02\n",
      "iteration: 278800 loss: 0.0009 lr: 0.02\n",
      "iteration: 278900 loss: 0.0009 lr: 0.02\n",
      "iteration: 279000 loss: 0.0008 lr: 0.02\n",
      "iteration: 279100 loss: 0.0008 lr: 0.02\n",
      "iteration: 279200 loss: 0.0008 lr: 0.02\n",
      "iteration: 279300 loss: 0.0010 lr: 0.02\n",
      "iteration: 279400 loss: 0.0008 lr: 0.02\n",
      "iteration: 279500 loss: 0.0008 lr: 0.02\n",
      "iteration: 279600 loss: 0.0008 lr: 0.02\n",
      "iteration: 279700 loss: 0.0011 lr: 0.02\n",
      "iteration: 279800 loss: 0.0009 lr: 0.02\n",
      "iteration: 279900 loss: 0.0012 lr: 0.02\n",
      "iteration: 280000 loss: 0.0011 lr: 0.02\n",
      "iteration: 280100 loss: 0.0009 lr: 0.02\n",
      "iteration: 280200 loss: 0.0008 lr: 0.02\n",
      "iteration: 280300 loss: 0.0010 lr: 0.02\n",
      "iteration: 280400 loss: 0.0009 lr: 0.02\n",
      "iteration: 280500 loss: 0.0007 lr: 0.02\n",
      "iteration: 280600 loss: 0.0007 lr: 0.02\n",
      "iteration: 280700 loss: 0.0007 lr: 0.02\n",
      "iteration: 280800 loss: 0.0008 lr: 0.02\n",
      "iteration: 280900 loss: 0.0009 lr: 0.02\n",
      "iteration: 281000 loss: 0.0008 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 281100 loss: 0.0009 lr: 0.02\n",
      "iteration: 281200 loss: 0.0009 lr: 0.02\n",
      "iteration: 281300 loss: 0.0008 lr: 0.02\n",
      "iteration: 281400 loss: 0.0008 lr: 0.02\n",
      "iteration: 281500 loss: 0.0007 lr: 0.02\n",
      "iteration: 281600 loss: 0.0008 lr: 0.02\n",
      "iteration: 281700 loss: 0.0008 lr: 0.02\n",
      "iteration: 281800 loss: 0.0009 lr: 0.02\n",
      "iteration: 281900 loss: 0.0009 lr: 0.02\n",
      "iteration: 282000 loss: 0.0011 lr: 0.02\n",
      "iteration: 282100 loss: 0.0009 lr: 0.02\n",
      "iteration: 282200 loss: 0.0008 lr: 0.02\n",
      "iteration: 282300 loss: 0.0009 lr: 0.02\n",
      "iteration: 282400 loss: 0.0008 lr: 0.02\n",
      "iteration: 282500 loss: 0.0009 lr: 0.02\n",
      "iteration: 282600 loss: 0.0009 lr: 0.02\n",
      "iteration: 282700 loss: 0.0013 lr: 0.02\n",
      "iteration: 282800 loss: 0.0010 lr: 0.02\n",
      "iteration: 282900 loss: 0.0011 lr: 0.02\n",
      "iteration: 283000 loss: 0.0010 lr: 0.02\n",
      "iteration: 283100 loss: 0.0010 lr: 0.02\n",
      "iteration: 283200 loss: 0.0010 lr: 0.02\n",
      "iteration: 283300 loss: 0.0008 lr: 0.02\n",
      "iteration: 283400 loss: 0.0008 lr: 0.02\n",
      "iteration: 283500 loss: 0.0009 lr: 0.02\n",
      "iteration: 283600 loss: 0.0007 lr: 0.02\n",
      "iteration: 283700 loss: 0.0007 lr: 0.02\n",
      "iteration: 283800 loss: 0.0009 lr: 0.02\n",
      "iteration: 283900 loss: 0.0008 lr: 0.02\n",
      "iteration: 284000 loss: 0.0009 lr: 0.02\n",
      "iteration: 284100 loss: 0.0008 lr: 0.02\n",
      "iteration: 284200 loss: 0.0008 lr: 0.02\n",
      "iteration: 284300 loss: 0.0009 lr: 0.02\n",
      "iteration: 284400 loss: 0.0010 lr: 0.02\n",
      "iteration: 284500 loss: 0.0011 lr: 0.02\n",
      "iteration: 284600 loss: 0.0009 lr: 0.02\n",
      "iteration: 284700 loss: 0.0009 lr: 0.02\n",
      "iteration: 284800 loss: 0.0011 lr: 0.02\n",
      "iteration: 284900 loss: 0.0009 lr: 0.02\n",
      "iteration: 285000 loss: 0.0008 lr: 0.02\n",
      "iteration: 285100 loss: 0.0008 lr: 0.02\n",
      "iteration: 285200 loss: 0.0009 lr: 0.02\n",
      "iteration: 285300 loss: 0.0008 lr: 0.02\n",
      "iteration: 285400 loss: 0.0007 lr: 0.02\n",
      "iteration: 285500 loss: 0.0008 lr: 0.02\n",
      "iteration: 285600 loss: 0.0008 lr: 0.02\n",
      "iteration: 285700 loss: 0.0009 lr: 0.02\n",
      "iteration: 285800 loss: 0.0010 lr: 0.02\n",
      "iteration: 285900 loss: 0.0008 lr: 0.02\n",
      "iteration: 286000 loss: 0.0009 lr: 0.02\n",
      "iteration: 286100 loss: 0.0009 lr: 0.02\n",
      "iteration: 286200 loss: 0.0010 lr: 0.02\n",
      "iteration: 286300 loss: 0.0009 lr: 0.02\n",
      "iteration: 286400 loss: 0.0008 lr: 0.02\n",
      "iteration: 286500 loss: 0.0008 lr: 0.02\n",
      "iteration: 286600 loss: 0.0008 lr: 0.02\n",
      "iteration: 286700 loss: 0.0009 lr: 0.02\n",
      "iteration: 286800 loss: 0.0009 lr: 0.02\n",
      "iteration: 286900 loss: 0.0008 lr: 0.02\n",
      "iteration: 287000 loss: 0.0009 lr: 0.02\n",
      "iteration: 287100 loss: 0.0008 lr: 0.02\n",
      "iteration: 287200 loss: 0.0013 lr: 0.02\n",
      "iteration: 287300 loss: 0.0009 lr: 0.02\n",
      "iteration: 287400 loss: 0.0009 lr: 0.02\n",
      "iteration: 287500 loss: 0.0007 lr: 0.02\n",
      "iteration: 287600 loss: 0.0009 lr: 0.02\n",
      "iteration: 287700 loss: 0.0007 lr: 0.02\n",
      "iteration: 287800 loss: 0.0007 lr: 0.02\n",
      "iteration: 287900 loss: 0.0007 lr: 0.02\n",
      "iteration: 288000 loss: 0.0008 lr: 0.02\n",
      "iteration: 288100 loss: 0.0009 lr: 0.02\n",
      "iteration: 288200 loss: 0.0008 lr: 0.02\n",
      "iteration: 288300 loss: 0.0008 lr: 0.02\n",
      "iteration: 288400 loss: 0.0008 lr: 0.02\n",
      "iteration: 288500 loss: 0.0008 lr: 0.02\n",
      "iteration: 288600 loss: 0.0009 lr: 0.02\n",
      "iteration: 288700 loss: 0.0006 lr: 0.02\n",
      "iteration: 288800 loss: 0.0008 lr: 0.02\n",
      "iteration: 288900 loss: 0.0007 lr: 0.02\n",
      "iteration: 289000 loss: 0.0008 lr: 0.02\n",
      "iteration: 289100 loss: 0.0008 lr: 0.02\n",
      "iteration: 289200 loss: 0.0010 lr: 0.02\n",
      "iteration: 289300 loss: 0.0011 lr: 0.02\n",
      "iteration: 289400 loss: 0.0010 lr: 0.02\n",
      "iteration: 289500 loss: 0.0008 lr: 0.02\n",
      "iteration: 289600 loss: 0.0008 lr: 0.02\n",
      "iteration: 289700 loss: 0.0009 lr: 0.02\n",
      "iteration: 289800 loss: 0.0009 lr: 0.02\n",
      "iteration: 289900 loss: 0.0007 lr: 0.02\n",
      "iteration: 290000 loss: 0.0009 lr: 0.02\n",
      "iteration: 290100 loss: 0.0009 lr: 0.02\n",
      "iteration: 290200 loss: 0.0012 lr: 0.02\n",
      "iteration: 290300 loss: 0.0008 lr: 0.02\n",
      "iteration: 290400 loss: 0.0009 lr: 0.02\n",
      "iteration: 290500 loss: 0.0008 lr: 0.02\n",
      "iteration: 290600 loss: 0.0009 lr: 0.02\n",
      "iteration: 290700 loss: 0.0009 lr: 0.02\n",
      "iteration: 290800 loss: 0.0008 lr: 0.02\n",
      "iteration: 290900 loss: 0.0007 lr: 0.02\n",
      "iteration: 291000 loss: 0.0007 lr: 0.02\n",
      "iteration: 291100 loss: 0.0008 lr: 0.02\n",
      "iteration: 291200 loss: 0.0010 lr: 0.02\n",
      "iteration: 291300 loss: 0.0009 lr: 0.02\n",
      "iteration: 291400 loss: 0.0008 lr: 0.02\n",
      "iteration: 291500 loss: 0.0008 lr: 0.02\n",
      "iteration: 291600 loss: 0.0008 lr: 0.02\n",
      "iteration: 291700 loss: 0.0011 lr: 0.02\n",
      "iteration: 291800 loss: 0.0008 lr: 0.02\n",
      "iteration: 291900 loss: 0.0008 lr: 0.02\n",
      "iteration: 292000 loss: 0.0009 lr: 0.02\n",
      "iteration: 292100 loss: 0.0008 lr: 0.02\n",
      "iteration: 292200 loss: 0.0008 lr: 0.02\n",
      "iteration: 292300 loss: 0.0008 lr: 0.02\n",
      "iteration: 292400 loss: 0.0008 lr: 0.02\n",
      "iteration: 292500 loss: 0.0009 lr: 0.02\n",
      "iteration: 292600 loss: 0.0007 lr: 0.02\n",
      "iteration: 292700 loss: 0.0009 lr: 0.02\n",
      "iteration: 292800 loss: 0.0007 lr: 0.02\n",
      "iteration: 292900 loss: 0.0008 lr: 0.02\n",
      "iteration: 293000 loss: 0.0007 lr: 0.02\n",
      "iteration: 293100 loss: 0.0008 lr: 0.02\n",
      "iteration: 293200 loss: 0.0007 lr: 0.02\n",
      "iteration: 293300 loss: 0.0009 lr: 0.02\n",
      "iteration: 293400 loss: 0.0009 lr: 0.02\n",
      "iteration: 293500 loss: 0.0009 lr: 0.02\n",
      "iteration: 293600 loss: 0.0008 lr: 0.02\n",
      "iteration: 293700 loss: 0.0008 lr: 0.02\n",
      "iteration: 293800 loss: 0.0008 lr: 0.02\n",
      "iteration: 293900 loss: 0.0007 lr: 0.02\n",
      "iteration: 294000 loss: 0.0009 lr: 0.02\n",
      "iteration: 294100 loss: 0.0009 lr: 0.02\n",
      "iteration: 294200 loss: 0.0008 lr: 0.02\n",
      "iteration: 294300 loss: 0.0009 lr: 0.02\n",
      "iteration: 294400 loss: 0.0009 lr: 0.02\n",
      "iteration: 294500 loss: 0.0009 lr: 0.02\n",
      "iteration: 294600 loss: 0.0009 lr: 0.02\n",
      "iteration: 294700 loss: 0.0010 lr: 0.02\n",
      "iteration: 294800 loss: 0.0009 lr: 0.02\n",
      "iteration: 294900 loss: 0.0009 lr: 0.02\n",
      "iteration: 295000 loss: 0.0009 lr: 0.02\n",
      "iteration: 295100 loss: 0.0010 lr: 0.02\n",
      "iteration: 295200 loss: 0.0009 lr: 0.02\n",
      "iteration: 295300 loss: 0.0010 lr: 0.02\n",
      "iteration: 295400 loss: 0.0009 lr: 0.02\n",
      "iteration: 295500 loss: 0.0008 lr: 0.02\n",
      "iteration: 295600 loss: 0.0008 lr: 0.02\n",
      "iteration: 295700 loss: 0.0008 lr: 0.02\n",
      "iteration: 295800 loss: 0.0009 lr: 0.02\n",
      "iteration: 295900 loss: 0.0010 lr: 0.02\n",
      "iteration: 296000 loss: 0.0009 lr: 0.02\n",
      "iteration: 296100 loss: 0.0008 lr: 0.02\n",
      "iteration: 296200 loss: 0.0008 lr: 0.02\n",
      "iteration: 296300 loss: 0.0007 lr: 0.02\n",
      "iteration: 296400 loss: 0.0008 lr: 0.02\n",
      "iteration: 296500 loss: 0.0008 lr: 0.02\n",
      "iteration: 296600 loss: 0.0009 lr: 0.02\n",
      "iteration: 296700 loss: 0.0009 lr: 0.02\n",
      "iteration: 296800 loss: 0.0008 lr: 0.02\n",
      "iteration: 296900 loss: 0.0008 lr: 0.02\n",
      "iteration: 297000 loss: 0.0009 lr: 0.02\n",
      "iteration: 297100 loss: 0.0009 lr: 0.02\n",
      "iteration: 297200 loss: 0.0009 lr: 0.02\n",
      "iteration: 297300 loss: 0.0011 lr: 0.02\n",
      "iteration: 297400 loss: 0.0009 lr: 0.02\n",
      "iteration: 297500 loss: 0.0008 lr: 0.02\n",
      "iteration: 297600 loss: 0.0007 lr: 0.02\n",
      "iteration: 297700 loss: 0.0009 lr: 0.02\n",
      "iteration: 297800 loss: 0.0008 lr: 0.02\n",
      "iteration: 297900 loss: 0.0008 lr: 0.02\n",
      "iteration: 298000 loss: 0.0008 lr: 0.02\n",
      "iteration: 298100 loss: 0.0009 lr: 0.02\n",
      "iteration: 298200 loss: 0.0009 lr: 0.02\n",
      "iteration: 298300 loss: 0.0010 lr: 0.02\n",
      "iteration: 298400 loss: 0.0009 lr: 0.02\n",
      "iteration: 298500 loss: 0.0011 lr: 0.02\n",
      "iteration: 298600 loss: 0.0008 lr: 0.02\n",
      "iteration: 298700 loss: 0.0008 lr: 0.02\n",
      "iteration: 298800 loss: 0.0011 lr: 0.02\n",
      "iteration: 298900 loss: 0.0008 lr: 0.02\n",
      "iteration: 299000 loss: 0.0009 lr: 0.02\n",
      "iteration: 299100 loss: 0.0008 lr: 0.02\n",
      "iteration: 299200 loss: 0.0007 lr: 0.02\n",
      "iteration: 299300 loss: 0.0007 lr: 0.02\n",
      "iteration: 299400 loss: 0.0008 lr: 0.02\n",
      "iteration: 299500 loss: 0.0008 lr: 0.02\n",
      "iteration: 299600 loss: 0.0008 lr: 0.02\n",
      "iteration: 299700 loss: 0.0009 lr: 0.02\n",
      "iteration: 299800 loss: 0.0008 lr: 0.02\n",
      "iteration: 299900 loss: 0.0016 lr: 0.02\n",
      "iteration: 300000 loss: 0.0027 lr: 0.02\n",
      "iteration: 300100 loss: 0.0014 lr: 0.02\n",
      "iteration: 300200 loss: 0.0010 lr: 0.02\n",
      "iteration: 300300 loss: 0.0010 lr: 0.02\n",
      "iteration: 300400 loss: 0.0009 lr: 0.02\n",
      "iteration: 300500 loss: 0.0009 lr: 0.02\n",
      "iteration: 300600 loss: 0.0008 lr: 0.02\n",
      "iteration: 300700 loss: 0.0014 lr: 0.02\n",
      "iteration: 300800 loss: 0.0011 lr: 0.02\n",
      "iteration: 300900 loss: 0.0009 lr: 0.02\n",
      "iteration: 301000 loss: 0.0009 lr: 0.02\n",
      "iteration: 301100 loss: 0.0008 lr: 0.02\n",
      "iteration: 301200 loss: 0.0007 lr: 0.02\n",
      "iteration: 301300 loss: 0.0007 lr: 0.02\n",
      "iteration: 301400 loss: 0.0008 lr: 0.02\n",
      "iteration: 301500 loss: 0.0008 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 301600 loss: 0.0008 lr: 0.02\n",
      "iteration: 301700 loss: 0.0009 lr: 0.02\n",
      "iteration: 301800 loss: 0.0007 lr: 0.02\n",
      "iteration: 301900 loss: 0.0008 lr: 0.02\n",
      "iteration: 302000 loss: 0.0008 lr: 0.02\n",
      "iteration: 302100 loss: 0.0009 lr: 0.02\n",
      "iteration: 302200 loss: 0.0009 lr: 0.02\n",
      "iteration: 302300 loss: 0.0008 lr: 0.02\n",
      "iteration: 302400 loss: 0.0008 lr: 0.02\n",
      "iteration: 302500 loss: 0.0009 lr: 0.02\n",
      "iteration: 302600 loss: 0.0010 lr: 0.02\n",
      "iteration: 302700 loss: 0.0010 lr: 0.02\n",
      "iteration: 302800 loss: 0.0009 lr: 0.02\n",
      "iteration: 302900 loss: 0.0007 lr: 0.02\n",
      "iteration: 303000 loss: 0.0008 lr: 0.02\n",
      "iteration: 303100 loss: 0.0007 lr: 0.02\n",
      "iteration: 303200 loss: 0.0009 lr: 0.02\n",
      "iteration: 303300 loss: 0.0008 lr: 0.02\n",
      "iteration: 303400 loss: 0.0007 lr: 0.02\n",
      "iteration: 303500 loss: 0.0007 lr: 0.02\n",
      "iteration: 303600 loss: 0.0009 lr: 0.02\n",
      "iteration: 303700 loss: 0.0011 lr: 0.02\n",
      "iteration: 303800 loss: 0.0008 lr: 0.02\n",
      "iteration: 303900 loss: 0.0009 lr: 0.02\n",
      "iteration: 304000 loss: 0.0010 lr: 0.02\n",
      "iteration: 304100 loss: 0.0007 lr: 0.02\n",
      "iteration: 304200 loss: 0.0008 lr: 0.02\n",
      "iteration: 304300 loss: 0.0007 lr: 0.02\n",
      "iteration: 304400 loss: 0.0007 lr: 0.02\n",
      "iteration: 304500 loss: 0.0009 lr: 0.02\n",
      "iteration: 304600 loss: 0.0008 lr: 0.02\n",
      "iteration: 304700 loss: 0.0007 lr: 0.02\n",
      "iteration: 304800 loss: 0.0008 lr: 0.02\n",
      "iteration: 304900 loss: 0.0006 lr: 0.02\n",
      "iteration: 305000 loss: 0.0008 lr: 0.02\n",
      "iteration: 305100 loss: 0.0009 lr: 0.02\n",
      "iteration: 305200 loss: 0.0009 lr: 0.02\n",
      "iteration: 305300 loss: 0.0009 lr: 0.02\n",
      "iteration: 305400 loss: 0.0009 lr: 0.02\n",
      "iteration: 305500 loss: 0.0008 lr: 0.02\n",
      "iteration: 305600 loss: 0.0009 lr: 0.02\n",
      "iteration: 305700 loss: 0.0008 lr: 0.02\n",
      "iteration: 305800 loss: 0.0007 lr: 0.02\n",
      "iteration: 305900 loss: 0.0007 lr: 0.02\n",
      "iteration: 306000 loss: 0.0009 lr: 0.02\n",
      "iteration: 306100 loss: 0.0009 lr: 0.02\n",
      "iteration: 306200 loss: 0.0010 lr: 0.02\n",
      "iteration: 306300 loss: 0.0009 lr: 0.02\n",
      "iteration: 306400 loss: 0.0007 lr: 0.02\n",
      "iteration: 306500 loss: 0.0008 lr: 0.02\n",
      "iteration: 306600 loss: 0.0009 lr: 0.02\n",
      "iteration: 306700 loss: 0.0008 lr: 0.02\n",
      "iteration: 306800 loss: 0.0009 lr: 0.02\n",
      "iteration: 306900 loss: 0.0008 lr: 0.02\n",
      "iteration: 307000 loss: 0.0008 lr: 0.02\n",
      "iteration: 307100 loss: 0.0009 lr: 0.02\n",
      "iteration: 307200 loss: 0.0008 lr: 0.02\n",
      "iteration: 307300 loss: 0.0008 lr: 0.02\n",
      "iteration: 307400 loss: 0.0007 lr: 0.02\n",
      "iteration: 307500 loss: 0.0007 lr: 0.02\n",
      "iteration: 307600 loss: 0.0010 lr: 0.02\n",
      "iteration: 307700 loss: 0.0007 lr: 0.02\n",
      "iteration: 307800 loss: 0.0011 lr: 0.02\n",
      "iteration: 307900 loss: 0.0012 lr: 0.02\n",
      "iteration: 308000 loss: 0.0010 lr: 0.02\n",
      "iteration: 308100 loss: 0.0014 lr: 0.02\n",
      "iteration: 308200 loss: 0.0019 lr: 0.02\n",
      "iteration: 308300 loss: 0.0009 lr: 0.02\n",
      "iteration: 308400 loss: 0.0009 lr: 0.02\n",
      "iteration: 308500 loss: 0.0008 lr: 0.02\n",
      "iteration: 308600 loss: 0.0010 lr: 0.02\n",
      "iteration: 308700 loss: 0.0017 lr: 0.02\n",
      "iteration: 308800 loss: 0.0009 lr: 0.02\n",
      "iteration: 308900 loss: 0.0010 lr: 0.02\n",
      "iteration: 309000 loss: 0.0011 lr: 0.02\n",
      "iteration: 309100 loss: 0.0009 lr: 0.02\n",
      "iteration: 309200 loss: 0.0010 lr: 0.02\n",
      "iteration: 309300 loss: 0.0009 lr: 0.02\n",
      "iteration: 309400 loss: 0.0009 lr: 0.02\n",
      "iteration: 309500 loss: 0.0008 lr: 0.02\n",
      "iteration: 309600 loss: 0.0007 lr: 0.02\n",
      "iteration: 309700 loss: 0.0009 lr: 0.02\n",
      "iteration: 309800 loss: 0.0011 lr: 0.02\n",
      "iteration: 309900 loss: 0.0011 lr: 0.02\n",
      "iteration: 310000 loss: 0.0008 lr: 0.02\n",
      "iteration: 310100 loss: 0.0009 lr: 0.02\n",
      "iteration: 310200 loss: 0.0007 lr: 0.02\n",
      "iteration: 310300 loss: 0.0007 lr: 0.02\n",
      "iteration: 310400 loss: 0.0009 lr: 0.02\n",
      "iteration: 310500 loss: 0.0008 lr: 0.02\n",
      "iteration: 310600 loss: 0.0008 lr: 0.02\n",
      "iteration: 310700 loss: 0.0008 lr: 0.02\n",
      "iteration: 310800 loss: 0.0009 lr: 0.02\n",
      "iteration: 310900 loss: 0.0008 lr: 0.02\n",
      "iteration: 311000 loss: 0.0008 lr: 0.02\n",
      "iteration: 311100 loss: 0.0009 lr: 0.02\n",
      "iteration: 311200 loss: 0.0007 lr: 0.02\n",
      "iteration: 311300 loss: 0.0008 lr: 0.02\n",
      "iteration: 311400 loss: 0.0009 lr: 0.02\n",
      "iteration: 311500 loss: 0.0008 lr: 0.02\n",
      "iteration: 311600 loss: 0.0010 lr: 0.02\n",
      "iteration: 311700 loss: 0.0008 lr: 0.02\n",
      "iteration: 311800 loss: 0.0009 lr: 0.02\n",
      "iteration: 311900 loss: 0.0009 lr: 0.02\n",
      "iteration: 312000 loss: 0.0007 lr: 0.02\n",
      "iteration: 312100 loss: 0.0008 lr: 0.02\n",
      "iteration: 312200 loss: 0.0008 lr: 0.02\n",
      "iteration: 312300 loss: 0.0009 lr: 0.02\n",
      "iteration: 312400 loss: 0.0010 lr: 0.02\n",
      "iteration: 312500 loss: 0.0007 lr: 0.02\n",
      "iteration: 312600 loss: 0.0009 lr: 0.02\n",
      "iteration: 312700 loss: 0.0007 lr: 0.02\n",
      "iteration: 312800 loss: 0.0007 lr: 0.02\n",
      "iteration: 312900 loss: 0.0009 lr: 0.02\n",
      "iteration: 313000 loss: 0.0009 lr: 0.02\n",
      "iteration: 313100 loss: 0.0007 lr: 0.02\n",
      "iteration: 313200 loss: 0.0007 lr: 0.02\n",
      "iteration: 313300 loss: 0.0008 lr: 0.02\n",
      "iteration: 313400 loss: 0.0008 lr: 0.02\n",
      "iteration: 313500 loss: 0.0007 lr: 0.02\n",
      "iteration: 313600 loss: 0.0010 lr: 0.02\n",
      "iteration: 313700 loss: 0.0010 lr: 0.02\n",
      "iteration: 313800 loss: 0.0009 lr: 0.02\n",
      "iteration: 313900 loss: 0.0009 lr: 0.02\n",
      "iteration: 314000 loss: 0.0014 lr: 0.02\n",
      "iteration: 314100 loss: 0.0012 lr: 0.02\n",
      "iteration: 314200 loss: 0.0010 lr: 0.02\n",
      "iteration: 314300 loss: 0.0008 lr: 0.02\n",
      "iteration: 314400 loss: 0.0008 lr: 0.02\n",
      "iteration: 314500 loss: 0.0008 lr: 0.02\n",
      "iteration: 314600 loss: 0.0009 lr: 0.02\n",
      "iteration: 314700 loss: 0.0009 lr: 0.02\n",
      "iteration: 314800 loss: 0.0009 lr: 0.02\n",
      "iteration: 314900 loss: 0.0007 lr: 0.02\n",
      "iteration: 315000 loss: 0.0008 lr: 0.02\n",
      "iteration: 315100 loss: 0.0007 lr: 0.02\n",
      "iteration: 315200 loss: 0.0010 lr: 0.02\n",
      "iteration: 315300 loss: 0.0008 lr: 0.02\n",
      "iteration: 315400 loss: 0.0009 lr: 0.02\n",
      "iteration: 315500 loss: 0.0009 lr: 0.02\n",
      "iteration: 315600 loss: 0.0010 lr: 0.02\n",
      "iteration: 315700 loss: 0.0009 lr: 0.02\n",
      "iteration: 315800 loss: 0.0009 lr: 0.02\n",
      "iteration: 315900 loss: 0.0008 lr: 0.02\n",
      "iteration: 316000 loss: 0.0008 lr: 0.02\n",
      "iteration: 316100 loss: 0.0010 lr: 0.02\n",
      "iteration: 316200 loss: 0.0009 lr: 0.02\n",
      "iteration: 316300 loss: 0.0011 lr: 0.02\n",
      "iteration: 316400 loss: 0.0009 lr: 0.02\n",
      "iteration: 316500 loss: 0.0009 lr: 0.02\n",
      "iteration: 316600 loss: 0.0009 lr: 0.02\n",
      "iteration: 316700 loss: 0.0010 lr: 0.02\n",
      "iteration: 316800 loss: 0.0008 lr: 0.02\n",
      "iteration: 316900 loss: 0.0007 lr: 0.02\n",
      "iteration: 317000 loss: 0.0008 lr: 0.02\n",
      "iteration: 317100 loss: 0.0009 lr: 0.02\n",
      "iteration: 317200 loss: 0.0008 lr: 0.02\n",
      "iteration: 317300 loss: 0.0007 lr: 0.02\n",
      "iteration: 317400 loss: 0.0008 lr: 0.02\n",
      "iteration: 317500 loss: 0.0007 lr: 0.02\n",
      "iteration: 317600 loss: 0.0009 lr: 0.02\n",
      "iteration: 317700 loss: 0.0009 lr: 0.02\n",
      "iteration: 317800 loss: 0.0008 lr: 0.02\n",
      "iteration: 317900 loss: 0.0007 lr: 0.02\n",
      "iteration: 318000 loss: 0.0007 lr: 0.02\n",
      "iteration: 318100 loss: 0.0008 lr: 0.02\n",
      "iteration: 318200 loss: 0.0010 lr: 0.02\n",
      "iteration: 318300 loss: 0.0010 lr: 0.02\n",
      "iteration: 318400 loss: 0.0010 lr: 0.02\n",
      "iteration: 318500 loss: 0.0009 lr: 0.02\n",
      "iteration: 318600 loss: 0.0008 lr: 0.02\n",
      "iteration: 318700 loss: 0.0010 lr: 0.02\n",
      "iteration: 318800 loss: 0.0008 lr: 0.02\n",
      "iteration: 318900 loss: 0.0007 lr: 0.02\n",
      "iteration: 319000 loss: 0.0009 lr: 0.02\n",
      "iteration: 319100 loss: 0.0008 lr: 0.02\n",
      "iteration: 319200 loss: 0.0010 lr: 0.02\n",
      "iteration: 319300 loss: 0.0008 lr: 0.02\n",
      "iteration: 319400 loss: 0.0006 lr: 0.02\n",
      "iteration: 319500 loss: 0.0009 lr: 0.02\n",
      "iteration: 319600 loss: 0.0009 lr: 0.02\n",
      "iteration: 319700 loss: 0.0010 lr: 0.02\n",
      "iteration: 319800 loss: 0.0010 lr: 0.02\n",
      "iteration: 319900 loss: 0.0008 lr: 0.02\n",
      "iteration: 320000 loss: 0.0009 lr: 0.02\n",
      "iteration: 320100 loss: 0.0010 lr: 0.02\n",
      "iteration: 320200 loss: 0.0009 lr: 0.02\n",
      "iteration: 320300 loss: 0.0008 lr: 0.02\n",
      "iteration: 320400 loss: 0.0010 lr: 0.02\n",
      "iteration: 320500 loss: 0.0009 lr: 0.02\n",
      "iteration: 320600 loss: 0.0008 lr: 0.02\n",
      "iteration: 320700 loss: 0.0008 lr: 0.02\n",
      "iteration: 320800 loss: 0.0008 lr: 0.02\n",
      "iteration: 320900 loss: 0.0007 lr: 0.02\n",
      "iteration: 321000 loss: 0.0008 lr: 0.02\n",
      "iteration: 321100 loss: 0.0009 lr: 0.02\n",
      "iteration: 321200 loss: 0.0007 lr: 0.02\n",
      "iteration: 321300 loss: 0.0009 lr: 0.02\n",
      "iteration: 321400 loss: 0.0009 lr: 0.02\n",
      "iteration: 321500 loss: 0.0008 lr: 0.02\n",
      "iteration: 321600 loss: 0.0007 lr: 0.02\n",
      "iteration: 321700 loss: 0.0009 lr: 0.02\n",
      "iteration: 321800 loss: 0.0008 lr: 0.02\n",
      "iteration: 321900 loss: 0.0010 lr: 0.02\n",
      "iteration: 322000 loss: 0.0009 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 322100 loss: 0.0008 lr: 0.02\n",
      "iteration: 322200 loss: 0.0009 lr: 0.02\n",
      "iteration: 322300 loss: 0.0008 lr: 0.02\n",
      "iteration: 322400 loss: 0.0008 lr: 0.02\n",
      "iteration: 322500 loss: 0.0007 lr: 0.02\n",
      "iteration: 322600 loss: 0.0009 lr: 0.02\n",
      "iteration: 322700 loss: 0.0008 lr: 0.02\n",
      "iteration: 322800 loss: 0.0008 lr: 0.02\n",
      "iteration: 322900 loss: 0.0008 lr: 0.02\n",
      "iteration: 323000 loss: 0.0008 lr: 0.02\n",
      "iteration: 323100 loss: 0.0008 lr: 0.02\n",
      "iteration: 323200 loss: 0.0007 lr: 0.02\n",
      "iteration: 323300 loss: 0.0007 lr: 0.02\n",
      "iteration: 323400 loss: 0.0009 lr: 0.02\n",
      "iteration: 323500 loss: 0.0010 lr: 0.02\n",
      "iteration: 323600 loss: 0.0008 lr: 0.02\n",
      "iteration: 323700 loss: 0.0012 lr: 0.02\n",
      "iteration: 323800 loss: 0.0011 lr: 0.02\n",
      "iteration: 323900 loss: 0.0009 lr: 0.02\n",
      "iteration: 324000 loss: 0.0008 lr: 0.02\n",
      "iteration: 324100 loss: 0.0010 lr: 0.02\n",
      "iteration: 324200 loss: 0.0008 lr: 0.02\n",
      "iteration: 324300 loss: 0.0009 lr: 0.02\n",
      "iteration: 324400 loss: 0.0011 lr: 0.02\n",
      "iteration: 324500 loss: 0.0010 lr: 0.02\n",
      "iteration: 324600 loss: 0.0008 lr: 0.02\n",
      "iteration: 324700 loss: 0.0009 lr: 0.02\n",
      "iteration: 324800 loss: 0.0010 lr: 0.02\n",
      "iteration: 324900 loss: 0.0008 lr: 0.02\n",
      "iteration: 325000 loss: 0.0009 lr: 0.02\n",
      "iteration: 325100 loss: 0.0009 lr: 0.02\n",
      "iteration: 325200 loss: 0.0009 lr: 0.02\n",
      "iteration: 325300 loss: 0.0008 lr: 0.02\n",
      "iteration: 325400 loss: 0.0007 lr: 0.02\n",
      "iteration: 325500 loss: 0.0007 lr: 0.02\n",
      "iteration: 325600 loss: 0.0009 lr: 0.02\n",
      "iteration: 325700 loss: 0.0011 lr: 0.02\n",
      "iteration: 325800 loss: 0.0014 lr: 0.02\n",
      "iteration: 325900 loss: 0.0009 lr: 0.02\n",
      "iteration: 326000 loss: 0.0007 lr: 0.02\n",
      "iteration: 326100 loss: 0.0009 lr: 0.02\n",
      "iteration: 326200 loss: 0.0008 lr: 0.02\n",
      "iteration: 326300 loss: 0.0007 lr: 0.02\n",
      "iteration: 326400 loss: 0.0008 lr: 0.02\n",
      "iteration: 326500 loss: 0.0011 lr: 0.02\n",
      "iteration: 326600 loss: 0.0010 lr: 0.02\n",
      "iteration: 326700 loss: 0.0008 lr: 0.02\n",
      "iteration: 326800 loss: 0.0008 lr: 0.02\n",
      "iteration: 326900 loss: 0.0008 lr: 0.02\n",
      "iteration: 327000 loss: 0.0009 lr: 0.02\n",
      "iteration: 327100 loss: 0.0009 lr: 0.02\n",
      "iteration: 327200 loss: 0.0010 lr: 0.02\n",
      "iteration: 327300 loss: 0.0009 lr: 0.02\n",
      "iteration: 327400 loss: 0.0008 lr: 0.02\n",
      "iteration: 327500 loss: 0.0010 lr: 0.02\n",
      "iteration: 327600 loss: 0.0009 lr: 0.02\n",
      "iteration: 327700 loss: 0.0027 lr: 0.02\n",
      "iteration: 327800 loss: 0.0018 lr: 0.02\n",
      "iteration: 327900 loss: 0.0009 lr: 0.02\n",
      "iteration: 328000 loss: 0.0010 lr: 0.02\n",
      "iteration: 328100 loss: 0.0018 lr: 0.02\n",
      "iteration: 328200 loss: 0.0011 lr: 0.02\n",
      "iteration: 328300 loss: 0.0013 lr: 0.02\n",
      "iteration: 328400 loss: 0.0012 lr: 0.02\n",
      "iteration: 328500 loss: 0.0011 lr: 0.02\n",
      "iteration: 328600 loss: 0.0009 lr: 0.02\n",
      "iteration: 328700 loss: 0.0008 lr: 0.02\n",
      "iteration: 328800 loss: 0.0009 lr: 0.02\n",
      "iteration: 328900 loss: 0.0009 lr: 0.02\n",
      "iteration: 329000 loss: 0.0009 lr: 0.02\n",
      "iteration: 329100 loss: 0.0008 lr: 0.02\n",
      "iteration: 329200 loss: 0.0007 lr: 0.02\n",
      "iteration: 329300 loss: 0.0008 lr: 0.02\n",
      "iteration: 329400 loss: 0.0008 lr: 0.02\n",
      "iteration: 329500 loss: 0.0009 lr: 0.02\n",
      "iteration: 329600 loss: 0.0007 lr: 0.02\n",
      "iteration: 329700 loss: 0.0008 lr: 0.02\n",
      "iteration: 329800 loss: 0.0009 lr: 0.02\n",
      "iteration: 329900 loss: 0.0009 lr: 0.02\n",
      "iteration: 330000 loss: 0.0009 lr: 0.02\n",
      "iteration: 330100 loss: 0.0008 lr: 0.02\n",
      "iteration: 330200 loss: 0.0008 lr: 0.02\n",
      "iteration: 330300 loss: 0.0008 lr: 0.02\n",
      "iteration: 330400 loss: 0.0007 lr: 0.02\n",
      "iteration: 330500 loss: 0.0007 lr: 0.02\n",
      "iteration: 330600 loss: 0.0009 lr: 0.02\n",
      "iteration: 330700 loss: 0.0007 lr: 0.02\n",
      "iteration: 330800 loss: 0.0011 lr: 0.02\n",
      "iteration: 330900 loss: 0.0008 lr: 0.02\n",
      "iteration: 331000 loss: 0.0007 lr: 0.02\n",
      "iteration: 331100 loss: 0.0008 lr: 0.02\n",
      "iteration: 331200 loss: 0.0008 lr: 0.02\n",
      "iteration: 331300 loss: 0.0008 lr: 0.02\n",
      "iteration: 331400 loss: 0.0007 lr: 0.02\n",
      "iteration: 331500 loss: 0.0008 lr: 0.02\n",
      "iteration: 331600 loss: 0.0008 lr: 0.02\n",
      "iteration: 331700 loss: 0.0009 lr: 0.02\n",
      "iteration: 331800 loss: 0.0009 lr: 0.02\n",
      "iteration: 331900 loss: 0.0008 lr: 0.02\n",
      "iteration: 332000 loss: 0.0009 lr: 0.02\n",
      "iteration: 332100 loss: 0.0007 lr: 0.02\n",
      "iteration: 332200 loss: 0.0008 lr: 0.02\n",
      "iteration: 332300 loss: 0.0009 lr: 0.02\n",
      "iteration: 332400 loss: 0.0009 lr: 0.02\n",
      "iteration: 332500 loss: 0.0009 lr: 0.02\n",
      "iteration: 332600 loss: 0.0008 lr: 0.02\n",
      "iteration: 332700 loss: 0.0008 lr: 0.02\n",
      "iteration: 332800 loss: 0.0009 lr: 0.02\n",
      "iteration: 332900 loss: 0.0012 lr: 0.02\n",
      "iteration: 333000 loss: 0.0009 lr: 0.02\n",
      "iteration: 333100 loss: 0.0008 lr: 0.02\n",
      "iteration: 333200 loss: 0.0008 lr: 0.02\n",
      "iteration: 333300 loss: 0.0007 lr: 0.02\n",
      "iteration: 333400 loss: 0.0009 lr: 0.02\n",
      "iteration: 333500 loss: 0.0009 lr: 0.02\n",
      "iteration: 333600 loss: 0.0008 lr: 0.02\n",
      "iteration: 333700 loss: 0.0007 lr: 0.02\n",
      "iteration: 333800 loss: 0.0009 lr: 0.02\n",
      "iteration: 333900 loss: 0.0007 lr: 0.02\n",
      "iteration: 334000 loss: 0.0007 lr: 0.02\n",
      "iteration: 334100 loss: 0.0009 lr: 0.02\n",
      "iteration: 334200 loss: 0.0009 lr: 0.02\n",
      "iteration: 334300 loss: 0.0008 lr: 0.02\n",
      "iteration: 334400 loss: 0.0008 lr: 0.02\n",
      "iteration: 334500 loss: 0.0006 lr: 0.02\n",
      "iteration: 334600 loss: 0.0008 lr: 0.02\n",
      "iteration: 334700 loss: 0.0008 lr: 0.02\n",
      "iteration: 334800 loss: 0.0008 lr: 0.02\n",
      "iteration: 334900 loss: 0.0008 lr: 0.02\n",
      "iteration: 335000 loss: 0.0008 lr: 0.02\n",
      "iteration: 335100 loss: 0.0009 lr: 0.02\n",
      "iteration: 335200 loss: 0.0008 lr: 0.02\n",
      "iteration: 335300 loss: 0.0007 lr: 0.02\n",
      "iteration: 335400 loss: 0.0006 lr: 0.02\n",
      "iteration: 335500 loss: 0.0007 lr: 0.02\n",
      "iteration: 335600 loss: 0.0008 lr: 0.02\n",
      "iteration: 335700 loss: 0.0008 lr: 0.02\n",
      "iteration: 335800 loss: 0.0008 lr: 0.02\n",
      "iteration: 335900 loss: 0.0007 lr: 0.02\n",
      "iteration: 336000 loss: 0.0007 lr: 0.02\n",
      "iteration: 336100 loss: 0.0009 lr: 0.02\n",
      "iteration: 336200 loss: 0.0008 lr: 0.02\n",
      "iteration: 336300 loss: 0.0008 lr: 0.02\n",
      "iteration: 336400 loss: 0.0008 lr: 0.02\n",
      "iteration: 336500 loss: 0.0007 lr: 0.02\n",
      "iteration: 336600 loss: 0.0007 lr: 0.02\n",
      "iteration: 336700 loss: 0.0007 lr: 0.02\n",
      "iteration: 336800 loss: 0.0008 lr: 0.02\n",
      "iteration: 336900 loss: 0.0008 lr: 0.02\n",
      "iteration: 337000 loss: 0.0009 lr: 0.02\n",
      "iteration: 337100 loss: 0.0008 lr: 0.02\n",
      "iteration: 337200 loss: 0.0008 lr: 0.02\n",
      "iteration: 337300 loss: 0.0008 lr: 0.02\n",
      "iteration: 337400 loss: 0.0008 lr: 0.02\n",
      "iteration: 337500 loss: 0.0008 lr: 0.02\n",
      "iteration: 337600 loss: 0.0007 lr: 0.02\n",
      "iteration: 337700 loss: 0.0006 lr: 0.02\n",
      "iteration: 337800 loss: 0.0007 lr: 0.02\n",
      "iteration: 337900 loss: 0.0008 lr: 0.02\n",
      "iteration: 338000 loss: 0.0008 lr: 0.02\n",
      "iteration: 338100 loss: 0.0010 lr: 0.02\n",
      "iteration: 338200 loss: 0.0007 lr: 0.02\n",
      "iteration: 338300 loss: 0.0008 lr: 0.02\n",
      "iteration: 338400 loss: 0.0010 lr: 0.02\n",
      "iteration: 338500 loss: 0.0008 lr: 0.02\n",
      "iteration: 338600 loss: 0.0007 lr: 0.02\n",
      "iteration: 338700 loss: 0.0007 lr: 0.02\n",
      "iteration: 338800 loss: 0.0009 lr: 0.02\n",
      "iteration: 338900 loss: 0.0009 lr: 0.02\n",
      "iteration: 339000 loss: 0.0008 lr: 0.02\n",
      "iteration: 339100 loss: 0.0008 lr: 0.02\n",
      "iteration: 339200 loss: 0.0007 lr: 0.02\n",
      "iteration: 339300 loss: 0.0007 lr: 0.02\n",
      "iteration: 339400 loss: 0.0007 lr: 0.02\n",
      "iteration: 339500 loss: 0.0008 lr: 0.02\n",
      "iteration: 339600 loss: 0.0008 lr: 0.02\n",
      "iteration: 339700 loss: 0.0008 lr: 0.02\n",
      "iteration: 339800 loss: 0.0008 lr: 0.02\n",
      "iteration: 339900 loss: 0.0007 lr: 0.02\n",
      "iteration: 340000 loss: 0.0007 lr: 0.02\n",
      "iteration: 340100 loss: 0.0009 lr: 0.02\n",
      "iteration: 340200 loss: 0.0007 lr: 0.02\n",
      "iteration: 340300 loss: 0.0006 lr: 0.02\n",
      "iteration: 340400 loss: 0.0008 lr: 0.02\n",
      "iteration: 340500 loss: 0.0009 lr: 0.02\n",
      "iteration: 340600 loss: 0.0007 lr: 0.02\n",
      "iteration: 340700 loss: 0.0009 lr: 0.02\n",
      "iteration: 340800 loss: 0.0009 lr: 0.02\n",
      "iteration: 340900 loss: 0.0007 lr: 0.02\n",
      "iteration: 341000 loss: 0.0009 lr: 0.02\n",
      "iteration: 341100 loss: 0.0009 lr: 0.02\n",
      "iteration: 341200 loss: 0.0008 lr: 0.02\n",
      "iteration: 341300 loss: 0.0008 lr: 0.02\n",
      "iteration: 341400 loss: 0.0008 lr: 0.02\n",
      "iteration: 341500 loss: 0.0008 lr: 0.02\n",
      "iteration: 341600 loss: 0.0007 lr: 0.02\n",
      "iteration: 341700 loss: 0.0009 lr: 0.02\n",
      "iteration: 341800 loss: 0.0007 lr: 0.02\n",
      "iteration: 341900 loss: 0.0007 lr: 0.02\n",
      "iteration: 342000 loss: 0.0008 lr: 0.02\n",
      "iteration: 342100 loss: 0.0008 lr: 0.02\n",
      "iteration: 342200 loss: 0.0008 lr: 0.02\n",
      "iteration: 342300 loss: 0.0008 lr: 0.02\n",
      "iteration: 342400 loss: 0.0008 lr: 0.02\n",
      "iteration: 342500 loss: 0.0009 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 342600 loss: 0.0009 lr: 0.02\n",
      "iteration: 342700 loss: 0.0008 lr: 0.02\n",
      "iteration: 342800 loss: 0.0008 lr: 0.02\n",
      "iteration: 342900 loss: 0.0007 lr: 0.02\n",
      "iteration: 343000 loss: 0.0010 lr: 0.02\n",
      "iteration: 343100 loss: 0.0008 lr: 0.02\n",
      "iteration: 343200 loss: 0.0009 lr: 0.02\n",
      "iteration: 343300 loss: 0.0008 lr: 0.02\n",
      "iteration: 343400 loss: 0.0008 lr: 0.02\n",
      "iteration: 343500 loss: 0.0009 lr: 0.02\n",
      "iteration: 343600 loss: 0.0007 lr: 0.02\n",
      "iteration: 343700 loss: 0.0008 lr: 0.02\n",
      "iteration: 343800 loss: 0.0009 lr: 0.02\n",
      "iteration: 343900 loss: 0.0007 lr: 0.02\n",
      "iteration: 344000 loss: 0.0008 lr: 0.02\n",
      "iteration: 344100 loss: 0.0008 lr: 0.02\n",
      "iteration: 344200 loss: 0.0008 lr: 0.02\n",
      "iteration: 344300 loss: 0.0009 lr: 0.02\n",
      "iteration: 344400 loss: 0.0008 lr: 0.02\n",
      "iteration: 344500 loss: 0.0007 lr: 0.02\n",
      "iteration: 344600 loss: 0.0009 lr: 0.02\n",
      "iteration: 344700 loss: 0.0008 lr: 0.02\n",
      "iteration: 344800 loss: 0.0007 lr: 0.02\n",
      "iteration: 344900 loss: 0.0009 lr: 0.02\n",
      "iteration: 345000 loss: 0.0008 lr: 0.02\n",
      "iteration: 345100 loss: 0.0008 lr: 0.02\n",
      "iteration: 345200 loss: 0.0007 lr: 0.02\n",
      "iteration: 345300 loss: 0.0007 lr: 0.02\n",
      "iteration: 345400 loss: 0.0008 lr: 0.02\n",
      "iteration: 345500 loss: 0.0009 lr: 0.02\n",
      "iteration: 345600 loss: 0.0009 lr: 0.02\n",
      "iteration: 345700 loss: 0.0008 lr: 0.02\n",
      "iteration: 345800 loss: 0.0011 lr: 0.02\n",
      "iteration: 345900 loss: 0.0008 lr: 0.02\n",
      "iteration: 346000 loss: 0.0009 lr: 0.02\n",
      "iteration: 346100 loss: 0.0008 lr: 0.02\n",
      "iteration: 346200 loss: 0.0009 lr: 0.02\n",
      "iteration: 346300 loss: 0.0009 lr: 0.02\n",
      "iteration: 346400 loss: 0.0007 lr: 0.02\n",
      "iteration: 346500 loss: 0.0009 lr: 0.02\n",
      "iteration: 346600 loss: 0.0008 lr: 0.02\n",
      "iteration: 346700 loss: 0.0008 lr: 0.02\n",
      "iteration: 346800 loss: 0.0007 lr: 0.02\n",
      "iteration: 346900 loss: 0.0007 lr: 0.02\n",
      "iteration: 347000 loss: 0.0008 lr: 0.02\n",
      "iteration: 347100 loss: 0.0009 lr: 0.02\n",
      "iteration: 347200 loss: 0.0008 lr: 0.02\n",
      "iteration: 347300 loss: 0.0008 lr: 0.02\n",
      "iteration: 347400 loss: 0.0007 lr: 0.02\n",
      "iteration: 347500 loss: 0.0009 lr: 0.02\n",
      "iteration: 347600 loss: 0.0007 lr: 0.02\n",
      "iteration: 347700 loss: 0.0007 lr: 0.02\n",
      "iteration: 347800 loss: 0.0008 lr: 0.02\n",
      "iteration: 347900 loss: 0.0007 lr: 0.02\n",
      "iteration: 348000 loss: 0.0008 lr: 0.02\n",
      "iteration: 348100 loss: 0.0008 lr: 0.02\n",
      "iteration: 348200 loss: 0.0008 lr: 0.02\n",
      "iteration: 348300 loss: 0.0008 lr: 0.02\n",
      "iteration: 348400 loss: 0.0007 lr: 0.02\n",
      "iteration: 348500 loss: 0.0008 lr: 0.02\n",
      "iteration: 348600 loss: 0.0008 lr: 0.02\n",
      "iteration: 348700 loss: 0.0008 lr: 0.02\n",
      "iteration: 348800 loss: 0.0009 lr: 0.02\n",
      "iteration: 348900 loss: 0.0008 lr: 0.02\n",
      "iteration: 349000 loss: 0.0008 lr: 0.02\n",
      "iteration: 349100 loss: 0.0008 lr: 0.02\n",
      "iteration: 349200 loss: 0.0008 lr: 0.02\n",
      "iteration: 349300 loss: 0.0009 lr: 0.02\n",
      "iteration: 349400 loss: 0.0009 lr: 0.02\n",
      "iteration: 349500 loss: 0.0007 lr: 0.02\n",
      "iteration: 349600 loss: 0.0008 lr: 0.02\n",
      "iteration: 349700 loss: 0.0008 lr: 0.02\n",
      "iteration: 349800 loss: 0.0006 lr: 0.02\n",
      "iteration: 349900 loss: 0.0007 lr: 0.02\n",
      "iteration: 350000 loss: 0.0006 lr: 0.02\n",
      "iteration: 350100 loss: 0.0010 lr: 0.02\n",
      "iteration: 350200 loss: 0.0008 lr: 0.02\n",
      "iteration: 350300 loss: 0.0006 lr: 0.02\n",
      "iteration: 350400 loss: 0.0007 lr: 0.02\n",
      "iteration: 350500 loss: 0.0006 lr: 0.02\n",
      "iteration: 350600 loss: 0.0007 lr: 0.02\n",
      "iteration: 350700 loss: 0.0009 lr: 0.02\n",
      "iteration: 350800 loss: 0.0009 lr: 0.02\n",
      "iteration: 350900 loss: 0.0009 lr: 0.02\n",
      "iteration: 351000 loss: 0.0008 lr: 0.02\n",
      "iteration: 351100 loss: 0.0009 lr: 0.02\n",
      "iteration: 351200 loss: 0.0008 lr: 0.02\n",
      "iteration: 351300 loss: 0.0011 lr: 0.02\n",
      "iteration: 351400 loss: 0.0008 lr: 0.02\n",
      "iteration: 351500 loss: 0.0007 lr: 0.02\n",
      "iteration: 351600 loss: 0.0008 lr: 0.02\n",
      "iteration: 351700 loss: 0.0009 lr: 0.02\n",
      "iteration: 351800 loss: 0.0007 lr: 0.02\n",
      "iteration: 351900 loss: 0.0009 lr: 0.02\n",
      "iteration: 352000 loss: 0.0008 lr: 0.02\n",
      "iteration: 352100 loss: 0.0007 lr: 0.02\n",
      "iteration: 352200 loss: 0.0007 lr: 0.02\n",
      "iteration: 352300 loss: 0.0009 lr: 0.02\n",
      "iteration: 352400 loss: 0.0008 lr: 0.02\n",
      "iteration: 352500 loss: 0.0008 lr: 0.02\n",
      "iteration: 352600 loss: 0.0007 lr: 0.02\n",
      "iteration: 352700 loss: 0.0007 lr: 0.02\n",
      "iteration: 352800 loss: 0.0010 lr: 0.02\n",
      "iteration: 352900 loss: 0.0008 lr: 0.02\n",
      "iteration: 353000 loss: 0.0008 lr: 0.02\n",
      "iteration: 353100 loss: 0.0009 lr: 0.02\n",
      "iteration: 353200 loss: 0.0008 lr: 0.02\n",
      "iteration: 353300 loss: 0.0008 lr: 0.02\n",
      "iteration: 353400 loss: 0.0008 lr: 0.02\n",
      "iteration: 353500 loss: 0.0008 lr: 0.02\n",
      "iteration: 353600 loss: 0.0008 lr: 0.02\n",
      "iteration: 353700 loss: 0.0011 lr: 0.02\n",
      "iteration: 353800 loss: 0.0008 lr: 0.02\n",
      "iteration: 353900 loss: 0.0008 lr: 0.02\n",
      "iteration: 354000 loss: 0.0009 lr: 0.02\n",
      "iteration: 354100 loss: 0.0008 lr: 0.02\n",
      "iteration: 354200 loss: 0.0007 lr: 0.02\n",
      "iteration: 354300 loss: 0.0008 lr: 0.02\n",
      "iteration: 354400 loss: 0.0008 lr: 0.02\n",
      "iteration: 354500 loss: 0.0009 lr: 0.02\n",
      "iteration: 354600 loss: 0.0006 lr: 0.02\n",
      "iteration: 354700 loss: 0.0009 lr: 0.02\n",
      "iteration: 354800 loss: 0.0007 lr: 0.02\n",
      "iteration: 354900 loss: 0.0007 lr: 0.02\n",
      "iteration: 355000 loss: 0.0007 lr: 0.02\n",
      "iteration: 355100 loss: 0.0008 lr: 0.02\n",
      "iteration: 355200 loss: 0.0008 lr: 0.02\n",
      "iteration: 355300 loss: 0.0008 lr: 0.02\n",
      "iteration: 355400 loss: 0.0006 lr: 0.02\n",
      "iteration: 355500 loss: 0.0008 lr: 0.02\n",
      "iteration: 355600 loss: 0.0007 lr: 0.02\n",
      "iteration: 355700 loss: 0.0007 lr: 0.02\n",
      "iteration: 355800 loss: 0.0007 lr: 0.02\n",
      "iteration: 355900 loss: 0.0008 lr: 0.02\n",
      "iteration: 356000 loss: 0.0010 lr: 0.02\n",
      "iteration: 356100 loss: 0.0009 lr: 0.02\n",
      "iteration: 356200 loss: 0.0006 lr: 0.02\n",
      "iteration: 356300 loss: 0.0007 lr: 0.02\n",
      "iteration: 356400 loss: 0.0007 lr: 0.02\n",
      "iteration: 356500 loss: 0.0009 lr: 0.02\n",
      "iteration: 356600 loss: 0.0007 lr: 0.02\n",
      "iteration: 356700 loss: 0.0008 lr: 0.02\n",
      "iteration: 356800 loss: 0.0007 lr: 0.02\n",
      "iteration: 356900 loss: 0.0008 lr: 0.02\n",
      "iteration: 357000 loss: 0.0009 lr: 0.02\n",
      "iteration: 357100 loss: 0.0007 lr: 0.02\n",
      "iteration: 357200 loss: 0.0008 lr: 0.02\n",
      "iteration: 357300 loss: 0.0008 lr: 0.02\n",
      "iteration: 357400 loss: 0.0008 lr: 0.02\n",
      "iteration: 357500 loss: 0.0008 lr: 0.02\n",
      "iteration: 357600 loss: 0.0008 lr: 0.02\n",
      "iteration: 357700 loss: 0.0008 lr: 0.02\n",
      "iteration: 357800 loss: 0.0009 lr: 0.02\n",
      "iteration: 357900 loss: 0.0009 lr: 0.02\n",
      "iteration: 358000 loss: 0.0008 lr: 0.02\n",
      "iteration: 358100 loss: 0.0009 lr: 0.02\n",
      "iteration: 358200 loss: 0.0010 lr: 0.02\n",
      "iteration: 358300 loss: 0.0007 lr: 0.02\n",
      "iteration: 358400 loss: 0.0008 lr: 0.02\n",
      "iteration: 358500 loss: 0.0007 lr: 0.02\n",
      "iteration: 358600 loss: 0.0010 lr: 0.02\n",
      "iteration: 358700 loss: 0.0009 lr: 0.02\n",
      "iteration: 358800 loss: 0.0009 lr: 0.02\n",
      "iteration: 358900 loss: 0.0008 lr: 0.02\n",
      "iteration: 359000 loss: 0.0009 lr: 0.02\n",
      "iteration: 359100 loss: 0.0007 lr: 0.02\n",
      "iteration: 359200 loss: 0.0009 lr: 0.02\n",
      "iteration: 359300 loss: 0.0007 lr: 0.02\n",
      "iteration: 359400 loss: 0.0010 lr: 0.02\n",
      "iteration: 359500 loss: 0.0008 lr: 0.02\n",
      "iteration: 359600 loss: 0.0008 lr: 0.02\n",
      "iteration: 359700 loss: 0.0010 lr: 0.02\n",
      "iteration: 359800 loss: 0.0009 lr: 0.02\n",
      "iteration: 359900 loss: 0.0007 lr: 0.02\n",
      "iteration: 360000 loss: 0.0008 lr: 0.02\n",
      "iteration: 360100 loss: 0.0007 lr: 0.02\n",
      "iteration: 360200 loss: 0.0008 lr: 0.02\n",
      "iteration: 360300 loss: 0.0008 lr: 0.02\n",
      "iteration: 360400 loss: 0.0009 lr: 0.02\n",
      "iteration: 360500 loss: 0.0009 lr: 0.02\n",
      "iteration: 360600 loss: 0.0008 lr: 0.02\n",
      "iteration: 360700 loss: 0.0008 lr: 0.02\n",
      "iteration: 360800 loss: 0.0010 lr: 0.02\n",
      "iteration: 360900 loss: 0.0007 lr: 0.02\n",
      "iteration: 361000 loss: 0.0007 lr: 0.02\n",
      "iteration: 361100 loss: 0.0007 lr: 0.02\n",
      "iteration: 361200 loss: 0.0007 lr: 0.02\n",
      "iteration: 361300 loss: 0.0008 lr: 0.02\n",
      "iteration: 361400 loss: 0.0008 lr: 0.02\n",
      "iteration: 361500 loss: 0.0007 lr: 0.02\n",
      "iteration: 361600 loss: 0.0009 lr: 0.02\n",
      "iteration: 361700 loss: 0.0008 lr: 0.02\n",
      "iteration: 361800 loss: 0.0007 lr: 0.02\n",
      "iteration: 361900 loss: 0.0009 lr: 0.02\n",
      "iteration: 362000 loss: 0.0007 lr: 0.02\n",
      "iteration: 362100 loss: 0.0007 lr: 0.02\n",
      "iteration: 362200 loss: 0.0009 lr: 0.02\n",
      "iteration: 362300 loss: 0.0008 lr: 0.02\n",
      "iteration: 362400 loss: 0.0008 lr: 0.02\n",
      "iteration: 362500 loss: 0.0007 lr: 0.02\n",
      "iteration: 362600 loss: 0.0009 lr: 0.02\n",
      "iteration: 362700 loss: 0.0008 lr: 0.02\n",
      "iteration: 362800 loss: 0.0009 lr: 0.02\n",
      "iteration: 362900 loss: 0.0008 lr: 0.02\n",
      "iteration: 363000 loss: 0.0008 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 363100 loss: 0.0007 lr: 0.02\n",
      "iteration: 363200 loss: 0.0006 lr: 0.02\n",
      "iteration: 363300 loss: 0.0007 lr: 0.02\n",
      "iteration: 363400 loss: 0.0009 lr: 0.02\n",
      "iteration: 363500 loss: 0.0008 lr: 0.02\n",
      "iteration: 363600 loss: 0.0007 lr: 0.02\n",
      "iteration: 363700 loss: 0.0006 lr: 0.02\n",
      "iteration: 363800 loss: 0.0008 lr: 0.02\n",
      "iteration: 363900 loss: 0.0009 lr: 0.02\n",
      "iteration: 364000 loss: 0.0007 lr: 0.02\n",
      "iteration: 364100 loss: 0.0007 lr: 0.02\n",
      "iteration: 364200 loss: 0.0007 lr: 0.02\n",
      "iteration: 364300 loss: 0.0007 lr: 0.02\n",
      "iteration: 364400 loss: 0.0006 lr: 0.02\n",
      "iteration: 364500 loss: 0.0006 lr: 0.02\n",
      "iteration: 364600 loss: 0.0008 lr: 0.02\n",
      "iteration: 364700 loss: 0.0008 lr: 0.02\n",
      "iteration: 364800 loss: 0.0008 lr: 0.02\n",
      "iteration: 364900 loss: 0.0010 lr: 0.02\n",
      "iteration: 365000 loss: 0.0008 lr: 0.02\n",
      "iteration: 365100 loss: 0.0009 lr: 0.02\n",
      "iteration: 365200 loss: 0.0008 lr: 0.02\n",
      "iteration: 365300 loss: 0.0008 lr: 0.02\n",
      "iteration: 365400 loss: 0.0007 lr: 0.02\n",
      "iteration: 365500 loss: 0.0009 lr: 0.02\n",
      "iteration: 365600 loss: 0.0008 lr: 0.02\n",
      "iteration: 365700 loss: 0.0008 lr: 0.02\n",
      "iteration: 365800 loss: 0.0010 lr: 0.02\n",
      "iteration: 365900 loss: 0.0008 lr: 0.02\n",
      "iteration: 366000 loss: 0.0009 lr: 0.02\n",
      "iteration: 366100 loss: 0.0009 lr: 0.02\n",
      "iteration: 366200 loss: 0.0007 lr: 0.02\n",
      "iteration: 366300 loss: 0.0007 lr: 0.02\n",
      "iteration: 366400 loss: 0.0007 lr: 0.02\n",
      "iteration: 366500 loss: 0.0007 lr: 0.02\n",
      "iteration: 366600 loss: 0.0008 lr: 0.02\n",
      "iteration: 366700 loss: 0.0007 lr: 0.02\n",
      "iteration: 366800 loss: 0.0008 lr: 0.02\n",
      "iteration: 366900 loss: 0.0007 lr: 0.02\n",
      "iteration: 367000 loss: 0.0008 lr: 0.02\n",
      "iteration: 367100 loss: 0.0009 lr: 0.02\n",
      "iteration: 367200 loss: 0.0006 lr: 0.02\n",
      "iteration: 367300 loss: 0.0008 lr: 0.02\n",
      "iteration: 367400 loss: 0.0008 lr: 0.02\n",
      "iteration: 367500 loss: 0.0006 lr: 0.02\n",
      "iteration: 367600 loss: 0.0008 lr: 0.02\n",
      "iteration: 367700 loss: 0.0009 lr: 0.02\n",
      "iteration: 367800 loss: 0.0008 lr: 0.02\n",
      "iteration: 367900 loss: 0.0010 lr: 0.02\n",
      "iteration: 368000 loss: 0.0009 lr: 0.02\n",
      "iteration: 368100 loss: 0.0009 lr: 0.02\n",
      "iteration: 368200 loss: 0.0009 lr: 0.02\n",
      "iteration: 368300 loss: 0.0007 lr: 0.02\n",
      "iteration: 368400 loss: 0.0007 lr: 0.02\n",
      "iteration: 368500 loss: 0.0008 lr: 0.02\n",
      "iteration: 368600 loss: 0.0010 lr: 0.02\n",
      "iteration: 368700 loss: 0.0008 lr: 0.02\n",
      "iteration: 368800 loss: 0.0009 lr: 0.02\n",
      "iteration: 368900 loss: 0.0007 lr: 0.02\n",
      "iteration: 369000 loss: 0.0007 lr: 0.02\n",
      "iteration: 369100 loss: 0.0007 lr: 0.02\n",
      "iteration: 369200 loss: 0.0007 lr: 0.02\n",
      "iteration: 369300 loss: 0.0006 lr: 0.02\n",
      "iteration: 369400 loss: 0.0007 lr: 0.02\n",
      "iteration: 369500 loss: 0.0006 lr: 0.02\n",
      "iteration: 369600 loss: 0.0008 lr: 0.02\n",
      "iteration: 369700 loss: 0.0008 lr: 0.02\n",
      "iteration: 369800 loss: 0.0007 lr: 0.02\n",
      "iteration: 369900 loss: 0.0009 lr: 0.02\n",
      "iteration: 370000 loss: 0.0007 lr: 0.02\n",
      "iteration: 370100 loss: 0.0007 lr: 0.02\n",
      "iteration: 370200 loss: 0.0008 lr: 0.02\n",
      "iteration: 370300 loss: 0.0010 lr: 0.02\n",
      "iteration: 370400 loss: 0.0011 lr: 0.02\n",
      "iteration: 370500 loss: 0.0010 lr: 0.02\n",
      "iteration: 370600 loss: 0.0008 lr: 0.02\n",
      "iteration: 370700 loss: 0.0008 lr: 0.02\n",
      "iteration: 370800 loss: 0.0009 lr: 0.02\n",
      "iteration: 370900 loss: 0.0008 lr: 0.02\n",
      "iteration: 371000 loss: 0.0007 lr: 0.02\n",
      "iteration: 371100 loss: 0.0007 lr: 0.02\n",
      "iteration: 371200 loss: 0.0006 lr: 0.02\n",
      "iteration: 371300 loss: 0.0008 lr: 0.02\n",
      "iteration: 371400 loss: 0.0007 lr: 0.02\n",
      "iteration: 371500 loss: 0.0010 lr: 0.02\n",
      "iteration: 371600 loss: 0.0008 lr: 0.02\n",
      "iteration: 371700 loss: 0.0008 lr: 0.02\n",
      "iteration: 371800 loss: 0.0009 lr: 0.02\n",
      "iteration: 371900 loss: 0.0007 lr: 0.02\n",
      "iteration: 372000 loss: 0.0007 lr: 0.02\n",
      "iteration: 372100 loss: 0.0006 lr: 0.02\n",
      "iteration: 372200 loss: 0.0008 lr: 0.02\n",
      "iteration: 372300 loss: 0.0007 lr: 0.02\n",
      "iteration: 372400 loss: 0.0009 lr: 0.02\n",
      "iteration: 372500 loss: 0.0008 lr: 0.02\n",
      "iteration: 372600 loss: 0.0008 lr: 0.02\n",
      "iteration: 372700 loss: 0.0008 lr: 0.02\n",
      "iteration: 372800 loss: 0.0008 lr: 0.02\n",
      "iteration: 372900 loss: 0.0008 lr: 0.02\n",
      "iteration: 373000 loss: 0.0009 lr: 0.02\n",
      "iteration: 373100 loss: 0.0008 lr: 0.02\n",
      "iteration: 373200 loss: 0.0007 lr: 0.02\n",
      "iteration: 373300 loss: 0.0008 lr: 0.02\n",
      "iteration: 373400 loss: 0.0007 lr: 0.02\n",
      "iteration: 373500 loss: 0.0008 lr: 0.02\n",
      "iteration: 373600 loss: 0.0008 lr: 0.02\n",
      "iteration: 373700 loss: 0.0008 lr: 0.02\n",
      "iteration: 373800 loss: 0.0006 lr: 0.02\n",
      "iteration: 373900 loss: 0.0007 lr: 0.02\n",
      "iteration: 374000 loss: 0.0008 lr: 0.02\n",
      "iteration: 374100 loss: 0.0008 lr: 0.02\n",
      "iteration: 374200 loss: 0.0008 lr: 0.02\n",
      "iteration: 374300 loss: 0.0009 lr: 0.02\n",
      "iteration: 374400 loss: 0.0007 lr: 0.02\n",
      "iteration: 374500 loss: 0.0007 lr: 0.02\n",
      "iteration: 374600 loss: 0.0007 lr: 0.02\n",
      "iteration: 374700 loss: 0.0007 lr: 0.02\n",
      "iteration: 374800 loss: 0.0007 lr: 0.02\n",
      "iteration: 374900 loss: 0.0007 lr: 0.02\n",
      "iteration: 375000 loss: 0.0008 lr: 0.02\n",
      "iteration: 375100 loss: 0.0008 lr: 0.02\n",
      "iteration: 375200 loss: 0.0007 lr: 0.02\n",
      "iteration: 375300 loss: 0.0008 lr: 0.02\n",
      "iteration: 375400 loss: 0.0009 lr: 0.02\n",
      "iteration: 375500 loss: 0.0008 lr: 0.02\n",
      "iteration: 375600 loss: 0.0007 lr: 0.02\n",
      "iteration: 375700 loss: 0.0008 lr: 0.02\n",
      "iteration: 375800 loss: 0.0008 lr: 0.02\n",
      "iteration: 375900 loss: 0.0007 lr: 0.02\n",
      "iteration: 376000 loss: 0.0008 lr: 0.02\n",
      "iteration: 376100 loss: 0.0007 lr: 0.02\n",
      "iteration: 376200 loss: 0.0008 lr: 0.02\n",
      "iteration: 376300 loss: 0.0007 lr: 0.02\n",
      "iteration: 376400 loss: 0.0007 lr: 0.02\n",
      "iteration: 376500 loss: 0.0009 lr: 0.02\n",
      "iteration: 376600 loss: 0.0008 lr: 0.02\n",
      "iteration: 376700 loss: 0.0007 lr: 0.02\n",
      "iteration: 376800 loss: 0.0008 lr: 0.02\n",
      "iteration: 376900 loss: 0.0008 lr: 0.02\n",
      "iteration: 377000 loss: 0.0008 lr: 0.02\n",
      "iteration: 377100 loss: 0.0007 lr: 0.02\n",
      "iteration: 377200 loss: 0.0010 lr: 0.02\n",
      "iteration: 377300 loss: 0.0006 lr: 0.02\n",
      "iteration: 377400 loss: 0.0007 lr: 0.02\n",
      "iteration: 377500 loss: 0.0007 lr: 0.02\n",
      "iteration: 377600 loss: 0.0008 lr: 0.02\n",
      "iteration: 377700 loss: 0.0009 lr: 0.02\n",
      "iteration: 377800 loss: 0.0008 lr: 0.02\n",
      "iteration: 377900 loss: 0.0008 lr: 0.02\n",
      "iteration: 378000 loss: 0.0006 lr: 0.02\n",
      "iteration: 378100 loss: 0.0006 lr: 0.02\n",
      "iteration: 378200 loss: 0.0007 lr: 0.02\n",
      "iteration: 378300 loss: 0.0008 lr: 0.02\n",
      "iteration: 378400 loss: 0.0007 lr: 0.02\n",
      "iteration: 378500 loss: 0.0007 lr: 0.02\n",
      "iteration: 378600 loss: 0.0008 lr: 0.02\n",
      "iteration: 378700 loss: 0.0008 lr: 0.02\n",
      "iteration: 378800 loss: 0.0008 lr: 0.02\n",
      "iteration: 378900 loss: 0.0008 lr: 0.02\n",
      "iteration: 379000 loss: 0.0009 lr: 0.02\n",
      "iteration: 379100 loss: 0.0008 lr: 0.02\n",
      "iteration: 379200 loss: 0.0008 lr: 0.02\n",
      "iteration: 379300 loss: 0.0007 lr: 0.02\n",
      "iteration: 379400 loss: 0.0009 lr: 0.02\n",
      "iteration: 379500 loss: 0.0009 lr: 0.02\n",
      "iteration: 379600 loss: 0.0008 lr: 0.02\n",
      "iteration: 379700 loss: 0.0008 lr: 0.02\n",
      "iteration: 379800 loss: 0.0007 lr: 0.02\n",
      "iteration: 379900 loss: 0.0007 lr: 0.02\n",
      "iteration: 380000 loss: 0.0007 lr: 0.02\n",
      "iteration: 380100 loss: 0.0011 lr: 0.02\n",
      "iteration: 380200 loss: 0.0008 lr: 0.02\n",
      "iteration: 380300 loss: 0.0007 lr: 0.02\n",
      "iteration: 380400 loss: 0.0006 lr: 0.02\n",
      "iteration: 380500 loss: 0.0007 lr: 0.02\n",
      "iteration: 380600 loss: 0.0007 lr: 0.02\n",
      "iteration: 380700 loss: 0.0007 lr: 0.02\n",
      "iteration: 380800 loss: 0.0007 lr: 0.02\n",
      "iteration: 380900 loss: 0.0007 lr: 0.02\n",
      "iteration: 381000 loss: 0.0008 lr: 0.02\n",
      "iteration: 381100 loss: 0.0010 lr: 0.02\n",
      "iteration: 381200 loss: 0.0008 lr: 0.02\n",
      "iteration: 381300 loss: 0.0008 lr: 0.02\n",
      "iteration: 381400 loss: 0.0007 lr: 0.02\n",
      "iteration: 381500 loss: 0.0008 lr: 0.02\n",
      "iteration: 381600 loss: 0.0009 lr: 0.02\n",
      "iteration: 381700 loss: 0.0008 lr: 0.02\n",
      "iteration: 381800 loss: 0.0008 lr: 0.02\n",
      "iteration: 381900 loss: 0.0008 lr: 0.02\n",
      "iteration: 382000 loss: 0.0007 lr: 0.02\n",
      "iteration: 382100 loss: 0.0008 lr: 0.02\n",
      "iteration: 382200 loss: 0.0008 lr: 0.02\n",
      "iteration: 382300 loss: 0.0008 lr: 0.02\n",
      "iteration: 382400 loss: 0.0008 lr: 0.02\n",
      "iteration: 382500 loss: 0.0007 lr: 0.02\n",
      "iteration: 382600 loss: 0.0008 lr: 0.02\n",
      "iteration: 382700 loss: 0.0008 lr: 0.02\n",
      "iteration: 382800 loss: 0.0006 lr: 0.02\n",
      "iteration: 382900 loss: 0.0007 lr: 0.02\n",
      "iteration: 383000 loss: 0.0007 lr: 0.02\n",
      "iteration: 383100 loss: 0.0007 lr: 0.02\n",
      "iteration: 383200 loss: 0.0007 lr: 0.02\n",
      "iteration: 383300 loss: 0.0007 lr: 0.02\n",
      "iteration: 383400 loss: 0.0008 lr: 0.02\n",
      "iteration: 383500 loss: 0.0007 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 383600 loss: 0.0007 lr: 0.02\n",
      "iteration: 383700 loss: 0.0006 lr: 0.02\n",
      "iteration: 383800 loss: 0.0007 lr: 0.02\n",
      "iteration: 383900 loss: 0.0008 lr: 0.02\n",
      "iteration: 384000 loss: 0.0008 lr: 0.02\n",
      "iteration: 384100 loss: 0.0008 lr: 0.02\n",
      "iteration: 384200 loss: 0.0008 lr: 0.02\n",
      "iteration: 384300 loss: 0.0007 lr: 0.02\n",
      "iteration: 384400 loss: 0.0012 lr: 0.02\n",
      "iteration: 384500 loss: 0.0009 lr: 0.02\n",
      "iteration: 384600 loss: 0.0006 lr: 0.02\n",
      "iteration: 384700 loss: 0.0008 lr: 0.02\n",
      "iteration: 384800 loss: 0.0007 lr: 0.02\n",
      "iteration: 384900 loss: 0.0007 lr: 0.02\n",
      "iteration: 385000 loss: 0.0009 lr: 0.02\n",
      "iteration: 385100 loss: 0.0007 lr: 0.02\n",
      "iteration: 385200 loss: 0.0006 lr: 0.02\n",
      "iteration: 385300 loss: 0.0008 lr: 0.02\n",
      "iteration: 385400 loss: 0.0008 lr: 0.02\n",
      "iteration: 385500 loss: 0.0008 lr: 0.02\n",
      "iteration: 385600 loss: 0.0007 lr: 0.02\n",
      "iteration: 385700 loss: 0.0007 lr: 0.02\n",
      "iteration: 385800 loss: 0.0006 lr: 0.02\n",
      "iteration: 385900 loss: 0.0007 lr: 0.02\n",
      "iteration: 386000 loss: 0.0007 lr: 0.02\n",
      "iteration: 386100 loss: 0.0008 lr: 0.02\n",
      "iteration: 386200 loss: 0.0007 lr: 0.02\n",
      "iteration: 386300 loss: 0.0007 lr: 0.02\n",
      "iteration: 386400 loss: 0.0006 lr: 0.02\n",
      "iteration: 386500 loss: 0.0007 lr: 0.02\n",
      "iteration: 386600 loss: 0.0008 lr: 0.02\n",
      "iteration: 386700 loss: 0.0010 lr: 0.02\n",
      "iteration: 386800 loss: 0.0009 lr: 0.02\n",
      "iteration: 386900 loss: 0.0008 lr: 0.02\n",
      "iteration: 387000 loss: 0.0009 lr: 0.02\n",
      "iteration: 387100 loss: 0.0008 lr: 0.02\n",
      "iteration: 387200 loss: 0.0008 lr: 0.02\n",
      "iteration: 387300 loss: 0.0006 lr: 0.02\n",
      "iteration: 387400 loss: 0.0007 lr: 0.02\n",
      "iteration: 387500 loss: 0.0007 lr: 0.02\n",
      "iteration: 387600 loss: 0.0009 lr: 0.02\n",
      "iteration: 387700 loss: 0.0007 lr: 0.02\n",
      "iteration: 387800 loss: 0.0007 lr: 0.02\n",
      "iteration: 387900 loss: 0.0008 lr: 0.02\n",
      "iteration: 388000 loss: 0.0009 lr: 0.02\n",
      "iteration: 388100 loss: 0.0008 lr: 0.02\n",
      "iteration: 388200 loss: 0.0009 lr: 0.02\n",
      "iteration: 388300 loss: 0.0008 lr: 0.02\n",
      "iteration: 388400 loss: 0.0007 lr: 0.02\n",
      "iteration: 388500 loss: 0.0008 lr: 0.02\n",
      "iteration: 388600 loss: 0.0008 lr: 0.02\n",
      "iteration: 388700 loss: 0.0008 lr: 0.02\n",
      "iteration: 388800 loss: 0.0007 lr: 0.02\n",
      "iteration: 388900 loss: 0.0007 lr: 0.02\n",
      "iteration: 389000 loss: 0.0007 lr: 0.02\n",
      "iteration: 389100 loss: 0.0008 lr: 0.02\n",
      "iteration: 389200 loss: 0.0007 lr: 0.02\n",
      "iteration: 389300 loss: 0.0007 lr: 0.02\n",
      "iteration: 389400 loss: 0.0006 lr: 0.02\n",
      "iteration: 389500 loss: 0.0008 lr: 0.02\n",
      "iteration: 389600 loss: 0.0006 lr: 0.02\n",
      "iteration: 389700 loss: 0.0008 lr: 0.02\n",
      "iteration: 389800 loss: 0.0007 lr: 0.02\n",
      "iteration: 389900 loss: 0.0008 lr: 0.02\n",
      "iteration: 390000 loss: 0.0008 lr: 0.02\n",
      "iteration: 390100 loss: 0.0007 lr: 0.02\n",
      "iteration: 390200 loss: 0.0008 lr: 0.02\n",
      "iteration: 390300 loss: 0.0009 lr: 0.02\n",
      "iteration: 390400 loss: 0.0008 lr: 0.02\n",
      "iteration: 390500 loss: 0.0008 lr: 0.02\n",
      "iteration: 390600 loss: 0.0006 lr: 0.02\n",
      "iteration: 390700 loss: 0.0009 lr: 0.02\n",
      "iteration: 390800 loss: 0.0006 lr: 0.02\n",
      "iteration: 390900 loss: 0.0007 lr: 0.02\n",
      "iteration: 391000 loss: 0.0007 lr: 0.02\n",
      "iteration: 391100 loss: 0.0008 lr: 0.02\n",
      "iteration: 391200 loss: 0.0008 lr: 0.02\n",
      "iteration: 391300 loss: 0.0006 lr: 0.02\n",
      "iteration: 391400 loss: 0.0007 lr: 0.02\n",
      "iteration: 391500 loss: 0.0007 lr: 0.02\n",
      "iteration: 391600 loss: 0.0007 lr: 0.02\n",
      "iteration: 391700 loss: 0.0007 lr: 0.02\n",
      "iteration: 391800 loss: 0.0007 lr: 0.02\n",
      "iteration: 391900 loss: 0.0009 lr: 0.02\n",
      "iteration: 392000 loss: 0.0007 lr: 0.02\n",
      "iteration: 392100 loss: 0.0008 lr: 0.02\n",
      "iteration: 392200 loss: 0.0008 lr: 0.02\n",
      "iteration: 392300 loss: 0.0010 lr: 0.02\n",
      "iteration: 392400 loss: 0.0009 lr: 0.02\n",
      "iteration: 392500 loss: 0.0009 lr: 0.02\n",
      "iteration: 392600 loss: 0.0008 lr: 0.02\n",
      "iteration: 392700 loss: 0.0007 lr: 0.02\n",
      "iteration: 392800 loss: 0.0008 lr: 0.02\n",
      "iteration: 392900 loss: 0.0009 lr: 0.02\n",
      "iteration: 393000 loss: 0.0008 lr: 0.02\n",
      "iteration: 393100 loss: 0.0008 lr: 0.02\n",
      "iteration: 393200 loss: 0.0008 lr: 0.02\n",
      "iteration: 393300 loss: 0.0008 lr: 0.02\n",
      "iteration: 393400 loss: 0.0007 lr: 0.02\n",
      "iteration: 393500 loss: 0.0009 lr: 0.02\n",
      "iteration: 393600 loss: 0.0007 lr: 0.02\n",
      "iteration: 393700 loss: 0.0007 lr: 0.02\n",
      "iteration: 393800 loss: 0.0008 lr: 0.02\n",
      "iteration: 393900 loss: 0.0007 lr: 0.02\n",
      "iteration: 394000 loss: 0.0008 lr: 0.02\n",
      "iteration: 394100 loss: 0.0007 lr: 0.02\n",
      "iteration: 394200 loss: 0.0008 lr: 0.02\n",
      "iteration: 394300 loss: 0.0009 lr: 0.02\n",
      "iteration: 394400 loss: 0.0007 lr: 0.02\n",
      "iteration: 394500 loss: 0.0008 lr: 0.02\n",
      "iteration: 394600 loss: 0.0007 lr: 0.02\n",
      "iteration: 394700 loss: 0.0007 lr: 0.02\n",
      "iteration: 394800 loss: 0.0009 lr: 0.02\n",
      "iteration: 394900 loss: 0.0008 lr: 0.02\n",
      "iteration: 395000 loss: 0.0007 lr: 0.02\n",
      "iteration: 395100 loss: 0.0007 lr: 0.02\n",
      "iteration: 395200 loss: 0.0007 lr: 0.02\n",
      "iteration: 395300 loss: 0.0008 lr: 0.02\n",
      "iteration: 395400 loss: 0.0008 lr: 0.02\n",
      "iteration: 395500 loss: 0.0008 lr: 0.02\n",
      "iteration: 395600 loss: 0.0008 lr: 0.02\n",
      "iteration: 395700 loss: 0.0007 lr: 0.02\n",
      "iteration: 395800 loss: 0.0006 lr: 0.02\n",
      "iteration: 395900 loss: 0.0006 lr: 0.02\n",
      "iteration: 396000 loss: 0.0010 lr: 0.02\n",
      "iteration: 396100 loss: 0.0007 lr: 0.02\n",
      "iteration: 396200 loss: 0.0007 lr: 0.02\n",
      "iteration: 396300 loss: 0.0007 lr: 0.02\n",
      "iteration: 396400 loss: 0.0008 lr: 0.02\n",
      "iteration: 396500 loss: 0.0008 lr: 0.02\n",
      "iteration: 396600 loss: 0.0006 lr: 0.02\n",
      "iteration: 396700 loss: 0.0008 lr: 0.02\n",
      "iteration: 396800 loss: 0.0007 lr: 0.02\n",
      "iteration: 396900 loss: 0.0008 lr: 0.02\n",
      "iteration: 397000 loss: 0.0009 lr: 0.02\n",
      "iteration: 397100 loss: 0.0008 lr: 0.02\n",
      "iteration: 397200 loss: 0.0008 lr: 0.02\n",
      "iteration: 397300 loss: 0.0008 lr: 0.02\n",
      "iteration: 397400 loss: 0.0008 lr: 0.02\n",
      "iteration: 397500 loss: 0.0007 lr: 0.02\n",
      "iteration: 397600 loss: 0.0010 lr: 0.02\n",
      "iteration: 397700 loss: 0.0011 lr: 0.02\n",
      "iteration: 397800 loss: 0.0009 lr: 0.02\n",
      "iteration: 397900 loss: 0.0008 lr: 0.02\n",
      "iteration: 398000 loss: 0.0008 lr: 0.02\n",
      "iteration: 398100 loss: 0.0010 lr: 0.02\n",
      "iteration: 398200 loss: 0.0006 lr: 0.02\n",
      "iteration: 398300 loss: 0.0027 lr: 0.02\n",
      "iteration: 398400 loss: 0.0014 lr: 0.02\n",
      "iteration: 398500 loss: 0.0011 lr: 0.02\n",
      "iteration: 398600 loss: 0.0008 lr: 0.02\n",
      "iteration: 398700 loss: 0.0010 lr: 0.02\n",
      "iteration: 398800 loss: 0.0011 lr: 0.02\n",
      "iteration: 398900 loss: 0.0009 lr: 0.02\n",
      "iteration: 399000 loss: 0.0007 lr: 0.02\n",
      "iteration: 399100 loss: 0.0008 lr: 0.02\n",
      "iteration: 399200 loss: 0.0009 lr: 0.02\n",
      "iteration: 399300 loss: 0.0007 lr: 0.02\n",
      "iteration: 399400 loss: 0.0008 lr: 0.02\n",
      "iteration: 399500 loss: 0.0007 lr: 0.02\n",
      "iteration: 399600 loss: 0.0007 lr: 0.02\n",
      "iteration: 399700 loss: 0.0007 lr: 0.02\n",
      "iteration: 399800 loss: 0.0007 lr: 0.02\n",
      "iteration: 399900 loss: 0.0007 lr: 0.02\n",
      "iteration: 400000 loss: 0.0007 lr: 0.02\n",
      "iteration: 400100 loss: 0.0008 lr: 0.02\n",
      "iteration: 400200 loss: 0.0008 lr: 0.02\n",
      "iteration: 400300 loss: 0.0007 lr: 0.02\n",
      "iteration: 400400 loss: 0.0006 lr: 0.02\n",
      "iteration: 400500 loss: 0.0007 lr: 0.02\n",
      "iteration: 400600 loss: 0.0007 lr: 0.02\n",
      "iteration: 400700 loss: 0.0008 lr: 0.02\n",
      "iteration: 400800 loss: 0.0009 lr: 0.02\n",
      "iteration: 400900 loss: 0.0008 lr: 0.02\n",
      "iteration: 401000 loss: 0.0009 lr: 0.02\n",
      "iteration: 401100 loss: 0.0007 lr: 0.02\n",
      "iteration: 401200 loss: 0.0007 lr: 0.02\n",
      "iteration: 401300 loss: 0.0008 lr: 0.02\n",
      "iteration: 401400 loss: 0.0008 lr: 0.02\n",
      "iteration: 401500 loss: 0.0007 lr: 0.02\n",
      "iteration: 401600 loss: 0.0008 lr: 0.02\n",
      "iteration: 401700 loss: 0.0007 lr: 0.02\n",
      "iteration: 401800 loss: 0.0009 lr: 0.02\n",
      "iteration: 401900 loss: 0.0008 lr: 0.02\n",
      "iteration: 402000 loss: 0.0009 lr: 0.02\n",
      "iteration: 402100 loss: 0.0009 lr: 0.02\n",
      "iteration: 402200 loss: 0.0006 lr: 0.02\n",
      "iteration: 402300 loss: 0.0008 lr: 0.02\n",
      "iteration: 402400 loss: 0.0007 lr: 0.02\n",
      "iteration: 402500 loss: 0.0008 lr: 0.02\n",
      "iteration: 402600 loss: 0.0007 lr: 0.02\n",
      "iteration: 402700 loss: 0.0007 lr: 0.02\n",
      "iteration: 402800 loss: 0.0009 lr: 0.02\n",
      "iteration: 402900 loss: 0.0007 lr: 0.02\n",
      "iteration: 403000 loss: 0.0008 lr: 0.02\n",
      "iteration: 403100 loss: 0.0007 lr: 0.02\n",
      "iteration: 403200 loss: 0.0008 lr: 0.02\n",
      "iteration: 403300 loss: 0.0007 lr: 0.02\n",
      "iteration: 403400 loss: 0.0006 lr: 0.02\n",
      "iteration: 403500 loss: 0.0007 lr: 0.02\n",
      "iteration: 403600 loss: 0.0009 lr: 0.02\n",
      "iteration: 403700 loss: 0.0007 lr: 0.02\n",
      "iteration: 403800 loss: 0.0008 lr: 0.02\n",
      "iteration: 403900 loss: 0.0008 lr: 0.02\n",
      "iteration: 404000 loss: 0.0008 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 404100 loss: 0.0008 lr: 0.02\n",
      "iteration: 404200 loss: 0.0008 lr: 0.02\n",
      "iteration: 404300 loss: 0.0008 lr: 0.02\n",
      "iteration: 404400 loss: 0.0006 lr: 0.02\n",
      "iteration: 404500 loss: 0.0007 lr: 0.02\n",
      "iteration: 404600 loss: 0.0008 lr: 0.02\n",
      "iteration: 404700 loss: 0.0009 lr: 0.02\n",
      "iteration: 404800 loss: 0.0008 lr: 0.02\n",
      "iteration: 404900 loss: 0.0009 lr: 0.02\n",
      "iteration: 405000 loss: 0.0008 lr: 0.02\n",
      "iteration: 405100 loss: 0.0008 lr: 0.02\n",
      "iteration: 405200 loss: 0.0006 lr: 0.02\n",
      "iteration: 405300 loss: 0.0006 lr: 0.02\n",
      "iteration: 405400 loss: 0.0008 lr: 0.02\n",
      "iteration: 405500 loss: 0.0007 lr: 0.02\n",
      "iteration: 405600 loss: 0.0008 lr: 0.02\n",
      "iteration: 405700 loss: 0.0008 lr: 0.02\n",
      "iteration: 405800 loss: 0.0008 lr: 0.02\n",
      "iteration: 405900 loss: 0.0007 lr: 0.02\n",
      "iteration: 406000 loss: 0.0008 lr: 0.02\n",
      "iteration: 406100 loss: 0.0008 lr: 0.02\n",
      "iteration: 406200 loss: 0.0007 lr: 0.02\n",
      "iteration: 406300 loss: 0.0008 lr: 0.02\n",
      "iteration: 406400 loss: 0.0009 lr: 0.02\n",
      "iteration: 406500 loss: 0.0006 lr: 0.02\n",
      "iteration: 406600 loss: 0.0008 lr: 0.02\n",
      "iteration: 406700 loss: 0.0008 lr: 0.02\n",
      "iteration: 406800 loss: 0.0008 lr: 0.02\n",
      "iteration: 406900 loss: 0.0009 lr: 0.02\n",
      "iteration: 407000 loss: 0.0008 lr: 0.02\n",
      "iteration: 407100 loss: 0.0009 lr: 0.02\n",
      "iteration: 407200 loss: 0.0006 lr: 0.02\n",
      "iteration: 407300 loss: 0.0009 lr: 0.02\n",
      "iteration: 407400 loss: 0.0010 lr: 0.02\n",
      "iteration: 407500 loss: 0.0009 lr: 0.02\n",
      "iteration: 407600 loss: 0.0008 lr: 0.02\n",
      "iteration: 407700 loss: 0.0008 lr: 0.02\n",
      "iteration: 407800 loss: 0.0006 lr: 0.02\n",
      "iteration: 407900 loss: 0.0008 lr: 0.02\n",
      "iteration: 408000 loss: 0.0010 lr: 0.02\n",
      "iteration: 408100 loss: 0.0006 lr: 0.02\n",
      "iteration: 408200 loss: 0.0008 lr: 0.02\n",
      "iteration: 408300 loss: 0.0008 lr: 0.02\n",
      "iteration: 408400 loss: 0.0007 lr: 0.02\n",
      "iteration: 408500 loss: 0.0007 lr: 0.02\n",
      "iteration: 408600 loss: 0.0007 lr: 0.02\n",
      "iteration: 408700 loss: 0.0007 lr: 0.02\n",
      "iteration: 408800 loss: 0.0008 lr: 0.02\n",
      "iteration: 408900 loss: 0.0008 lr: 0.02\n",
      "iteration: 409000 loss: 0.0007 lr: 0.02\n",
      "iteration: 409100 loss: 0.0006 lr: 0.02\n",
      "iteration: 409200 loss: 0.0007 lr: 0.02\n",
      "iteration: 409300 loss: 0.0007 lr: 0.02\n",
      "iteration: 409400 loss: 0.0007 lr: 0.02\n",
      "iteration: 409500 loss: 0.0009 lr: 0.02\n",
      "iteration: 409600 loss: 0.0008 lr: 0.02\n",
      "iteration: 409700 loss: 0.0007 lr: 0.02\n",
      "iteration: 409800 loss: 0.0007 lr: 0.02\n",
      "iteration: 409900 loss: 0.0007 lr: 0.02\n",
      "iteration: 410000 loss: 0.0008 lr: 0.02\n",
      "iteration: 410100 loss: 0.0006 lr: 0.02\n",
      "iteration: 410200 loss: 0.0006 lr: 0.02\n",
      "iteration: 410300 loss: 0.0007 lr: 0.02\n",
      "iteration: 410400 loss: 0.0007 lr: 0.02\n",
      "iteration: 410500 loss: 0.0006 lr: 0.02\n",
      "iteration: 410600 loss: 0.0007 lr: 0.02\n",
      "iteration: 410700 loss: 0.0007 lr: 0.02\n",
      "iteration: 410800 loss: 0.0005 lr: 0.02\n",
      "iteration: 410900 loss: 0.0006 lr: 0.02\n",
      "iteration: 411000 loss: 0.0011 lr: 0.02\n",
      "iteration: 411100 loss: 0.0008 lr: 0.02\n",
      "iteration: 411200 loss: 0.0008 lr: 0.02\n",
      "iteration: 411300 loss: 0.0008 lr: 0.02\n",
      "iteration: 411400 loss: 0.0008 lr: 0.02\n",
      "iteration: 411500 loss: 0.0007 lr: 0.02\n",
      "iteration: 411600 loss: 0.0008 lr: 0.02\n",
      "iteration: 411700 loss: 0.0007 lr: 0.02\n",
      "iteration: 411800 loss: 0.0006 lr: 0.02\n",
      "iteration: 411900 loss: 0.0008 lr: 0.02\n",
      "iteration: 412000 loss: 0.0007 lr: 0.02\n",
      "iteration: 412100 loss: 0.0007 lr: 0.02\n",
      "iteration: 412200 loss: 0.0007 lr: 0.02\n",
      "iteration: 412300 loss: 0.0007 lr: 0.02\n",
      "iteration: 412400 loss: 0.0007 lr: 0.02\n",
      "iteration: 412500 loss: 0.0007 lr: 0.02\n",
      "iteration: 412600 loss: 0.0007 lr: 0.02\n",
      "iteration: 412700 loss: 0.0007 lr: 0.02\n",
      "iteration: 412800 loss: 0.0008 lr: 0.02\n",
      "iteration: 412900 loss: 0.0006 lr: 0.02\n",
      "iteration: 413000 loss: 0.0007 lr: 0.02\n",
      "iteration: 413100 loss: 0.0009 lr: 0.02\n",
      "iteration: 413200 loss: 0.0008 lr: 0.02\n",
      "iteration: 413300 loss: 0.0006 lr: 0.02\n",
      "iteration: 413400 loss: 0.0007 lr: 0.02\n",
      "iteration: 413500 loss: 0.0009 lr: 0.02\n",
      "iteration: 413600 loss: 0.0008 lr: 0.02\n",
      "iteration: 413700 loss: 0.0007 lr: 0.02\n",
      "iteration: 413800 loss: 0.0009 lr: 0.02\n",
      "iteration: 413900 loss: 0.0008 lr: 0.02\n",
      "iteration: 414000 loss: 0.0008 lr: 0.02\n",
      "iteration: 414100 loss: 0.0010 lr: 0.02\n",
      "iteration: 414200 loss: 0.0007 lr: 0.02\n",
      "iteration: 414300 loss: 0.0007 lr: 0.02\n",
      "iteration: 414400 loss: 0.0007 lr: 0.02\n",
      "iteration: 414500 loss: 0.0007 lr: 0.02\n",
      "iteration: 414600 loss: 0.0008 lr: 0.02\n",
      "iteration: 414700 loss: 0.0007 lr: 0.02\n",
      "iteration: 414800 loss: 0.0008 lr: 0.02\n",
      "iteration: 414900 loss: 0.0008 lr: 0.02\n",
      "iteration: 415000 loss: 0.0008 lr: 0.02\n",
      "iteration: 415100 loss: 0.0009 lr: 0.02\n",
      "iteration: 415200 loss: 0.0007 lr: 0.02\n",
      "iteration: 415300 loss: 0.0007 lr: 0.02\n",
      "iteration: 415400 loss: 0.0007 lr: 0.02\n",
      "iteration: 415500 loss: 0.0008 lr: 0.02\n",
      "iteration: 415600 loss: 0.0007 lr: 0.02\n",
      "iteration: 415700 loss: 0.0008 lr: 0.02\n",
      "iteration: 415800 loss: 0.0007 lr: 0.02\n",
      "iteration: 415900 loss: 0.0007 lr: 0.02\n",
      "iteration: 416000 loss: 0.0008 lr: 0.02\n",
      "iteration: 416100 loss: 0.0008 lr: 0.02\n",
      "iteration: 416200 loss: 0.0007 lr: 0.02\n",
      "iteration: 416300 loss: 0.0008 lr: 0.02\n",
      "iteration: 416400 loss: 0.0007 lr: 0.02\n",
      "iteration: 416500 loss: 0.0011 lr: 0.02\n",
      "iteration: 416600 loss: 0.0009 lr: 0.02\n",
      "iteration: 416700 loss: 0.0008 lr: 0.02\n",
      "iteration: 416800 loss: 0.0008 lr: 0.02\n",
      "iteration: 416900 loss: 0.0006 lr: 0.02\n",
      "iteration: 417000 loss: 0.0009 lr: 0.02\n",
      "iteration: 417100 loss: 0.0006 lr: 0.02\n",
      "iteration: 417200 loss: 0.0008 lr: 0.02\n",
      "iteration: 417300 loss: 0.0007 lr: 0.02\n",
      "iteration: 417400 loss: 0.0007 lr: 0.02\n",
      "iteration: 417500 loss: 0.0008 lr: 0.02\n",
      "iteration: 417600 loss: 0.0006 lr: 0.02\n",
      "iteration: 417700 loss: 0.0007 lr: 0.02\n",
      "iteration: 417800 loss: 0.0006 lr: 0.02\n",
      "iteration: 417900 loss: 0.0008 lr: 0.02\n",
      "iteration: 418000 loss: 0.0008 lr: 0.02\n",
      "iteration: 418100 loss: 0.0007 lr: 0.02\n",
      "iteration: 418200 loss: 0.0007 lr: 0.02\n",
      "iteration: 418300 loss: 0.0008 lr: 0.02\n",
      "iteration: 418400 loss: 0.0007 lr: 0.02\n",
      "iteration: 418500 loss: 0.0009 lr: 0.02\n",
      "iteration: 418600 loss: 0.0009 lr: 0.02\n",
      "iteration: 418700 loss: 0.0007 lr: 0.02\n",
      "iteration: 418800 loss: 0.0007 lr: 0.02\n",
      "iteration: 418900 loss: 0.0007 lr: 0.02\n",
      "iteration: 419000 loss: 0.0008 lr: 0.02\n",
      "iteration: 419100 loss: 0.0006 lr: 0.02\n",
      "iteration: 419200 loss: 0.0007 lr: 0.02\n",
      "iteration: 419300 loss: 0.0008 lr: 0.02\n",
      "iteration: 419400 loss: 0.0009 lr: 0.02\n",
      "iteration: 419500 loss: 0.0008 lr: 0.02\n",
      "iteration: 419600 loss: 0.0007 lr: 0.02\n",
      "iteration: 419700 loss: 0.0008 lr: 0.02\n",
      "iteration: 419800 loss: 0.0009 lr: 0.02\n",
      "iteration: 419900 loss: 0.0007 lr: 0.02\n",
      "iteration: 420000 loss: 0.0007 lr: 0.02\n",
      "iteration: 420100 loss: 0.0007 lr: 0.02\n",
      "iteration: 420200 loss: 0.0008 lr: 0.02\n",
      "iteration: 420300 loss: 0.0006 lr: 0.02\n",
      "iteration: 420400 loss: 0.0007 lr: 0.02\n",
      "iteration: 420500 loss: 0.0008 lr: 0.02\n",
      "iteration: 420600 loss: 0.0007 lr: 0.02\n",
      "iteration: 420700 loss: 0.0007 lr: 0.02\n",
      "iteration: 420800 loss: 0.0007 lr: 0.02\n",
      "iteration: 420900 loss: 0.0007 lr: 0.02\n",
      "iteration: 421000 loss: 0.0007 lr: 0.02\n",
      "iteration: 421100 loss: 0.0009 lr: 0.02\n",
      "iteration: 421200 loss: 0.0006 lr: 0.02\n",
      "iteration: 421300 loss: 0.0006 lr: 0.02\n",
      "iteration: 421400 loss: 0.0008 lr: 0.02\n",
      "iteration: 421500 loss: 0.0008 lr: 0.02\n",
      "iteration: 421600 loss: 0.0007 lr: 0.02\n",
      "iteration: 421700 loss: 0.0007 lr: 0.02\n",
      "iteration: 421800 loss: 0.0009 lr: 0.02\n",
      "iteration: 421900 loss: 0.0007 lr: 0.02\n",
      "iteration: 422000 loss: 0.0007 lr: 0.02\n",
      "iteration: 422100 loss: 0.0008 lr: 0.02\n",
      "iteration: 422200 loss: 0.0007 lr: 0.02\n",
      "iteration: 422300 loss: 0.0007 lr: 0.02\n",
      "iteration: 422400 loss: 0.0008 lr: 0.02\n",
      "iteration: 422500 loss: 0.0008 lr: 0.02\n",
      "iteration: 422600 loss: 0.0007 lr: 0.02\n",
      "iteration: 422700 loss: 0.0006 lr: 0.02\n",
      "iteration: 422800 loss: 0.0007 lr: 0.02\n",
      "iteration: 422900 loss: 0.0009 lr: 0.02\n",
      "iteration: 423000 loss: 0.0007 lr: 0.02\n",
      "iteration: 423100 loss: 0.0007 lr: 0.02\n",
      "iteration: 423200 loss: 0.0008 lr: 0.02\n",
      "iteration: 423300 loss: 0.0009 lr: 0.02\n",
      "iteration: 423400 loss: 0.0007 lr: 0.02\n",
      "iteration: 423500 loss: 0.0008 lr: 0.02\n",
      "iteration: 423600 loss: 0.0008 lr: 0.02\n",
      "iteration: 423700 loss: 0.0009 lr: 0.02\n",
      "iteration: 423800 loss: 0.0006 lr: 0.02\n",
      "iteration: 423900 loss: 0.0007 lr: 0.02\n",
      "iteration: 424000 loss: 0.0007 lr: 0.02\n",
      "iteration: 424100 loss: 0.0006 lr: 0.02\n",
      "iteration: 424200 loss: 0.0006 lr: 0.02\n",
      "iteration: 424300 loss: 0.0006 lr: 0.02\n",
      "iteration: 424400 loss: 0.0007 lr: 0.02\n",
      "iteration: 424500 loss: 0.0008 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 424600 loss: 0.0008 lr: 0.02\n",
      "iteration: 424700 loss: 0.0007 lr: 0.02\n",
      "iteration: 424800 loss: 0.0009 lr: 0.02\n",
      "iteration: 424900 loss: 0.0009 lr: 0.02\n",
      "iteration: 425000 loss: 0.0007 lr: 0.02\n",
      "iteration: 425100 loss: 0.0007 lr: 0.02\n",
      "iteration: 425200 loss: 0.0007 lr: 0.02\n",
      "iteration: 425300 loss: 0.0007 lr: 0.02\n",
      "iteration: 425400 loss: 0.0008 lr: 0.02\n",
      "iteration: 425500 loss: 0.0008 lr: 0.02\n",
      "iteration: 425600 loss: 0.0007 lr: 0.02\n",
      "iteration: 425700 loss: 0.0006 lr: 0.02\n",
      "iteration: 425800 loss: 0.0007 lr: 0.02\n",
      "iteration: 425900 loss: 0.0007 lr: 0.02\n",
      "iteration: 426000 loss: 0.0008 lr: 0.02\n",
      "iteration: 426100 loss: 0.0007 lr: 0.02\n",
      "iteration: 426200 loss: 0.0006 lr: 0.02\n",
      "iteration: 426300 loss: 0.0007 lr: 0.02\n",
      "iteration: 426400 loss: 0.0008 lr: 0.02\n",
      "iteration: 426500 loss: 0.0007 lr: 0.02\n",
      "iteration: 426600 loss: 0.0009 lr: 0.02\n",
      "iteration: 426700 loss: 0.0008 lr: 0.02\n",
      "iteration: 426800 loss: 0.0007 lr: 0.02\n",
      "iteration: 426900 loss: 0.0007 lr: 0.02\n",
      "iteration: 427000 loss: 0.0007 lr: 0.02\n",
      "iteration: 427100 loss: 0.0007 lr: 0.02\n",
      "iteration: 427200 loss: 0.0008 lr: 0.02\n",
      "iteration: 427300 loss: 0.0008 lr: 0.02\n",
      "iteration: 427400 loss: 0.0007 lr: 0.02\n",
      "iteration: 427500 loss: 0.0007 lr: 0.02\n",
      "iteration: 427600 loss: 0.0008 lr: 0.02\n",
      "iteration: 427700 loss: 0.0007 lr: 0.02\n",
      "iteration: 427800 loss: 0.0007 lr: 0.02\n",
      "iteration: 427900 loss: 0.0010 lr: 0.02\n",
      "iteration: 428000 loss: 0.0010 lr: 0.02\n",
      "iteration: 428100 loss: 0.0009 lr: 0.02\n",
      "iteration: 428200 loss: 0.0009 lr: 0.02\n",
      "iteration: 428300 loss: 0.0009 lr: 0.02\n",
      "iteration: 428400 loss: 0.0009 lr: 0.02\n",
      "iteration: 428500 loss: 0.0006 lr: 0.02\n",
      "iteration: 428600 loss: 0.0009 lr: 0.02\n",
      "iteration: 428700 loss: 0.0007 lr: 0.02\n",
      "iteration: 428800 loss: 0.0008 lr: 0.02\n",
      "iteration: 428900 loss: 0.0007 lr: 0.02\n",
      "iteration: 429000 loss: 0.0007 lr: 0.02\n",
      "iteration: 429100 loss: 0.0006 lr: 0.02\n",
      "iteration: 429200 loss: 0.0009 lr: 0.02\n",
      "iteration: 429300 loss: 0.0006 lr: 0.02\n",
      "iteration: 429400 loss: 0.0007 lr: 0.02\n",
      "iteration: 429500 loss: 0.0006 lr: 0.02\n",
      "iteration: 429600 loss: 0.0007 lr: 0.02\n",
      "iteration: 429700 loss: 0.0007 lr: 0.02\n",
      "iteration: 429800 loss: 0.0006 lr: 0.02\n",
      "iteration: 429900 loss: 0.0007 lr: 0.02\n",
      "iteration: 430000 loss: 0.0005 lr: 0.02\n",
      "iteration: 430100 loss: 0.0006 lr: 0.002\n",
      "iteration: 430200 loss: 0.0008 lr: 0.002\n",
      "iteration: 430300 loss: 0.0006 lr: 0.002\n",
      "iteration: 430400 loss: 0.0006 lr: 0.002\n",
      "iteration: 430500 loss: 0.0005 lr: 0.002\n",
      "iteration: 430600 loss: 0.0006 lr: 0.002\n",
      "iteration: 430700 loss: 0.0005 lr: 0.002\n",
      "iteration: 430800 loss: 0.0005 lr: 0.002\n",
      "iteration: 430900 loss: 0.0005 lr: 0.002\n",
      "iteration: 431000 loss: 0.0006 lr: 0.002\n",
      "iteration: 431100 loss: 0.0005 lr: 0.002\n",
      "iteration: 431200 loss: 0.0007 lr: 0.002\n",
      "iteration: 431300 loss: 0.0004 lr: 0.002\n",
      "iteration: 431400 loss: 0.0005 lr: 0.002\n",
      "iteration: 431500 loss: 0.0005 lr: 0.002\n",
      "iteration: 431600 loss: 0.0005 lr: 0.002\n",
      "iteration: 431700 loss: 0.0005 lr: 0.002\n",
      "iteration: 431800 loss: 0.0004 lr: 0.002\n",
      "iteration: 431900 loss: 0.0005 lr: 0.002\n",
      "iteration: 432000 loss: 0.0005 lr: 0.002\n",
      "iteration: 432100 loss: 0.0004 lr: 0.002\n",
      "iteration: 432200 loss: 0.0006 lr: 0.002\n",
      "iteration: 432300 loss: 0.0006 lr: 0.002\n",
      "iteration: 432400 loss: 0.0006 lr: 0.002\n",
      "iteration: 432500 loss: 0.0004 lr: 0.002\n",
      "iteration: 432600 loss: 0.0004 lr: 0.002\n",
      "iteration: 432700 loss: 0.0005 lr: 0.002\n",
      "iteration: 432800 loss: 0.0004 lr: 0.002\n",
      "iteration: 432900 loss: 0.0005 lr: 0.002\n",
      "iteration: 433000 loss: 0.0005 lr: 0.002\n",
      "iteration: 433100 loss: 0.0005 lr: 0.002\n",
      "iteration: 433200 loss: 0.0006 lr: 0.002\n",
      "iteration: 433300 loss: 0.0005 lr: 0.002\n",
      "iteration: 433400 loss: 0.0005 lr: 0.002\n",
      "iteration: 433500 loss: 0.0005 lr: 0.002\n",
      "iteration: 433600 loss: 0.0005 lr: 0.002\n",
      "iteration: 433700 loss: 0.0005 lr: 0.002\n",
      "iteration: 433800 loss: 0.0005 lr: 0.002\n",
      "iteration: 433900 loss: 0.0005 lr: 0.002\n",
      "iteration: 434000 loss: 0.0005 lr: 0.002\n",
      "iteration: 434100 loss: 0.0004 lr: 0.002\n",
      "iteration: 434200 loss: 0.0006 lr: 0.002\n",
      "iteration: 434300 loss: 0.0005 lr: 0.002\n",
      "iteration: 434400 loss: 0.0005 lr: 0.002\n",
      "iteration: 434500 loss: 0.0004 lr: 0.002\n",
      "iteration: 434600 loss: 0.0005 lr: 0.002\n",
      "iteration: 434700 loss: 0.0006 lr: 0.002\n",
      "iteration: 434800 loss: 0.0004 lr: 0.002\n",
      "iteration: 434900 loss: 0.0004 lr: 0.002\n",
      "iteration: 435000 loss: 0.0005 lr: 0.002\n",
      "iteration: 435100 loss: 0.0005 lr: 0.002\n",
      "iteration: 435200 loss: 0.0005 lr: 0.002\n",
      "iteration: 435300 loss: 0.0005 lr: 0.002\n",
      "iteration: 435400 loss: 0.0005 lr: 0.002\n",
      "iteration: 435500 loss: 0.0005 lr: 0.002\n",
      "iteration: 435600 loss: 0.0005 lr: 0.002\n",
      "iteration: 435700 loss: 0.0004 lr: 0.002\n",
      "iteration: 435800 loss: 0.0005 lr: 0.002\n",
      "iteration: 435900 loss: 0.0004 lr: 0.002\n",
      "iteration: 436000 loss: 0.0005 lr: 0.002\n",
      "iteration: 436100 loss: 0.0004 lr: 0.002\n",
      "iteration: 436200 loss: 0.0004 lr: 0.002\n",
      "iteration: 436300 loss: 0.0005 lr: 0.002\n",
      "iteration: 436400 loss: 0.0004 lr: 0.002\n",
      "iteration: 436500 loss: 0.0004 lr: 0.002\n",
      "iteration: 436600 loss: 0.0005 lr: 0.002\n",
      "iteration: 436700 loss: 0.0005 lr: 0.002\n",
      "iteration: 436800 loss: 0.0005 lr: 0.002\n",
      "iteration: 436900 loss: 0.0005 lr: 0.002\n",
      "iteration: 437000 loss: 0.0005 lr: 0.002\n",
      "iteration: 437100 loss: 0.0005 lr: 0.002\n",
      "iteration: 437200 loss: 0.0005 lr: 0.002\n",
      "iteration: 437300 loss: 0.0005 lr: 0.002\n",
      "iteration: 437400 loss: 0.0005 lr: 0.002\n",
      "iteration: 437500 loss: 0.0003 lr: 0.002\n",
      "iteration: 437600 loss: 0.0005 lr: 0.002\n",
      "iteration: 437700 loss: 0.0005 lr: 0.002\n",
      "iteration: 437800 loss: 0.0005 lr: 0.002\n",
      "iteration: 437900 loss: 0.0004 lr: 0.002\n",
      "iteration: 438000 loss: 0.0006 lr: 0.002\n",
      "iteration: 438100 loss: 0.0006 lr: 0.002\n",
      "iteration: 438200 loss: 0.0004 lr: 0.002\n",
      "iteration: 438300 loss: 0.0004 lr: 0.002\n",
      "iteration: 438400 loss: 0.0004 lr: 0.002\n",
      "iteration: 438500 loss: 0.0005 lr: 0.002\n",
      "iteration: 438600 loss: 0.0005 lr: 0.002\n",
      "iteration: 438700 loss: 0.0004 lr: 0.002\n",
      "iteration: 438800 loss: 0.0004 lr: 0.002\n",
      "iteration: 438900 loss: 0.0004 lr: 0.002\n",
      "iteration: 439000 loss: 0.0004 lr: 0.002\n",
      "iteration: 439100 loss: 0.0004 lr: 0.002\n",
      "iteration: 439200 loss: 0.0005 lr: 0.002\n",
      "iteration: 439300 loss: 0.0005 lr: 0.002\n",
      "iteration: 439400 loss: 0.0005 lr: 0.002\n",
      "iteration: 439500 loss: 0.0004 lr: 0.002\n",
      "iteration: 439600 loss: 0.0004 lr: 0.002\n",
      "iteration: 439700 loss: 0.0004 lr: 0.002\n",
      "iteration: 439800 loss: 0.0006 lr: 0.002\n",
      "iteration: 439900 loss: 0.0005 lr: 0.002\n",
      "iteration: 440000 loss: 0.0004 lr: 0.002\n",
      "iteration: 440100 loss: 0.0005 lr: 0.002\n",
      "iteration: 440200 loss: 0.0005 lr: 0.002\n",
      "iteration: 440300 loss: 0.0005 lr: 0.002\n",
      "iteration: 440400 loss: 0.0004 lr: 0.002\n",
      "iteration: 440500 loss: 0.0004 lr: 0.002\n",
      "iteration: 440600 loss: 0.0004 lr: 0.002\n",
      "iteration: 440700 loss: 0.0005 lr: 0.002\n",
      "iteration: 440800 loss: 0.0004 lr: 0.002\n",
      "iteration: 440900 loss: 0.0005 lr: 0.002\n",
      "iteration: 441000 loss: 0.0004 lr: 0.002\n",
      "iteration: 441100 loss: 0.0004 lr: 0.002\n",
      "iteration: 441200 loss: 0.0004 lr: 0.002\n",
      "iteration: 441300 loss: 0.0005 lr: 0.002\n",
      "iteration: 441400 loss: 0.0004 lr: 0.002\n",
      "iteration: 441500 loss: 0.0005 lr: 0.002\n",
      "iteration: 441600 loss: 0.0004 lr: 0.002\n",
      "iteration: 441700 loss: 0.0005 lr: 0.002\n",
      "iteration: 441800 loss: 0.0004 lr: 0.002\n",
      "iteration: 441900 loss: 0.0004 lr: 0.002\n",
      "iteration: 442000 loss: 0.0004 lr: 0.002\n",
      "iteration: 442100 loss: 0.0004 lr: 0.002\n",
      "iteration: 442200 loss: 0.0005 lr: 0.002\n",
      "iteration: 442300 loss: 0.0005 lr: 0.002\n",
      "iteration: 442400 loss: 0.0004 lr: 0.002\n",
      "iteration: 442500 loss: 0.0004 lr: 0.002\n",
      "iteration: 442600 loss: 0.0005 lr: 0.002\n",
      "iteration: 442700 loss: 0.0004 lr: 0.002\n",
      "iteration: 442800 loss: 0.0004 lr: 0.002\n",
      "iteration: 442900 loss: 0.0004 lr: 0.002\n",
      "iteration: 443000 loss: 0.0004 lr: 0.002\n",
      "iteration: 443100 loss: 0.0006 lr: 0.002\n",
      "iteration: 443200 loss: 0.0004 lr: 0.002\n",
      "iteration: 443300 loss: 0.0004 lr: 0.002\n",
      "iteration: 443400 loss: 0.0004 lr: 0.002\n",
      "iteration: 443500 loss: 0.0005 lr: 0.002\n",
      "iteration: 443600 loss: 0.0004 lr: 0.002\n",
      "iteration: 443700 loss: 0.0005 lr: 0.002\n",
      "iteration: 443800 loss: 0.0005 lr: 0.002\n",
      "iteration: 443900 loss: 0.0004 lr: 0.002\n",
      "iteration: 444000 loss: 0.0003 lr: 0.002\n",
      "iteration: 444100 loss: 0.0004 lr: 0.002\n",
      "iteration: 444200 loss: 0.0004 lr: 0.002\n",
      "iteration: 444300 loss: 0.0006 lr: 0.002\n",
      "iteration: 444400 loss: 0.0004 lr: 0.002\n",
      "iteration: 444500 loss: 0.0004 lr: 0.002\n",
      "iteration: 444600 loss: 0.0005 lr: 0.002\n",
      "iteration: 444700 loss: 0.0004 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 444800 loss: 0.0003 lr: 0.002\n",
      "iteration: 444900 loss: 0.0005 lr: 0.002\n",
      "iteration: 445000 loss: 0.0005 lr: 0.002\n",
      "iteration: 445100 loss: 0.0004 lr: 0.002\n",
      "iteration: 445200 loss: 0.0004 lr: 0.002\n",
      "iteration: 445300 loss: 0.0004 lr: 0.002\n",
      "iteration: 445400 loss: 0.0005 lr: 0.002\n",
      "iteration: 445500 loss: 0.0005 lr: 0.002\n",
      "iteration: 445600 loss: 0.0003 lr: 0.002\n",
      "iteration: 445700 loss: 0.0005 lr: 0.002\n",
      "iteration: 445800 loss: 0.0004 lr: 0.002\n",
      "iteration: 445900 loss: 0.0004 lr: 0.002\n",
      "iteration: 446000 loss: 0.0004 lr: 0.002\n",
      "iteration: 446100 loss: 0.0004 lr: 0.002\n",
      "iteration: 446200 loss: 0.0005 lr: 0.002\n",
      "iteration: 446300 loss: 0.0005 lr: 0.002\n",
      "iteration: 446400 loss: 0.0003 lr: 0.002\n",
      "iteration: 446500 loss: 0.0004 lr: 0.002\n",
      "iteration: 446600 loss: 0.0004 lr: 0.002\n",
      "iteration: 446700 loss: 0.0004 lr: 0.002\n",
      "iteration: 446800 loss: 0.0004 lr: 0.002\n",
      "iteration: 446900 loss: 0.0005 lr: 0.002\n",
      "iteration: 447000 loss: 0.0004 lr: 0.002\n",
      "iteration: 447100 loss: 0.0004 lr: 0.002\n",
      "iteration: 447200 loss: 0.0004 lr: 0.002\n",
      "iteration: 447300 loss: 0.0004 lr: 0.002\n",
      "iteration: 447400 loss: 0.0004 lr: 0.002\n",
      "iteration: 447500 loss: 0.0003 lr: 0.002\n",
      "iteration: 447600 loss: 0.0004 lr: 0.002\n",
      "iteration: 447700 loss: 0.0004 lr: 0.002\n",
      "iteration: 447800 loss: 0.0005 lr: 0.002\n",
      "iteration: 447900 loss: 0.0004 lr: 0.002\n",
      "iteration: 448000 loss: 0.0005 lr: 0.002\n",
      "iteration: 448100 loss: 0.0005 lr: 0.002\n",
      "iteration: 448200 loss: 0.0004 lr: 0.002\n",
      "iteration: 448300 loss: 0.0005 lr: 0.002\n",
      "iteration: 448400 loss: 0.0004 lr: 0.002\n",
      "iteration: 448500 loss: 0.0004 lr: 0.002\n",
      "iteration: 448600 loss: 0.0004 lr: 0.002\n",
      "iteration: 448700 loss: 0.0004 lr: 0.002\n",
      "iteration: 448800 loss: 0.0005 lr: 0.002\n",
      "iteration: 448900 loss: 0.0005 lr: 0.002\n",
      "iteration: 449000 loss: 0.0004 lr: 0.002\n",
      "iteration: 449100 loss: 0.0004 lr: 0.002\n",
      "iteration: 449200 loss: 0.0004 lr: 0.002\n",
      "iteration: 449300 loss: 0.0004 lr: 0.002\n",
      "iteration: 449400 loss: 0.0005 lr: 0.002\n",
      "iteration: 449500 loss: 0.0005 lr: 0.002\n",
      "iteration: 449600 loss: 0.0004 lr: 0.002\n",
      "iteration: 449700 loss: 0.0005 lr: 0.002\n",
      "iteration: 449800 loss: 0.0005 lr: 0.002\n",
      "iteration: 449900 loss: 0.0004 lr: 0.002\n",
      "iteration: 450000 loss: 0.0004 lr: 0.002\n",
      "iteration: 450100 loss: 0.0004 lr: 0.002\n",
      "iteration: 450200 loss: 0.0004 lr: 0.002\n",
      "iteration: 450300 loss: 0.0004 lr: 0.002\n",
      "iteration: 450400 loss: 0.0004 lr: 0.002\n",
      "iteration: 450500 loss: 0.0005 lr: 0.002\n",
      "iteration: 450600 loss: 0.0003 lr: 0.002\n",
      "iteration: 450700 loss: 0.0005 lr: 0.002\n",
      "iteration: 450800 loss: 0.0003 lr: 0.002\n",
      "iteration: 450900 loss: 0.0004 lr: 0.002\n",
      "iteration: 451000 loss: 0.0003 lr: 0.002\n",
      "iteration: 451100 loss: 0.0005 lr: 0.002\n",
      "iteration: 451200 loss: 0.0004 lr: 0.002\n",
      "iteration: 451300 loss: 0.0004 lr: 0.002\n",
      "iteration: 451400 loss: 0.0004 lr: 0.002\n",
      "iteration: 451500 loss: 0.0004 lr: 0.002\n",
      "iteration: 451600 loss: 0.0004 lr: 0.002\n",
      "iteration: 451700 loss: 0.0004 lr: 0.002\n",
      "iteration: 451800 loss: 0.0004 lr: 0.002\n",
      "iteration: 451900 loss: 0.0006 lr: 0.002\n",
      "iteration: 452000 loss: 0.0006 lr: 0.002\n",
      "iteration: 452100 loss: 0.0006 lr: 0.002\n",
      "iteration: 452200 loss: 0.0005 lr: 0.002\n",
      "iteration: 452300 loss: 0.0004 lr: 0.002\n",
      "iteration: 452400 loss: 0.0004 lr: 0.002\n",
      "iteration: 452500 loss: 0.0004 lr: 0.002\n",
      "iteration: 452600 loss: 0.0004 lr: 0.002\n",
      "iteration: 452700 loss: 0.0005 lr: 0.002\n",
      "iteration: 452800 loss: 0.0004 lr: 0.002\n",
      "iteration: 452900 loss: 0.0004 lr: 0.002\n",
      "iteration: 453000 loss: 0.0003 lr: 0.002\n",
      "iteration: 453100 loss: 0.0004 lr: 0.002\n",
      "iteration: 453200 loss: 0.0003 lr: 0.002\n",
      "iteration: 453300 loss: 0.0004 lr: 0.002\n",
      "iteration: 453400 loss: 0.0004 lr: 0.002\n",
      "iteration: 453500 loss: 0.0004 lr: 0.002\n",
      "iteration: 453600 loss: 0.0004 lr: 0.002\n",
      "iteration: 453700 loss: 0.0004 lr: 0.002\n",
      "iteration: 453800 loss: 0.0005 lr: 0.002\n",
      "iteration: 453900 loss: 0.0004 lr: 0.002\n",
      "iteration: 454000 loss: 0.0004 lr: 0.002\n",
      "iteration: 454100 loss: 0.0004 lr: 0.002\n",
      "iteration: 454200 loss: 0.0004 lr: 0.002\n",
      "iteration: 454300 loss: 0.0004 lr: 0.002\n",
      "iteration: 454400 loss: 0.0004 lr: 0.002\n",
      "iteration: 454500 loss: 0.0004 lr: 0.002\n",
      "iteration: 454600 loss: 0.0005 lr: 0.002\n",
      "iteration: 454700 loss: 0.0004 lr: 0.002\n",
      "iteration: 454800 loss: 0.0004 lr: 0.002\n",
      "iteration: 454900 loss: 0.0003 lr: 0.002\n",
      "iteration: 455000 loss: 0.0004 lr: 0.002\n",
      "iteration: 455100 loss: 0.0004 lr: 0.002\n",
      "iteration: 455200 loss: 0.0004 lr: 0.002\n",
      "iteration: 455300 loss: 0.0004 lr: 0.002\n",
      "iteration: 455400 loss: 0.0004 lr: 0.002\n",
      "iteration: 455500 loss: 0.0005 lr: 0.002\n",
      "iteration: 455600 loss: 0.0004 lr: 0.002\n",
      "iteration: 455700 loss: 0.0005 lr: 0.002\n",
      "iteration: 455800 loss: 0.0004 lr: 0.002\n",
      "iteration: 455900 loss: 0.0004 lr: 0.002\n",
      "iteration: 456000 loss: 0.0004 lr: 0.002\n",
      "iteration: 456100 loss: 0.0004 lr: 0.002\n",
      "iteration: 456200 loss: 0.0004 lr: 0.002\n",
      "iteration: 456300 loss: 0.0005 lr: 0.002\n",
      "iteration: 456400 loss: 0.0004 lr: 0.002\n",
      "iteration: 456500 loss: 0.0004 lr: 0.002\n",
      "iteration: 456600 loss: 0.0005 lr: 0.002\n",
      "iteration: 456700 loss: 0.0005 lr: 0.002\n",
      "iteration: 456800 loss: 0.0004 lr: 0.002\n",
      "iteration: 456900 loss: 0.0004 lr: 0.002\n",
      "iteration: 457000 loss: 0.0004 lr: 0.002\n",
      "iteration: 457100 loss: 0.0006 lr: 0.002\n",
      "iteration: 457200 loss: 0.0004 lr: 0.002\n",
      "iteration: 457300 loss: 0.0004 lr: 0.002\n",
      "iteration: 457400 loss: 0.0004 lr: 0.002\n",
      "iteration: 457500 loss: 0.0003 lr: 0.002\n",
      "iteration: 457600 loss: 0.0004 lr: 0.002\n",
      "iteration: 457700 loss: 0.0005 lr: 0.002\n",
      "iteration: 457800 loss: 0.0004 lr: 0.002\n",
      "iteration: 457900 loss: 0.0004 lr: 0.002\n",
      "iteration: 458000 loss: 0.0004 lr: 0.002\n",
      "iteration: 458100 loss: 0.0004 lr: 0.002\n",
      "iteration: 458200 loss: 0.0004 lr: 0.002\n",
      "iteration: 458300 loss: 0.0005 lr: 0.002\n",
      "iteration: 458400 loss: 0.0005 lr: 0.002\n",
      "iteration: 458500 loss: 0.0005 lr: 0.002\n",
      "iteration: 458600 loss: 0.0005 lr: 0.002\n",
      "iteration: 458700 loss: 0.0004 lr: 0.002\n",
      "iteration: 458800 loss: 0.0004 lr: 0.002\n",
      "iteration: 458900 loss: 0.0004 lr: 0.002\n",
      "iteration: 459000 loss: 0.0004 lr: 0.002\n",
      "iteration: 459100 loss: 0.0005 lr: 0.002\n",
      "iteration: 459200 loss: 0.0003 lr: 0.002\n",
      "iteration: 459300 loss: 0.0005 lr: 0.002\n",
      "iteration: 459400 loss: 0.0005 lr: 0.002\n",
      "iteration: 459500 loss: 0.0004 lr: 0.002\n",
      "iteration: 459600 loss: 0.0004 lr: 0.002\n",
      "iteration: 459700 loss: 0.0004 lr: 0.002\n",
      "iteration: 459800 loss: 0.0005 lr: 0.002\n",
      "iteration: 459900 loss: 0.0003 lr: 0.002\n",
      "iteration: 460000 loss: 0.0003 lr: 0.002\n",
      "iteration: 460100 loss: 0.0005 lr: 0.002\n",
      "iteration: 460200 loss: 0.0004 lr: 0.002\n",
      "iteration: 460300 loss: 0.0003 lr: 0.002\n",
      "iteration: 460400 loss: 0.0004 lr: 0.002\n",
      "iteration: 460500 loss: 0.0004 lr: 0.002\n",
      "iteration: 460600 loss: 0.0004 lr: 0.002\n",
      "iteration: 460700 loss: 0.0005 lr: 0.002\n",
      "iteration: 460800 loss: 0.0004 lr: 0.002\n",
      "iteration: 460900 loss: 0.0004 lr: 0.002\n",
      "iteration: 461000 loss: 0.0004 lr: 0.002\n",
      "iteration: 461100 loss: 0.0004 lr: 0.002\n",
      "iteration: 461200 loss: 0.0004 lr: 0.002\n",
      "iteration: 461300 loss: 0.0004 lr: 0.002\n",
      "iteration: 461400 loss: 0.0004 lr: 0.002\n",
      "iteration: 461500 loss: 0.0005 lr: 0.002\n",
      "iteration: 461600 loss: 0.0004 lr: 0.002\n",
      "iteration: 461700 loss: 0.0004 lr: 0.002\n",
      "iteration: 461800 loss: 0.0004 lr: 0.002\n",
      "iteration: 461900 loss: 0.0005 lr: 0.002\n",
      "iteration: 462000 loss: 0.0005 lr: 0.002\n",
      "iteration: 462100 loss: 0.0003 lr: 0.002\n",
      "iteration: 462200 loss: 0.0004 lr: 0.002\n",
      "iteration: 462300 loss: 0.0004 lr: 0.002\n",
      "iteration: 462400 loss: 0.0004 lr: 0.002\n",
      "iteration: 462500 loss: 0.0004 lr: 0.002\n",
      "iteration: 462600 loss: 0.0004 lr: 0.002\n",
      "iteration: 462700 loss: 0.0005 lr: 0.002\n",
      "iteration: 462800 loss: 0.0004 lr: 0.002\n",
      "iteration: 462900 loss: 0.0004 lr: 0.002\n",
      "iteration: 463000 loss: 0.0005 lr: 0.002\n",
      "iteration: 463100 loss: 0.0004 lr: 0.002\n",
      "iteration: 463200 loss: 0.0004 lr: 0.002\n",
      "iteration: 463300 loss: 0.0005 lr: 0.002\n",
      "iteration: 463400 loss: 0.0004 lr: 0.002\n",
      "iteration: 463500 loss: 0.0005 lr: 0.002\n",
      "iteration: 463600 loss: 0.0004 lr: 0.002\n",
      "iteration: 463700 loss: 0.0004 lr: 0.002\n",
      "iteration: 463800 loss: 0.0005 lr: 0.002\n",
      "iteration: 463900 loss: 0.0004 lr: 0.002\n",
      "iteration: 464000 loss: 0.0004 lr: 0.002\n",
      "iteration: 464100 loss: 0.0004 lr: 0.002\n",
      "iteration: 464200 loss: 0.0004 lr: 0.002\n",
      "iteration: 464300 loss: 0.0003 lr: 0.002\n",
      "iteration: 464400 loss: 0.0003 lr: 0.002\n",
      "iteration: 464500 loss: 0.0004 lr: 0.002\n",
      "iteration: 464600 loss: 0.0004 lr: 0.002\n",
      "iteration: 464700 loss: 0.0004 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 464800 loss: 0.0003 lr: 0.002\n",
      "iteration: 464900 loss: 0.0004 lr: 0.002\n",
      "iteration: 465000 loss: 0.0004 lr: 0.002\n",
      "iteration: 465100 loss: 0.0004 lr: 0.002\n",
      "iteration: 465200 loss: 0.0005 lr: 0.002\n",
      "iteration: 465300 loss: 0.0003 lr: 0.002\n",
      "iteration: 465400 loss: 0.0005 lr: 0.002\n",
      "iteration: 465500 loss: 0.0004 lr: 0.002\n",
      "iteration: 465600 loss: 0.0004 lr: 0.002\n",
      "iteration: 465700 loss: 0.0004 lr: 0.002\n",
      "iteration: 465800 loss: 0.0004 lr: 0.002\n",
      "iteration: 465900 loss: 0.0003 lr: 0.002\n",
      "iteration: 466000 loss: 0.0004 lr: 0.002\n",
      "iteration: 466100 loss: 0.0004 lr: 0.002\n",
      "iteration: 466200 loss: 0.0004 lr: 0.002\n",
      "iteration: 466300 loss: 0.0004 lr: 0.002\n",
      "iteration: 466400 loss: 0.0003 lr: 0.002\n",
      "iteration: 466500 loss: 0.0003 lr: 0.002\n",
      "iteration: 466600 loss: 0.0003 lr: 0.002\n",
      "iteration: 466700 loss: 0.0004 lr: 0.002\n",
      "iteration: 466800 loss: 0.0004 lr: 0.002\n",
      "iteration: 466900 loss: 0.0004 lr: 0.002\n",
      "iteration: 467000 loss: 0.0004 lr: 0.002\n",
      "iteration: 467100 loss: 0.0004 lr: 0.002\n",
      "iteration: 467200 loss: 0.0003 lr: 0.002\n",
      "iteration: 467300 loss: 0.0003 lr: 0.002\n",
      "iteration: 467400 loss: 0.0004 lr: 0.002\n",
      "iteration: 467500 loss: 0.0004 lr: 0.002\n",
      "iteration: 467600 loss: 0.0004 lr: 0.002\n",
      "iteration: 467700 loss: 0.0003 lr: 0.002\n",
      "iteration: 467800 loss: 0.0005 lr: 0.002\n",
      "iteration: 467900 loss: 0.0005 lr: 0.002\n",
      "iteration: 468000 loss: 0.0004 lr: 0.002\n",
      "iteration: 468100 loss: 0.0003 lr: 0.002\n",
      "iteration: 468200 loss: 0.0004 lr: 0.002\n",
      "iteration: 468300 loss: 0.0003 lr: 0.002\n",
      "iteration: 468400 loss: 0.0004 lr: 0.002\n",
      "iteration: 468500 loss: 0.0004 lr: 0.002\n",
      "iteration: 468600 loss: 0.0004 lr: 0.002\n",
      "iteration: 468700 loss: 0.0004 lr: 0.002\n",
      "iteration: 468800 loss: 0.0005 lr: 0.002\n",
      "iteration: 468900 loss: 0.0004 lr: 0.002\n",
      "iteration: 469000 loss: 0.0004 lr: 0.002\n",
      "iteration: 469100 loss: 0.0005 lr: 0.002\n",
      "iteration: 469200 loss: 0.0003 lr: 0.002\n",
      "iteration: 469300 loss: 0.0004 lr: 0.002\n",
      "iteration: 469400 loss: 0.0004 lr: 0.002\n",
      "iteration: 469500 loss: 0.0003 lr: 0.002\n",
      "iteration: 469600 loss: 0.0004 lr: 0.002\n",
      "iteration: 469700 loss: 0.0003 lr: 0.002\n",
      "iteration: 469800 loss: 0.0004 lr: 0.002\n",
      "iteration: 469900 loss: 0.0004 lr: 0.002\n",
      "iteration: 470000 loss: 0.0003 lr: 0.002\n",
      "iteration: 470100 loss: 0.0003 lr: 0.002\n",
      "iteration: 470200 loss: 0.0004 lr: 0.002\n",
      "iteration: 470300 loss: 0.0003 lr: 0.002\n",
      "iteration: 470400 loss: 0.0004 lr: 0.002\n",
      "iteration: 470500 loss: 0.0003 lr: 0.002\n",
      "iteration: 470600 loss: 0.0004 lr: 0.002\n",
      "iteration: 470700 loss: 0.0004 lr: 0.002\n",
      "iteration: 470800 loss: 0.0004 lr: 0.002\n",
      "iteration: 470900 loss: 0.0004 lr: 0.002\n",
      "iteration: 471000 loss: 0.0003 lr: 0.002\n",
      "iteration: 471100 loss: 0.0004 lr: 0.002\n",
      "iteration: 471200 loss: 0.0004 lr: 0.002\n",
      "iteration: 471300 loss: 0.0004 lr: 0.002\n",
      "iteration: 471400 loss: 0.0004 lr: 0.002\n",
      "iteration: 471500 loss: 0.0003 lr: 0.002\n",
      "iteration: 471600 loss: 0.0005 lr: 0.002\n",
      "iteration: 471700 loss: 0.0004 lr: 0.002\n",
      "iteration: 471800 loss: 0.0004 lr: 0.002\n",
      "iteration: 471900 loss: 0.0005 lr: 0.002\n",
      "iteration: 472000 loss: 0.0003 lr: 0.002\n",
      "iteration: 472100 loss: 0.0003 lr: 0.002\n",
      "iteration: 472200 loss: 0.0003 lr: 0.002\n",
      "iteration: 472300 loss: 0.0004 lr: 0.002\n",
      "iteration: 472400 loss: 0.0004 lr: 0.002\n",
      "iteration: 472500 loss: 0.0004 lr: 0.002\n",
      "iteration: 472600 loss: 0.0005 lr: 0.002\n",
      "iteration: 472700 loss: 0.0004 lr: 0.002\n",
      "iteration: 472800 loss: 0.0004 lr: 0.002\n",
      "iteration: 472900 loss: 0.0003 lr: 0.002\n",
      "iteration: 473000 loss: 0.0004 lr: 0.002\n",
      "iteration: 473100 loss: 0.0003 lr: 0.002\n",
      "iteration: 473200 loss: 0.0004 lr: 0.002\n",
      "iteration: 473300 loss: 0.0005 lr: 0.002\n",
      "iteration: 473400 loss: 0.0004 lr: 0.002\n",
      "iteration: 473500 loss: 0.0004 lr: 0.002\n",
      "iteration: 473600 loss: 0.0004 lr: 0.002\n",
      "iteration: 473700 loss: 0.0004 lr: 0.002\n",
      "iteration: 473800 loss: 0.0004 lr: 0.002\n",
      "iteration: 473900 loss: 0.0004 lr: 0.002\n",
      "iteration: 474000 loss: 0.0004 lr: 0.002\n",
      "iteration: 474100 loss: 0.0004 lr: 0.002\n",
      "iteration: 474200 loss: 0.0003 lr: 0.002\n",
      "iteration: 474300 loss: 0.0004 lr: 0.002\n",
      "iteration: 474400 loss: 0.0003 lr: 0.002\n",
      "iteration: 474500 loss: 0.0004 lr: 0.002\n",
      "iteration: 474600 loss: 0.0004 lr: 0.002\n",
      "iteration: 474700 loss: 0.0003 lr: 0.002\n",
      "iteration: 474800 loss: 0.0004 lr: 0.002\n",
      "iteration: 474900 loss: 0.0004 lr: 0.002\n",
      "iteration: 475000 loss: 0.0005 lr: 0.002\n",
      "iteration: 475100 loss: 0.0004 lr: 0.002\n",
      "iteration: 475200 loss: 0.0004 lr: 0.002\n",
      "iteration: 475300 loss: 0.0004 lr: 0.002\n",
      "iteration: 475400 loss: 0.0004 lr: 0.002\n",
      "iteration: 475500 loss: 0.0004 lr: 0.002\n",
      "iteration: 475600 loss: 0.0004 lr: 0.002\n",
      "iteration: 475700 loss: 0.0004 lr: 0.002\n",
      "iteration: 475800 loss: 0.0004 lr: 0.002\n",
      "iteration: 475900 loss: 0.0004 lr: 0.002\n",
      "iteration: 476000 loss: 0.0004 lr: 0.002\n",
      "iteration: 476100 loss: 0.0004 lr: 0.002\n",
      "iteration: 476200 loss: 0.0004 lr: 0.002\n",
      "iteration: 476300 loss: 0.0004 lr: 0.002\n",
      "iteration: 476400 loss: 0.0004 lr: 0.002\n",
      "iteration: 476500 loss: 0.0004 lr: 0.002\n",
      "iteration: 476600 loss: 0.0005 lr: 0.002\n",
      "iteration: 476700 loss: 0.0004 lr: 0.002\n",
      "iteration: 476800 loss: 0.0003 lr: 0.002\n",
      "iteration: 476900 loss: 0.0004 lr: 0.002\n",
      "iteration: 477000 loss: 0.0004 lr: 0.002\n",
      "iteration: 477100 loss: 0.0004 lr: 0.002\n",
      "iteration: 477200 loss: 0.0004 lr: 0.002\n",
      "iteration: 477300 loss: 0.0003 lr: 0.002\n",
      "iteration: 477400 loss: 0.0004 lr: 0.002\n",
      "iteration: 477500 loss: 0.0003 lr: 0.002\n",
      "iteration: 477600 loss: 0.0004 lr: 0.002\n",
      "iteration: 477700 loss: 0.0004 lr: 0.002\n",
      "iteration: 477800 loss: 0.0004 lr: 0.002\n",
      "iteration: 477900 loss: 0.0004 lr: 0.002\n",
      "iteration: 478000 loss: 0.0004 lr: 0.002\n",
      "iteration: 478100 loss: 0.0003 lr: 0.002\n",
      "iteration: 478200 loss: 0.0004 lr: 0.002\n",
      "iteration: 478300 loss: 0.0004 lr: 0.002\n",
      "iteration: 478400 loss: 0.0004 lr: 0.002\n",
      "iteration: 478500 loss: 0.0003 lr: 0.002\n",
      "iteration: 478600 loss: 0.0004 lr: 0.002\n",
      "iteration: 478700 loss: 0.0004 lr: 0.002\n",
      "iteration: 478800 loss: 0.0003 lr: 0.002\n",
      "iteration: 478900 loss: 0.0004 lr: 0.002\n",
      "iteration: 479000 loss: 0.0003 lr: 0.002\n",
      "iteration: 479100 loss: 0.0003 lr: 0.002\n",
      "iteration: 479200 loss: 0.0004 lr: 0.002\n",
      "iteration: 479300 loss: 0.0005 lr: 0.002\n",
      "iteration: 479400 loss: 0.0003 lr: 0.002\n",
      "iteration: 479500 loss: 0.0004 lr: 0.002\n",
      "iteration: 479600 loss: 0.0004 lr: 0.002\n",
      "iteration: 479700 loss: 0.0003 lr: 0.002\n",
      "iteration: 479800 loss: 0.0004 lr: 0.002\n",
      "iteration: 479900 loss: 0.0004 lr: 0.002\n",
      "iteration: 480000 loss: 0.0003 lr: 0.002\n",
      "iteration: 480100 loss: 0.0005 lr: 0.002\n",
      "iteration: 480200 loss: 0.0004 lr: 0.002\n",
      "iteration: 480300 loss: 0.0004 lr: 0.002\n",
      "iteration: 480400 loss: 0.0003 lr: 0.002\n",
      "iteration: 480500 loss: 0.0003 lr: 0.002\n",
      "iteration: 480600 loss: 0.0003 lr: 0.002\n",
      "iteration: 480700 loss: 0.0004 lr: 0.002\n",
      "iteration: 480800 loss: 0.0004 lr: 0.002\n",
      "iteration: 480900 loss: 0.0004 lr: 0.002\n",
      "iteration: 481000 loss: 0.0003 lr: 0.002\n",
      "iteration: 481100 loss: 0.0004 lr: 0.002\n",
      "iteration: 481200 loss: 0.0004 lr: 0.002\n",
      "iteration: 481300 loss: 0.0005 lr: 0.002\n",
      "iteration: 481400 loss: 0.0004 lr: 0.002\n",
      "iteration: 481500 loss: 0.0005 lr: 0.002\n",
      "iteration: 481600 loss: 0.0004 lr: 0.002\n",
      "iteration: 481700 loss: 0.0003 lr: 0.002\n",
      "iteration: 481800 loss: 0.0005 lr: 0.002\n",
      "iteration: 481900 loss: 0.0004 lr: 0.002\n",
      "iteration: 482000 loss: 0.0003 lr: 0.002\n",
      "iteration: 482100 loss: 0.0004 lr: 0.002\n",
      "iteration: 482200 loss: 0.0003 lr: 0.002\n",
      "iteration: 482300 loss: 0.0004 lr: 0.002\n",
      "iteration: 482400 loss: 0.0004 lr: 0.002\n",
      "iteration: 482500 loss: 0.0003 lr: 0.002\n",
      "iteration: 482600 loss: 0.0004 lr: 0.002\n",
      "iteration: 482700 loss: 0.0004 lr: 0.002\n",
      "iteration: 482800 loss: 0.0004 lr: 0.002\n",
      "iteration: 482900 loss: 0.0004 lr: 0.002\n",
      "iteration: 483000 loss: 0.0003 lr: 0.002\n",
      "iteration: 483100 loss: 0.0005 lr: 0.002\n",
      "iteration: 483200 loss: 0.0004 lr: 0.002\n",
      "iteration: 483300 loss: 0.0004 lr: 0.002\n",
      "iteration: 483400 loss: 0.0003 lr: 0.002\n",
      "iteration: 483500 loss: 0.0004 lr: 0.002\n",
      "iteration: 483600 loss: 0.0003 lr: 0.002\n",
      "iteration: 483700 loss: 0.0004 lr: 0.002\n",
      "iteration: 483800 loss: 0.0004 lr: 0.002\n",
      "iteration: 483900 loss: 0.0004 lr: 0.002\n",
      "iteration: 484000 loss: 0.0004 lr: 0.002\n",
      "iteration: 484100 loss: 0.0004 lr: 0.002\n",
      "iteration: 484200 loss: 0.0004 lr: 0.002\n",
      "iteration: 484300 loss: 0.0004 lr: 0.002\n",
      "iteration: 484400 loss: 0.0004 lr: 0.002\n",
      "iteration: 484500 loss: 0.0004 lr: 0.002\n",
      "iteration: 484600 loss: 0.0003 lr: 0.002\n",
      "iteration: 484700 loss: 0.0003 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 484800 loss: 0.0003 lr: 0.002\n",
      "iteration: 484900 loss: 0.0004 lr: 0.002\n",
      "iteration: 485000 loss: 0.0003 lr: 0.002\n",
      "iteration: 485100 loss: 0.0004 lr: 0.002\n",
      "iteration: 485200 loss: 0.0004 lr: 0.002\n",
      "iteration: 485300 loss: 0.0004 lr: 0.002\n",
      "iteration: 485400 loss: 0.0004 lr: 0.002\n",
      "iteration: 485500 loss: 0.0004 lr: 0.002\n",
      "iteration: 485600 loss: 0.0005 lr: 0.002\n",
      "iteration: 485700 loss: 0.0003 lr: 0.002\n",
      "iteration: 485800 loss: 0.0003 lr: 0.002\n",
      "iteration: 485900 loss: 0.0004 lr: 0.002\n",
      "iteration: 486000 loss: 0.0004 lr: 0.002\n",
      "iteration: 486100 loss: 0.0003 lr: 0.002\n",
      "iteration: 486200 loss: 0.0003 lr: 0.002\n",
      "iteration: 486300 loss: 0.0004 lr: 0.002\n",
      "iteration: 486400 loss: 0.0004 lr: 0.002\n",
      "iteration: 486500 loss: 0.0004 lr: 0.002\n",
      "iteration: 486600 loss: 0.0004 lr: 0.002\n",
      "iteration: 486700 loss: 0.0004 lr: 0.002\n",
      "iteration: 486800 loss: 0.0003 lr: 0.002\n",
      "iteration: 486900 loss: 0.0004 lr: 0.002\n",
      "iteration: 487000 loss: 0.0003 lr: 0.002\n",
      "iteration: 487100 loss: 0.0004 lr: 0.002\n",
      "iteration: 487200 loss: 0.0004 lr: 0.002\n",
      "iteration: 487300 loss: 0.0004 lr: 0.002\n",
      "iteration: 487400 loss: 0.0004 lr: 0.002\n",
      "iteration: 487500 loss: 0.0005 lr: 0.002\n",
      "iteration: 487600 loss: 0.0004 lr: 0.002\n",
      "iteration: 487700 loss: 0.0003 lr: 0.002\n",
      "iteration: 487800 loss: 0.0004 lr: 0.002\n",
      "iteration: 487900 loss: 0.0004 lr: 0.002\n",
      "iteration: 488000 loss: 0.0004 lr: 0.002\n",
      "iteration: 488100 loss: 0.0004 lr: 0.002\n",
      "iteration: 488200 loss: 0.0004 lr: 0.002\n",
      "iteration: 488300 loss: 0.0003 lr: 0.002\n",
      "iteration: 488400 loss: 0.0004 lr: 0.002\n",
      "iteration: 488500 loss: 0.0004 lr: 0.002\n",
      "iteration: 488600 loss: 0.0004 lr: 0.002\n",
      "iteration: 488700 loss: 0.0004 lr: 0.002\n",
      "iteration: 488800 loss: 0.0003 lr: 0.002\n",
      "iteration: 488900 loss: 0.0004 lr: 0.002\n",
      "iteration: 489000 loss: 0.0003 lr: 0.002\n",
      "iteration: 489100 loss: 0.0003 lr: 0.002\n",
      "iteration: 489200 loss: 0.0003 lr: 0.002\n",
      "iteration: 489300 loss: 0.0004 lr: 0.002\n",
      "iteration: 489400 loss: 0.0004 lr: 0.002\n",
      "iteration: 489500 loss: 0.0004 lr: 0.002\n",
      "iteration: 489600 loss: 0.0004 lr: 0.002\n",
      "iteration: 489700 loss: 0.0003 lr: 0.002\n",
      "iteration: 489800 loss: 0.0004 lr: 0.002\n",
      "iteration: 489900 loss: 0.0004 lr: 0.002\n",
      "iteration: 490000 loss: 0.0004 lr: 0.002\n",
      "iteration: 490100 loss: 0.0003 lr: 0.002\n",
      "iteration: 490200 loss: 0.0003 lr: 0.002\n",
      "iteration: 490300 loss: 0.0003 lr: 0.002\n",
      "iteration: 490400 loss: 0.0003 lr: 0.002\n",
      "iteration: 490500 loss: 0.0004 lr: 0.002\n",
      "iteration: 490600 loss: 0.0005 lr: 0.002\n",
      "iteration: 490700 loss: 0.0004 lr: 0.002\n",
      "iteration: 490800 loss: 0.0004 lr: 0.002\n",
      "iteration: 490900 loss: 0.0004 lr: 0.002\n",
      "iteration: 491000 loss: 0.0004 lr: 0.002\n",
      "iteration: 491100 loss: 0.0004 lr: 0.002\n",
      "iteration: 491200 loss: 0.0003 lr: 0.002\n",
      "iteration: 491300 loss: 0.0003 lr: 0.002\n",
      "iteration: 491400 loss: 0.0004 lr: 0.002\n",
      "iteration: 491500 loss: 0.0003 lr: 0.002\n",
      "iteration: 491600 loss: 0.0004 lr: 0.002\n",
      "iteration: 491700 loss: 0.0004 lr: 0.002\n",
      "iteration: 491800 loss: 0.0003 lr: 0.002\n",
      "iteration: 491900 loss: 0.0004 lr: 0.002\n",
      "iteration: 492000 loss: 0.0004 lr: 0.002\n",
      "iteration: 492100 loss: 0.0004 lr: 0.002\n",
      "iteration: 492200 loss: 0.0004 lr: 0.002\n",
      "iteration: 492300 loss: 0.0003 lr: 0.002\n",
      "iteration: 492400 loss: 0.0004 lr: 0.002\n",
      "iteration: 492500 loss: 0.0004 lr: 0.002\n",
      "iteration: 492600 loss: 0.0003 lr: 0.002\n",
      "iteration: 492700 loss: 0.0004 lr: 0.002\n",
      "iteration: 492800 loss: 0.0004 lr: 0.002\n",
      "iteration: 492900 loss: 0.0004 lr: 0.002\n",
      "iteration: 493000 loss: 0.0004 lr: 0.002\n",
      "iteration: 493100 loss: 0.0005 lr: 0.002\n",
      "iteration: 493200 loss: 0.0003 lr: 0.002\n",
      "iteration: 493300 loss: 0.0003 lr: 0.002\n",
      "iteration: 493400 loss: 0.0003 lr: 0.002\n",
      "iteration: 493500 loss: 0.0003 lr: 0.002\n",
      "iteration: 493600 loss: 0.0003 lr: 0.002\n",
      "iteration: 493700 loss: 0.0003 lr: 0.002\n",
      "iteration: 493800 loss: 0.0004 lr: 0.002\n",
      "iteration: 493900 loss: 0.0003 lr: 0.002\n",
      "iteration: 494000 loss: 0.0003 lr: 0.002\n",
      "iteration: 494100 loss: 0.0004 lr: 0.002\n",
      "iteration: 494200 loss: 0.0004 lr: 0.002\n",
      "iteration: 494300 loss: 0.0004 lr: 0.002\n",
      "iteration: 494400 loss: 0.0004 lr: 0.002\n",
      "iteration: 494500 loss: 0.0004 lr: 0.002\n",
      "iteration: 494600 loss: 0.0003 lr: 0.002\n",
      "iteration: 494700 loss: 0.0003 lr: 0.002\n",
      "iteration: 494800 loss: 0.0003 lr: 0.002\n",
      "iteration: 494900 loss: 0.0004 lr: 0.002\n",
      "iteration: 495000 loss: 0.0003 lr: 0.002\n",
      "iteration: 495100 loss: 0.0004 lr: 0.002\n",
      "iteration: 495200 loss: 0.0004 lr: 0.002\n",
      "iteration: 495300 loss: 0.0004 lr: 0.002\n",
      "iteration: 495400 loss: 0.0005 lr: 0.002\n",
      "iteration: 495500 loss: 0.0003 lr: 0.002\n",
      "iteration: 495600 loss: 0.0004 lr: 0.002\n",
      "iteration: 495700 loss: 0.0004 lr: 0.002\n",
      "iteration: 495800 loss: 0.0004 lr: 0.002\n",
      "iteration: 495900 loss: 0.0004 lr: 0.002\n",
      "iteration: 496000 loss: 0.0003 lr: 0.002\n",
      "iteration: 496100 loss: 0.0004 lr: 0.002\n",
      "iteration: 496200 loss: 0.0004 lr: 0.002\n",
      "iteration: 496300 loss: 0.0004 lr: 0.002\n",
      "iteration: 496400 loss: 0.0003 lr: 0.002\n",
      "iteration: 496500 loss: 0.0004 lr: 0.002\n",
      "iteration: 496600 loss: 0.0004 lr: 0.002\n",
      "iteration: 496700 loss: 0.0003 lr: 0.002\n",
      "iteration: 496800 loss: 0.0003 lr: 0.002\n",
      "iteration: 496900 loss: 0.0004 lr: 0.002\n",
      "iteration: 497000 loss: 0.0004 lr: 0.002\n",
      "iteration: 497100 loss: 0.0004 lr: 0.002\n",
      "iteration: 497200 loss: 0.0004 lr: 0.002\n",
      "iteration: 497300 loss: 0.0005 lr: 0.002\n",
      "iteration: 497400 loss: 0.0003 lr: 0.002\n",
      "iteration: 497500 loss: 0.0004 lr: 0.002\n",
      "iteration: 497600 loss: 0.0004 lr: 0.002\n",
      "iteration: 497700 loss: 0.0004 lr: 0.002\n",
      "iteration: 497800 loss: 0.0005 lr: 0.002\n",
      "iteration: 497900 loss: 0.0004 lr: 0.002\n",
      "iteration: 498000 loss: 0.0003 lr: 0.002\n",
      "iteration: 498100 loss: 0.0004 lr: 0.002\n",
      "iteration: 498200 loss: 0.0003 lr: 0.002\n",
      "iteration: 498300 loss: 0.0004 lr: 0.002\n",
      "iteration: 498400 loss: 0.0003 lr: 0.002\n",
      "iteration: 498500 loss: 0.0004 lr: 0.002\n",
      "iteration: 498600 loss: 0.0003 lr: 0.002\n",
      "iteration: 498700 loss: 0.0003 lr: 0.002\n",
      "iteration: 498800 loss: 0.0004 lr: 0.002\n",
      "iteration: 498900 loss: 0.0003 lr: 0.002\n",
      "iteration: 499000 loss: 0.0004 lr: 0.002\n",
      "iteration: 499100 loss: 0.0004 lr: 0.002\n",
      "iteration: 499200 loss: 0.0005 lr: 0.002\n",
      "iteration: 499300 loss: 0.0003 lr: 0.002\n",
      "iteration: 499400 loss: 0.0004 lr: 0.002\n",
      "iteration: 499500 loss: 0.0003 lr: 0.002\n",
      "iteration: 499600 loss: 0.0004 lr: 0.002\n",
      "iteration: 499700 loss: 0.0004 lr: 0.002\n",
      "iteration: 499800 loss: 0.0004 lr: 0.002\n",
      "iteration: 499900 loss: 0.0004 lr: 0.002\n",
      "iteration: 500000 loss: 0.0003 lr: 0.002\n",
      "iteration: 500100 loss: 0.0004 lr: 0.002\n",
      "iteration: 500200 loss: 0.0004 lr: 0.002\n",
      "iteration: 500300 loss: 0.0004 lr: 0.002\n",
      "iteration: 500400 loss: 0.0004 lr: 0.002\n",
      "iteration: 500500 loss: 0.0004 lr: 0.002\n",
      "iteration: 500600 loss: 0.0003 lr: 0.002\n",
      "iteration: 500700 loss: 0.0004 lr: 0.002\n",
      "iteration: 500800 loss: 0.0004 lr: 0.002\n",
      "iteration: 500900 loss: 0.0004 lr: 0.002\n",
      "iteration: 501000 loss: 0.0004 lr: 0.002\n",
      "iteration: 501100 loss: 0.0004 lr: 0.002\n",
      "iteration: 501200 loss: 0.0004 lr: 0.002\n",
      "iteration: 501300 loss: 0.0003 lr: 0.002\n",
      "iteration: 501400 loss: 0.0003 lr: 0.002\n",
      "iteration: 501500 loss: 0.0003 lr: 0.002\n",
      "iteration: 501600 loss: 0.0003 lr: 0.002\n",
      "iteration: 501700 loss: 0.0004 lr: 0.002\n",
      "iteration: 501800 loss: 0.0004 lr: 0.002\n",
      "iteration: 501900 loss: 0.0004 lr: 0.002\n",
      "iteration: 502000 loss: 0.0003 lr: 0.002\n",
      "iteration: 502100 loss: 0.0004 lr: 0.002\n",
      "iteration: 502200 loss: 0.0004 lr: 0.002\n",
      "iteration: 502300 loss: 0.0004 lr: 0.002\n",
      "iteration: 502400 loss: 0.0003 lr: 0.002\n",
      "iteration: 502500 loss: 0.0003 lr: 0.002\n",
      "iteration: 502600 loss: 0.0003 lr: 0.002\n",
      "iteration: 502700 loss: 0.0004 lr: 0.002\n",
      "iteration: 502800 loss: 0.0003 lr: 0.002\n",
      "iteration: 502900 loss: 0.0004 lr: 0.002\n",
      "iteration: 503000 loss: 0.0004 lr: 0.002\n",
      "iteration: 503100 loss: 0.0004 lr: 0.002\n",
      "iteration: 503200 loss: 0.0003 lr: 0.002\n",
      "iteration: 503300 loss: 0.0004 lr: 0.002\n",
      "iteration: 503400 loss: 0.0005 lr: 0.002\n",
      "iteration: 503500 loss: 0.0004 lr: 0.002\n",
      "iteration: 503600 loss: 0.0004 lr: 0.002\n",
      "iteration: 503700 loss: 0.0003 lr: 0.002\n",
      "iteration: 503800 loss: 0.0003 lr: 0.002\n",
      "iteration: 503900 loss: 0.0004 lr: 0.002\n",
      "iteration: 504000 loss: 0.0003 lr: 0.002\n",
      "iteration: 504100 loss: 0.0004 lr: 0.002\n",
      "iteration: 504200 loss: 0.0004 lr: 0.002\n",
      "iteration: 504300 loss: 0.0004 lr: 0.002\n",
      "iteration: 504400 loss: 0.0003 lr: 0.002\n",
      "iteration: 504500 loss: 0.0003 lr: 0.002\n",
      "iteration: 504600 loss: 0.0004 lr: 0.002\n",
      "iteration: 504700 loss: 0.0003 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 504800 loss: 0.0004 lr: 0.002\n",
      "iteration: 504900 loss: 0.0003 lr: 0.002\n",
      "iteration: 505000 loss: 0.0004 lr: 0.002\n",
      "iteration: 505100 loss: 0.0004 lr: 0.002\n",
      "iteration: 505200 loss: 0.0004 lr: 0.002\n",
      "iteration: 505300 loss: 0.0004 lr: 0.002\n",
      "iteration: 505400 loss: 0.0004 lr: 0.002\n",
      "iteration: 505500 loss: 0.0003 lr: 0.002\n",
      "iteration: 505600 loss: 0.0004 lr: 0.002\n",
      "iteration: 505700 loss: 0.0004 lr: 0.002\n",
      "iteration: 505800 loss: 0.0004 lr: 0.002\n",
      "iteration: 505900 loss: 0.0003 lr: 0.002\n",
      "iteration: 506000 loss: 0.0003 lr: 0.002\n",
      "iteration: 506100 loss: 0.0003 lr: 0.002\n",
      "iteration: 506200 loss: 0.0003 lr: 0.002\n",
      "iteration: 506300 loss: 0.0003 lr: 0.002\n",
      "iteration: 506400 loss: 0.0003 lr: 0.002\n",
      "iteration: 506500 loss: 0.0004 lr: 0.002\n",
      "iteration: 506600 loss: 0.0003 lr: 0.002\n",
      "iteration: 506700 loss: 0.0003 lr: 0.002\n",
      "iteration: 506800 loss: 0.0003 lr: 0.002\n",
      "iteration: 506900 loss: 0.0003 lr: 0.002\n",
      "iteration: 507000 loss: 0.0004 lr: 0.002\n",
      "iteration: 507100 loss: 0.0003 lr: 0.002\n",
      "iteration: 507200 loss: 0.0004 lr: 0.002\n",
      "iteration: 507300 loss: 0.0004 lr: 0.002\n",
      "iteration: 507400 loss: 0.0003 lr: 0.002\n",
      "iteration: 507500 loss: 0.0004 lr: 0.002\n",
      "iteration: 507600 loss: 0.0004 lr: 0.002\n",
      "iteration: 507700 loss: 0.0003 lr: 0.002\n",
      "iteration: 507800 loss: 0.0004 lr: 0.002\n",
      "iteration: 507900 loss: 0.0003 lr: 0.002\n",
      "iteration: 508000 loss: 0.0004 lr: 0.002\n",
      "iteration: 508100 loss: 0.0005 lr: 0.002\n",
      "iteration: 508200 loss: 0.0004 lr: 0.002\n",
      "iteration: 508300 loss: 0.0003 lr: 0.002\n",
      "iteration: 508400 loss: 0.0004 lr: 0.002\n",
      "iteration: 508500 loss: 0.0003 lr: 0.002\n",
      "iteration: 508600 loss: 0.0003 lr: 0.002\n",
      "iteration: 508700 loss: 0.0003 lr: 0.002\n",
      "iteration: 508800 loss: 0.0004 lr: 0.002\n",
      "iteration: 508900 loss: 0.0003 lr: 0.002\n",
      "iteration: 509000 loss: 0.0003 lr: 0.002\n",
      "iteration: 509100 loss: 0.0004 lr: 0.002\n",
      "iteration: 509200 loss: 0.0004 lr: 0.002\n",
      "iteration: 509300 loss: 0.0004 lr: 0.002\n",
      "iteration: 509400 loss: 0.0003 lr: 0.002\n",
      "iteration: 509500 loss: 0.0005 lr: 0.002\n",
      "iteration: 509600 loss: 0.0004 lr: 0.002\n",
      "iteration: 509700 loss: 0.0004 lr: 0.002\n",
      "iteration: 509800 loss: 0.0005 lr: 0.002\n",
      "iteration: 509900 loss: 0.0004 lr: 0.002\n",
      "iteration: 510000 loss: 0.0004 lr: 0.002\n",
      "iteration: 510100 loss: 0.0003 lr: 0.002\n",
      "iteration: 510200 loss: 0.0003 lr: 0.002\n",
      "iteration: 510300 loss: 0.0003 lr: 0.002\n",
      "iteration: 510400 loss: 0.0004 lr: 0.002\n",
      "iteration: 510500 loss: 0.0004 lr: 0.002\n",
      "iteration: 510600 loss: 0.0003 lr: 0.002\n",
      "iteration: 510700 loss: 0.0003 lr: 0.002\n",
      "iteration: 510800 loss: 0.0004 lr: 0.002\n",
      "iteration: 510900 loss: 0.0003 lr: 0.002\n",
      "iteration: 511000 loss: 0.0003 lr: 0.002\n",
      "iteration: 511100 loss: 0.0003 lr: 0.002\n",
      "iteration: 511200 loss: 0.0004 lr: 0.002\n",
      "iteration: 511300 loss: 0.0003 lr: 0.002\n",
      "iteration: 511400 loss: 0.0004 lr: 0.002\n",
      "iteration: 511500 loss: 0.0003 lr: 0.002\n",
      "iteration: 511600 loss: 0.0003 lr: 0.002\n",
      "iteration: 511700 loss: 0.0004 lr: 0.002\n",
      "iteration: 511800 loss: 0.0003 lr: 0.002\n",
      "iteration: 511900 loss: 0.0003 lr: 0.002\n",
      "iteration: 512000 loss: 0.0003 lr: 0.002\n",
      "iteration: 512100 loss: 0.0003 lr: 0.002\n",
      "iteration: 512200 loss: 0.0004 lr: 0.002\n",
      "iteration: 512300 loss: 0.0004 lr: 0.002\n",
      "iteration: 512400 loss: 0.0004 lr: 0.002\n",
      "iteration: 512500 loss: 0.0003 lr: 0.002\n",
      "iteration: 512600 loss: 0.0004 lr: 0.002\n",
      "iteration: 512700 loss: 0.0003 lr: 0.002\n",
      "iteration: 512800 loss: 0.0004 lr: 0.002\n",
      "iteration: 512900 loss: 0.0003 lr: 0.002\n",
      "iteration: 513000 loss: 0.0003 lr: 0.002\n",
      "iteration: 513100 loss: 0.0003 lr: 0.002\n",
      "iteration: 513200 loss: 0.0003 lr: 0.002\n",
      "iteration: 513300 loss: 0.0004 lr: 0.002\n",
      "iteration: 513400 loss: 0.0003 lr: 0.002\n",
      "iteration: 513500 loss: 0.0005 lr: 0.002\n",
      "iteration: 513600 loss: 0.0003 lr: 0.002\n",
      "iteration: 513700 loss: 0.0004 lr: 0.002\n",
      "iteration: 513800 loss: 0.0004 lr: 0.002\n",
      "iteration: 513900 loss: 0.0003 lr: 0.002\n",
      "iteration: 514000 loss: 0.0003 lr: 0.002\n",
      "iteration: 514100 loss: 0.0003 lr: 0.002\n",
      "iteration: 514200 loss: 0.0004 lr: 0.002\n",
      "iteration: 514300 loss: 0.0003 lr: 0.002\n",
      "iteration: 514400 loss: 0.0005 lr: 0.002\n",
      "iteration: 514500 loss: 0.0003 lr: 0.002\n",
      "iteration: 514600 loss: 0.0004 lr: 0.002\n",
      "iteration: 514700 loss: 0.0004 lr: 0.002\n",
      "iteration: 514800 loss: 0.0004 lr: 0.002\n",
      "iteration: 514900 loss: 0.0004 lr: 0.002\n",
      "iteration: 515000 loss: 0.0003 lr: 0.002\n",
      "iteration: 515100 loss: 0.0004 lr: 0.002\n",
      "iteration: 515200 loss: 0.0004 lr: 0.002\n",
      "iteration: 515300 loss: 0.0003 lr: 0.002\n",
      "iteration: 515400 loss: 0.0003 lr: 0.002\n",
      "iteration: 515500 loss: 0.0004 lr: 0.002\n",
      "iteration: 515600 loss: 0.0003 lr: 0.002\n",
      "iteration: 515700 loss: 0.0004 lr: 0.002\n",
      "iteration: 515800 loss: 0.0003 lr: 0.002\n",
      "iteration: 515900 loss: 0.0004 lr: 0.002\n",
      "iteration: 516000 loss: 0.0004 lr: 0.002\n",
      "iteration: 516100 loss: 0.0004 lr: 0.002\n",
      "iteration: 516200 loss: 0.0003 lr: 0.002\n",
      "iteration: 516300 loss: 0.0004 lr: 0.002\n",
      "iteration: 516400 loss: 0.0004 lr: 0.002\n",
      "iteration: 516500 loss: 0.0004 lr: 0.002\n",
      "iteration: 516600 loss: 0.0003 lr: 0.002\n",
      "iteration: 516700 loss: 0.0003 lr: 0.002\n",
      "iteration: 516800 loss: 0.0003 lr: 0.002\n",
      "iteration: 516900 loss: 0.0003 lr: 0.002\n",
      "iteration: 517000 loss: 0.0003 lr: 0.002\n",
      "iteration: 517100 loss: 0.0005 lr: 0.002\n",
      "iteration: 517200 loss: 0.0003 lr: 0.002\n",
      "iteration: 517300 loss: 0.0003 lr: 0.002\n",
      "iteration: 517400 loss: 0.0004 lr: 0.002\n",
      "iteration: 517500 loss: 0.0004 lr: 0.002\n",
      "iteration: 517600 loss: 0.0004 lr: 0.002\n",
      "iteration: 517700 loss: 0.0003 lr: 0.002\n",
      "iteration: 517800 loss: 0.0003 lr: 0.002\n",
      "iteration: 517900 loss: 0.0003 lr: 0.002\n",
      "iteration: 518000 loss: 0.0004 lr: 0.002\n",
      "iteration: 518100 loss: 0.0004 lr: 0.002\n",
      "iteration: 518200 loss: 0.0003 lr: 0.002\n",
      "iteration: 518300 loss: 0.0004 lr: 0.002\n",
      "iteration: 518400 loss: 0.0003 lr: 0.002\n",
      "iteration: 518500 loss: 0.0003 lr: 0.002\n",
      "iteration: 518600 loss: 0.0003 lr: 0.002\n",
      "iteration: 518700 loss: 0.0003 lr: 0.002\n",
      "iteration: 518800 loss: 0.0003 lr: 0.002\n",
      "iteration: 518900 loss: 0.0003 lr: 0.002\n",
      "iteration: 519000 loss: 0.0003 lr: 0.002\n",
      "iteration: 519100 loss: 0.0003 lr: 0.002\n",
      "iteration: 519200 loss: 0.0004 lr: 0.002\n",
      "iteration: 519300 loss: 0.0003 lr: 0.002\n",
      "iteration: 519400 loss: 0.0004 lr: 0.002\n",
      "iteration: 519500 loss: 0.0003 lr: 0.002\n",
      "iteration: 519600 loss: 0.0003 lr: 0.002\n",
      "iteration: 519700 loss: 0.0004 lr: 0.002\n",
      "iteration: 519800 loss: 0.0005 lr: 0.002\n",
      "iteration: 519900 loss: 0.0003 lr: 0.002\n",
      "iteration: 520000 loss: 0.0003 lr: 0.002\n",
      "iteration: 520100 loss: 0.0004 lr: 0.002\n",
      "iteration: 520200 loss: 0.0004 lr: 0.002\n",
      "iteration: 520300 loss: 0.0003 lr: 0.002\n",
      "iteration: 520400 loss: 0.0003 lr: 0.002\n",
      "iteration: 520500 loss: 0.0003 lr: 0.002\n",
      "iteration: 520600 loss: 0.0004 lr: 0.002\n",
      "iteration: 520700 loss: 0.0003 lr: 0.002\n",
      "iteration: 520800 loss: 0.0004 lr: 0.002\n",
      "iteration: 520900 loss: 0.0004 lr: 0.002\n",
      "iteration: 521000 loss: 0.0004 lr: 0.002\n",
      "iteration: 521100 loss: 0.0004 lr: 0.002\n",
      "iteration: 521200 loss: 0.0003 lr: 0.002\n",
      "iteration: 521300 loss: 0.0003 lr: 0.002\n",
      "iteration: 521400 loss: 0.0003 lr: 0.002\n",
      "iteration: 521500 loss: 0.0003 lr: 0.002\n",
      "iteration: 521600 loss: 0.0003 lr: 0.002\n",
      "iteration: 521700 loss: 0.0003 lr: 0.002\n",
      "iteration: 521800 loss: 0.0003 lr: 0.002\n",
      "iteration: 521900 loss: 0.0004 lr: 0.002\n",
      "iteration: 522000 loss: 0.0004 lr: 0.002\n",
      "iteration: 522100 loss: 0.0003 lr: 0.002\n",
      "iteration: 522200 loss: 0.0003 lr: 0.002\n",
      "iteration: 522300 loss: 0.0004 lr: 0.002\n",
      "iteration: 522400 loss: 0.0003 lr: 0.002\n",
      "iteration: 522500 loss: 0.0004 lr: 0.002\n",
      "iteration: 522600 loss: 0.0004 lr: 0.002\n",
      "iteration: 522700 loss: 0.0003 lr: 0.002\n",
      "iteration: 522800 loss: 0.0004 lr: 0.002\n",
      "iteration: 522900 loss: 0.0004 lr: 0.002\n",
      "iteration: 523000 loss: 0.0004 lr: 0.002\n",
      "iteration: 523100 loss: 0.0003 lr: 0.002\n",
      "iteration: 523200 loss: 0.0003 lr: 0.002\n",
      "iteration: 523300 loss: 0.0003 lr: 0.002\n",
      "iteration: 523400 loss: 0.0003 lr: 0.002\n",
      "iteration: 523500 loss: 0.0005 lr: 0.002\n",
      "iteration: 523600 loss: 0.0003 lr: 0.002\n",
      "iteration: 523700 loss: 0.0004 lr: 0.002\n",
      "iteration: 523800 loss: 0.0003 lr: 0.002\n",
      "iteration: 523900 loss: 0.0003 lr: 0.002\n",
      "iteration: 524000 loss: 0.0003 lr: 0.002\n",
      "iteration: 524100 loss: 0.0004 lr: 0.002\n",
      "iteration: 524200 loss: 0.0003 lr: 0.002\n",
      "iteration: 524300 loss: 0.0004 lr: 0.002\n",
      "iteration: 524400 loss: 0.0003 lr: 0.002\n",
      "iteration: 524500 loss: 0.0004 lr: 0.002\n",
      "iteration: 524600 loss: 0.0003 lr: 0.002\n",
      "iteration: 524700 loss: 0.0004 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 524800 loss: 0.0003 lr: 0.002\n",
      "iteration: 524900 loss: 0.0004 lr: 0.002\n",
      "iteration: 525000 loss: 0.0004 lr: 0.002\n",
      "iteration: 525100 loss: 0.0004 lr: 0.002\n",
      "iteration: 525200 loss: 0.0003 lr: 0.002\n",
      "iteration: 525300 loss: 0.0003 lr: 0.002\n",
      "iteration: 525400 loss: 0.0004 lr: 0.002\n",
      "iteration: 525500 loss: 0.0003 lr: 0.002\n",
      "iteration: 525600 loss: 0.0004 lr: 0.002\n",
      "iteration: 525700 loss: 0.0003 lr: 0.002\n",
      "iteration: 525800 loss: 0.0003 lr: 0.002\n",
      "iteration: 525900 loss: 0.0004 lr: 0.002\n",
      "iteration: 526000 loss: 0.0003 lr: 0.002\n",
      "iteration: 526100 loss: 0.0004 lr: 0.002\n",
      "iteration: 526200 loss: 0.0004 lr: 0.002\n",
      "iteration: 526300 loss: 0.0003 lr: 0.002\n",
      "iteration: 526400 loss: 0.0004 lr: 0.002\n",
      "iteration: 526500 loss: 0.0005 lr: 0.002\n",
      "iteration: 526600 loss: 0.0003 lr: 0.002\n",
      "iteration: 526700 loss: 0.0005 lr: 0.002\n",
      "iteration: 526800 loss: 0.0003 lr: 0.002\n",
      "iteration: 526900 loss: 0.0003 lr: 0.002\n",
      "iteration: 527000 loss: 0.0004 lr: 0.002\n",
      "iteration: 527100 loss: 0.0002 lr: 0.002\n",
      "iteration: 527200 loss: 0.0004 lr: 0.002\n",
      "iteration: 527300 loss: 0.0003 lr: 0.002\n",
      "iteration: 527400 loss: 0.0003 lr: 0.002\n",
      "iteration: 527500 loss: 0.0004 lr: 0.002\n",
      "iteration: 527600 loss: 0.0003 lr: 0.002\n",
      "iteration: 527700 loss: 0.0004 lr: 0.002\n",
      "iteration: 527800 loss: 0.0003 lr: 0.002\n",
      "iteration: 527900 loss: 0.0003 lr: 0.002\n",
      "iteration: 528000 loss: 0.0004 lr: 0.002\n",
      "iteration: 528100 loss: 0.0003 lr: 0.002\n",
      "iteration: 528200 loss: 0.0003 lr: 0.002\n",
      "iteration: 528300 loss: 0.0003 lr: 0.002\n",
      "iteration: 528400 loss: 0.0004 lr: 0.002\n",
      "iteration: 528500 loss: 0.0003 lr: 0.002\n",
      "iteration: 528600 loss: 0.0003 lr: 0.002\n",
      "iteration: 528700 loss: 0.0003 lr: 0.002\n",
      "iteration: 528800 loss: 0.0003 lr: 0.002\n",
      "iteration: 528900 loss: 0.0004 lr: 0.002\n",
      "iteration: 529000 loss: 0.0004 lr: 0.002\n",
      "iteration: 529100 loss: 0.0003 lr: 0.002\n",
      "iteration: 529200 loss: 0.0004 lr: 0.002\n",
      "iteration: 529300 loss: 0.0003 lr: 0.002\n",
      "iteration: 529400 loss: 0.0004 lr: 0.002\n",
      "iteration: 529500 loss: 0.0003 lr: 0.002\n",
      "iteration: 529600 loss: 0.0004 lr: 0.002\n",
      "iteration: 529700 loss: 0.0003 lr: 0.002\n",
      "iteration: 529800 loss: 0.0003 lr: 0.002\n",
      "iteration: 529900 loss: 0.0003 lr: 0.002\n",
      "iteration: 530000 loss: 0.0004 lr: 0.002\n",
      "iteration: 530100 loss: 0.0004 lr: 0.002\n",
      "iteration: 530200 loss: 0.0004 lr: 0.002\n",
      "iteration: 530300 loss: 0.0004 lr: 0.002\n",
      "iteration: 530400 loss: 0.0004 lr: 0.002\n",
      "iteration: 530500 loss: 0.0003 lr: 0.002\n",
      "iteration: 530600 loss: 0.0003 lr: 0.002\n",
      "iteration: 530700 loss: 0.0003 lr: 0.002\n",
      "iteration: 530800 loss: 0.0003 lr: 0.002\n",
      "iteration: 530900 loss: 0.0003 lr: 0.002\n",
      "iteration: 531000 loss: 0.0004 lr: 0.002\n",
      "iteration: 531100 loss: 0.0003 lr: 0.002\n",
      "iteration: 531200 loss: 0.0005 lr: 0.002\n",
      "iteration: 531300 loss: 0.0005 lr: 0.002\n",
      "iteration: 531400 loss: 0.0003 lr: 0.002\n",
      "iteration: 531500 loss: 0.0003 lr: 0.002\n",
      "iteration: 531600 loss: 0.0003 lr: 0.002\n",
      "iteration: 531700 loss: 0.0003 lr: 0.002\n",
      "iteration: 531800 loss: 0.0004 lr: 0.002\n",
      "iteration: 531900 loss: 0.0003 lr: 0.002\n",
      "iteration: 532000 loss: 0.0004 lr: 0.002\n",
      "iteration: 532100 loss: 0.0004 lr: 0.002\n",
      "iteration: 532200 loss: 0.0004 lr: 0.002\n",
      "iteration: 532300 loss: 0.0004 lr: 0.002\n",
      "iteration: 532400 loss: 0.0003 lr: 0.002\n",
      "iteration: 532500 loss: 0.0003 lr: 0.002\n",
      "iteration: 532600 loss: 0.0003 lr: 0.002\n",
      "iteration: 532700 loss: 0.0003 lr: 0.002\n",
      "iteration: 532800 loss: 0.0003 lr: 0.002\n",
      "iteration: 532900 loss: 0.0003 lr: 0.002\n",
      "iteration: 533000 loss: 0.0004 lr: 0.002\n",
      "iteration: 533100 loss: 0.0004 lr: 0.002\n",
      "iteration: 533200 loss: 0.0003 lr: 0.002\n",
      "iteration: 533300 loss: 0.0003 lr: 0.002\n",
      "iteration: 533400 loss: 0.0003 lr: 0.002\n",
      "iteration: 533500 loss: 0.0003 lr: 0.002\n",
      "iteration: 533600 loss: 0.0004 lr: 0.002\n",
      "iteration: 533700 loss: 0.0004 lr: 0.002\n",
      "iteration: 533800 loss: 0.0003 lr: 0.002\n",
      "iteration: 533900 loss: 0.0003 lr: 0.002\n",
      "iteration: 534000 loss: 0.0004 lr: 0.002\n",
      "iteration: 534100 loss: 0.0003 lr: 0.002\n",
      "iteration: 534200 loss: 0.0003 lr: 0.002\n",
      "iteration: 534300 loss: 0.0003 lr: 0.002\n",
      "iteration: 534400 loss: 0.0003 lr: 0.002\n",
      "iteration: 534500 loss: 0.0004 lr: 0.002\n",
      "iteration: 534600 loss: 0.0004 lr: 0.002\n",
      "iteration: 534700 loss: 0.0004 lr: 0.002\n",
      "iteration: 534800 loss: 0.0004 lr: 0.002\n",
      "iteration: 534900 loss: 0.0003 lr: 0.002\n",
      "iteration: 535000 loss: 0.0004 lr: 0.002\n",
      "iteration: 535100 loss: 0.0004 lr: 0.002\n",
      "iteration: 535200 loss: 0.0003 lr: 0.002\n",
      "iteration: 535300 loss: 0.0003 lr: 0.002\n",
      "iteration: 535400 loss: 0.0003 lr: 0.002\n",
      "iteration: 535500 loss: 0.0004 lr: 0.002\n",
      "iteration: 535600 loss: 0.0004 lr: 0.002\n",
      "iteration: 535700 loss: 0.0003 lr: 0.002\n",
      "iteration: 535800 loss: 0.0003 lr: 0.002\n",
      "iteration: 535900 loss: 0.0003 lr: 0.002\n",
      "iteration: 536000 loss: 0.0004 lr: 0.002\n",
      "iteration: 536100 loss: 0.0004 lr: 0.002\n",
      "iteration: 536200 loss: 0.0003 lr: 0.002\n",
      "iteration: 536300 loss: 0.0003 lr: 0.002\n",
      "iteration: 536400 loss: 0.0004 lr: 0.002\n",
      "iteration: 536500 loss: 0.0004 lr: 0.002\n",
      "iteration: 536600 loss: 0.0003 lr: 0.002\n",
      "iteration: 536700 loss: 0.0003 lr: 0.002\n",
      "iteration: 536800 loss: 0.0004 lr: 0.002\n",
      "iteration: 536900 loss: 0.0003 lr: 0.002\n",
      "iteration: 537000 loss: 0.0004 lr: 0.002\n",
      "iteration: 537100 loss: 0.0003 lr: 0.002\n",
      "iteration: 537200 loss: 0.0003 lr: 0.002\n",
      "iteration: 537300 loss: 0.0004 lr: 0.002\n",
      "iteration: 537400 loss: 0.0003 lr: 0.002\n",
      "iteration: 537500 loss: 0.0004 lr: 0.002\n",
      "iteration: 537600 loss: 0.0003 lr: 0.002\n",
      "iteration: 537700 loss: 0.0005 lr: 0.002\n",
      "iteration: 537800 loss: 0.0003 lr: 0.002\n",
      "iteration: 537900 loss: 0.0003 lr: 0.002\n",
      "iteration: 538000 loss: 0.0003 lr: 0.002\n",
      "iteration: 538100 loss: 0.0004 lr: 0.002\n",
      "iteration: 538200 loss: 0.0003 lr: 0.002\n",
      "iteration: 538300 loss: 0.0003 lr: 0.002\n",
      "iteration: 538400 loss: 0.0003 lr: 0.002\n",
      "iteration: 538500 loss: 0.0003 lr: 0.002\n",
      "iteration: 538600 loss: 0.0003 lr: 0.002\n",
      "iteration: 538700 loss: 0.0003 lr: 0.002\n",
      "iteration: 538800 loss: 0.0003 lr: 0.002\n",
      "iteration: 538900 loss: 0.0004 lr: 0.002\n",
      "iteration: 539000 loss: 0.0003 lr: 0.002\n",
      "iteration: 539100 loss: 0.0004 lr: 0.002\n",
      "iteration: 539200 loss: 0.0003 lr: 0.002\n",
      "iteration: 539300 loss: 0.0004 lr: 0.002\n",
      "iteration: 539400 loss: 0.0003 lr: 0.002\n",
      "iteration: 539500 loss: 0.0003 lr: 0.002\n",
      "iteration: 539600 loss: 0.0004 lr: 0.002\n",
      "iteration: 539700 loss: 0.0003 lr: 0.002\n",
      "iteration: 539800 loss: 0.0004 lr: 0.002\n",
      "iteration: 539900 loss: 0.0004 lr: 0.002\n",
      "iteration: 540000 loss: 0.0004 lr: 0.002\n",
      "iteration: 540100 loss: 0.0003 lr: 0.002\n",
      "iteration: 540200 loss: 0.0003 lr: 0.002\n",
      "iteration: 540300 loss: 0.0003 lr: 0.002\n",
      "iteration: 540400 loss: 0.0003 lr: 0.002\n",
      "iteration: 540500 loss: 0.0003 lr: 0.002\n",
      "iteration: 540600 loss: 0.0004 lr: 0.002\n",
      "iteration: 540700 loss: 0.0003 lr: 0.002\n",
      "iteration: 540800 loss: 0.0003 lr: 0.002\n",
      "iteration: 540900 loss: 0.0003 lr: 0.002\n",
      "iteration: 541000 loss: 0.0004 lr: 0.002\n",
      "iteration: 541100 loss: 0.0003 lr: 0.002\n",
      "iteration: 541200 loss: 0.0004 lr: 0.002\n",
      "iteration: 541300 loss: 0.0003 lr: 0.002\n",
      "iteration: 541400 loss: 0.0004 lr: 0.002\n",
      "iteration: 541500 loss: 0.0004 lr: 0.002\n",
      "iteration: 541600 loss: 0.0004 lr: 0.002\n",
      "iteration: 541700 loss: 0.0003 lr: 0.002\n",
      "iteration: 541800 loss: 0.0003 lr: 0.002\n",
      "iteration: 541900 loss: 0.0004 lr: 0.002\n",
      "iteration: 542000 loss: 0.0003 lr: 0.002\n",
      "iteration: 542100 loss: 0.0004 lr: 0.002\n",
      "iteration: 542200 loss: 0.0003 lr: 0.002\n",
      "iteration: 542300 loss: 0.0003 lr: 0.002\n",
      "iteration: 542400 loss: 0.0003 lr: 0.002\n",
      "iteration: 542500 loss: 0.0003 lr: 0.002\n",
      "iteration: 542600 loss: 0.0004 lr: 0.002\n",
      "iteration: 542700 loss: 0.0003 lr: 0.002\n",
      "iteration: 542800 loss: 0.0003 lr: 0.002\n",
      "iteration: 542900 loss: 0.0003 lr: 0.002\n",
      "iteration: 543000 loss: 0.0003 lr: 0.002\n",
      "iteration: 543100 loss: 0.0003 lr: 0.002\n",
      "iteration: 543200 loss: 0.0003 lr: 0.002\n",
      "iteration: 543300 loss: 0.0004 lr: 0.002\n",
      "iteration: 543400 loss: 0.0003 lr: 0.002\n",
      "iteration: 543500 loss: 0.0003 lr: 0.002\n",
      "iteration: 543600 loss: 0.0004 lr: 0.002\n",
      "iteration: 543700 loss: 0.0003 lr: 0.002\n",
      "iteration: 543800 loss: 0.0003 lr: 0.002\n",
      "iteration: 543900 loss: 0.0003 lr: 0.002\n",
      "iteration: 544000 loss: 0.0003 lr: 0.002\n",
      "iteration: 544100 loss: 0.0004 lr: 0.002\n",
      "iteration: 544200 loss: 0.0004 lr: 0.002\n",
      "iteration: 544300 loss: 0.0003 lr: 0.002\n",
      "iteration: 544400 loss: 0.0003 lr: 0.002\n",
      "iteration: 544500 loss: 0.0003 lr: 0.002\n",
      "iteration: 544600 loss: 0.0003 lr: 0.002\n",
      "iteration: 544700 loss: 0.0003 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 544800 loss: 0.0003 lr: 0.002\n",
      "iteration: 544900 loss: 0.0004 lr: 0.002\n",
      "iteration: 545000 loss: 0.0003 lr: 0.002\n",
      "iteration: 545100 loss: 0.0003 lr: 0.002\n",
      "iteration: 545200 loss: 0.0004 lr: 0.002\n",
      "iteration: 545300 loss: 0.0004 lr: 0.002\n",
      "iteration: 545400 loss: 0.0005 lr: 0.002\n",
      "iteration: 545500 loss: 0.0004 lr: 0.002\n",
      "iteration: 545600 loss: 0.0004 lr: 0.002\n",
      "iteration: 545700 loss: 0.0004 lr: 0.002\n",
      "iteration: 545800 loss: 0.0004 lr: 0.002\n",
      "iteration: 545900 loss: 0.0004 lr: 0.002\n",
      "iteration: 546000 loss: 0.0003 lr: 0.002\n",
      "iteration: 546100 loss: 0.0004 lr: 0.002\n",
      "iteration: 546200 loss: 0.0004 lr: 0.002\n",
      "iteration: 546300 loss: 0.0003 lr: 0.002\n",
      "iteration: 546400 loss: 0.0003 lr: 0.002\n",
      "iteration: 546500 loss: 0.0003 lr: 0.002\n",
      "iteration: 546600 loss: 0.0003 lr: 0.002\n",
      "iteration: 546700 loss: 0.0003 lr: 0.002\n",
      "iteration: 546800 loss: 0.0004 lr: 0.002\n",
      "iteration: 546900 loss: 0.0003 lr: 0.002\n",
      "iteration: 547000 loss: 0.0003 lr: 0.002\n",
      "iteration: 547100 loss: 0.0003 lr: 0.002\n",
      "iteration: 547200 loss: 0.0004 lr: 0.002\n",
      "iteration: 547300 loss: 0.0004 lr: 0.002\n",
      "iteration: 547400 loss: 0.0003 lr: 0.002\n",
      "iteration: 547500 loss: 0.0003 lr: 0.002\n",
      "iteration: 547600 loss: 0.0003 lr: 0.002\n",
      "iteration: 547700 loss: 0.0003 lr: 0.002\n",
      "iteration: 547800 loss: 0.0003 lr: 0.002\n",
      "iteration: 547900 loss: 0.0004 lr: 0.002\n",
      "iteration: 548000 loss: 0.0003 lr: 0.002\n",
      "iteration: 548100 loss: 0.0003 lr: 0.002\n",
      "iteration: 548200 loss: 0.0003 lr: 0.002\n",
      "iteration: 548300 loss: 0.0003 lr: 0.002\n",
      "iteration: 548400 loss: 0.0003 lr: 0.002\n",
      "iteration: 548500 loss: 0.0004 lr: 0.002\n",
      "iteration: 548600 loss: 0.0003 lr: 0.002\n",
      "iteration: 548700 loss: 0.0004 lr: 0.002\n",
      "iteration: 548800 loss: 0.0003 lr: 0.002\n",
      "iteration: 548900 loss: 0.0003 lr: 0.002\n",
      "iteration: 549000 loss: 0.0003 lr: 0.002\n",
      "iteration: 549100 loss: 0.0003 lr: 0.002\n",
      "iteration: 549200 loss: 0.0004 lr: 0.002\n",
      "iteration: 549300 loss: 0.0004 lr: 0.002\n",
      "iteration: 549400 loss: 0.0003 lr: 0.002\n",
      "iteration: 549500 loss: 0.0004 lr: 0.002\n",
      "iteration: 549600 loss: 0.0003 lr: 0.002\n",
      "iteration: 549700 loss: 0.0004 lr: 0.002\n",
      "iteration: 549800 loss: 0.0003 lr: 0.002\n",
      "iteration: 549900 loss: 0.0003 lr: 0.002\n",
      "iteration: 550000 loss: 0.0003 lr: 0.002\n",
      "iteration: 550100 loss: 0.0003 lr: 0.002\n",
      "iteration: 550200 loss: 0.0004 lr: 0.002\n",
      "iteration: 550300 loss: 0.0003 lr: 0.002\n",
      "iteration: 550400 loss: 0.0004 lr: 0.002\n",
      "iteration: 550500 loss: 0.0004 lr: 0.002\n",
      "iteration: 550600 loss: 0.0004 lr: 0.002\n",
      "iteration: 550700 loss: 0.0004 lr: 0.002\n",
      "iteration: 550800 loss: 0.0003 lr: 0.002\n",
      "iteration: 550900 loss: 0.0003 lr: 0.002\n",
      "iteration: 551000 loss: 0.0003 lr: 0.002\n",
      "iteration: 551100 loss: 0.0003 lr: 0.002\n",
      "iteration: 551200 loss: 0.0003 lr: 0.002\n",
      "iteration: 551300 loss: 0.0004 lr: 0.002\n",
      "iteration: 551400 loss: 0.0004 lr: 0.002\n",
      "iteration: 551500 loss: 0.0003 lr: 0.002\n",
      "iteration: 551600 loss: 0.0003 lr: 0.002\n",
      "iteration: 551700 loss: 0.0004 lr: 0.002\n",
      "iteration: 551800 loss: 0.0004 lr: 0.002\n",
      "iteration: 551900 loss: 0.0004 lr: 0.002\n",
      "iteration: 552000 loss: 0.0003 lr: 0.002\n",
      "iteration: 552100 loss: 0.0003 lr: 0.002\n",
      "iteration: 552200 loss: 0.0004 lr: 0.002\n",
      "iteration: 552300 loss: 0.0004 lr: 0.002\n",
      "iteration: 552400 loss: 0.0003 lr: 0.002\n",
      "iteration: 552500 loss: 0.0004 lr: 0.002\n",
      "iteration: 552600 loss: 0.0004 lr: 0.002\n",
      "iteration: 552700 loss: 0.0004 lr: 0.002\n",
      "iteration: 552800 loss: 0.0003 lr: 0.002\n",
      "iteration: 552900 loss: 0.0004 lr: 0.002\n",
      "iteration: 553000 loss: 0.0004 lr: 0.002\n",
      "iteration: 553100 loss: 0.0003 lr: 0.002\n",
      "iteration: 553200 loss: 0.0004 lr: 0.002\n",
      "iteration: 553300 loss: 0.0004 lr: 0.002\n",
      "iteration: 553400 loss: 0.0003 lr: 0.002\n",
      "iteration: 553500 loss: 0.0003 lr: 0.002\n",
      "iteration: 553600 loss: 0.0003 lr: 0.002\n",
      "iteration: 553700 loss: 0.0004 lr: 0.002\n",
      "iteration: 553800 loss: 0.0004 lr: 0.002\n",
      "iteration: 553900 loss: 0.0003 lr: 0.002\n",
      "iteration: 554000 loss: 0.0003 lr: 0.002\n",
      "iteration: 554100 loss: 0.0003 lr: 0.002\n",
      "iteration: 554200 loss: 0.0003 lr: 0.002\n",
      "iteration: 554300 loss: 0.0003 lr: 0.002\n",
      "iteration: 554400 loss: 0.0003 lr: 0.002\n",
      "iteration: 554500 loss: 0.0004 lr: 0.002\n",
      "iteration: 554600 loss: 0.0003 lr: 0.002\n",
      "iteration: 554700 loss: 0.0004 lr: 0.002\n",
      "iteration: 554800 loss: 0.0003 lr: 0.002\n",
      "iteration: 554900 loss: 0.0003 lr: 0.002\n",
      "iteration: 555000 loss: 0.0003 lr: 0.002\n",
      "iteration: 555100 loss: 0.0003 lr: 0.002\n",
      "iteration: 555200 loss: 0.0004 lr: 0.002\n",
      "iteration: 555300 loss: 0.0003 lr: 0.002\n",
      "iteration: 555400 loss: 0.0004 lr: 0.002\n",
      "iteration: 555500 loss: 0.0003 lr: 0.002\n",
      "iteration: 555600 loss: 0.0003 lr: 0.002\n",
      "iteration: 555700 loss: 0.0003 lr: 0.002\n",
      "iteration: 555800 loss: 0.0003 lr: 0.002\n",
      "iteration: 555900 loss: 0.0003 lr: 0.002\n",
      "iteration: 556000 loss: 0.0003 lr: 0.002\n",
      "iteration: 556100 loss: 0.0004 lr: 0.002\n",
      "iteration: 556200 loss: 0.0004 lr: 0.002\n",
      "iteration: 556300 loss: 0.0002 lr: 0.002\n",
      "iteration: 556400 loss: 0.0003 lr: 0.002\n",
      "iteration: 556500 loss: 0.0003 lr: 0.002\n",
      "iteration: 556600 loss: 0.0004 lr: 0.002\n",
      "iteration: 556700 loss: 0.0004 lr: 0.002\n",
      "iteration: 556800 loss: 0.0003 lr: 0.002\n",
      "iteration: 556900 loss: 0.0003 lr: 0.002\n",
      "iteration: 557000 loss: 0.0003 lr: 0.002\n",
      "iteration: 557100 loss: 0.0003 lr: 0.002\n",
      "iteration: 557200 loss: 0.0003 lr: 0.002\n",
      "iteration: 557300 loss: 0.0004 lr: 0.002\n",
      "iteration: 557400 loss: 0.0003 lr: 0.002\n",
      "iteration: 557500 loss: 0.0003 lr: 0.002\n",
      "iteration: 557600 loss: 0.0003 lr: 0.002\n",
      "iteration: 557700 loss: 0.0003 lr: 0.002\n",
      "iteration: 557800 loss: 0.0003 lr: 0.002\n",
      "iteration: 557900 loss: 0.0003 lr: 0.002\n",
      "iteration: 558000 loss: 0.0004 lr: 0.002\n",
      "iteration: 558100 loss: 0.0004 lr: 0.002\n",
      "iteration: 558200 loss: 0.0003 lr: 0.002\n",
      "iteration: 558300 loss: 0.0004 lr: 0.002\n",
      "iteration: 558400 loss: 0.0004 lr: 0.002\n",
      "iteration: 558500 loss: 0.0004 lr: 0.002\n",
      "iteration: 558600 loss: 0.0003 lr: 0.002\n",
      "iteration: 558700 loss: 0.0003 lr: 0.002\n",
      "iteration: 558800 loss: 0.0003 lr: 0.002\n",
      "iteration: 558900 loss: 0.0002 lr: 0.002\n",
      "iteration: 559000 loss: 0.0003 lr: 0.002\n",
      "iteration: 559100 loss: 0.0004 lr: 0.002\n",
      "iteration: 559200 loss: 0.0003 lr: 0.002\n",
      "iteration: 559300 loss: 0.0003 lr: 0.002\n",
      "iteration: 559400 loss: 0.0003 lr: 0.002\n",
      "iteration: 559500 loss: 0.0003 lr: 0.002\n",
      "iteration: 559600 loss: 0.0004 lr: 0.002\n",
      "iteration: 559700 loss: 0.0003 lr: 0.002\n",
      "iteration: 559800 loss: 0.0004 lr: 0.002\n",
      "iteration: 559900 loss: 0.0003 lr: 0.002\n",
      "iteration: 560000 loss: 0.0003 lr: 0.002\n",
      "iteration: 560100 loss: 0.0004 lr: 0.002\n",
      "iteration: 560200 loss: 0.0004 lr: 0.002\n",
      "iteration: 560300 loss: 0.0003 lr: 0.002\n",
      "iteration: 560400 loss: 0.0003 lr: 0.002\n",
      "iteration: 560500 loss: 0.0003 lr: 0.002\n",
      "iteration: 560600 loss: 0.0004 lr: 0.002\n",
      "iteration: 560700 loss: 0.0003 lr: 0.002\n",
      "iteration: 560800 loss: 0.0003 lr: 0.002\n",
      "iteration: 560900 loss: 0.0003 lr: 0.002\n",
      "iteration: 561000 loss: 0.0003 lr: 0.002\n",
      "iteration: 561100 loss: 0.0003 lr: 0.002\n",
      "iteration: 561200 loss: 0.0003 lr: 0.002\n",
      "iteration: 561300 loss: 0.0003 lr: 0.002\n",
      "iteration: 561400 loss: 0.0003 lr: 0.002\n",
      "iteration: 561500 loss: 0.0004 lr: 0.002\n",
      "iteration: 561600 loss: 0.0003 lr: 0.002\n",
      "iteration: 561700 loss: 0.0003 lr: 0.002\n",
      "iteration: 561800 loss: 0.0003 lr: 0.002\n",
      "iteration: 561900 loss: 0.0003 lr: 0.002\n",
      "iteration: 562000 loss: 0.0003 lr: 0.002\n",
      "iteration: 562100 loss: 0.0004 lr: 0.002\n",
      "iteration: 562200 loss: 0.0003 lr: 0.002\n",
      "iteration: 562300 loss: 0.0003 lr: 0.002\n",
      "iteration: 562400 loss: 0.0003 lr: 0.002\n",
      "iteration: 562500 loss: 0.0003 lr: 0.002\n",
      "iteration: 562600 loss: 0.0004 lr: 0.002\n",
      "iteration: 562700 loss: 0.0004 lr: 0.002\n",
      "iteration: 562800 loss: 0.0003 lr: 0.002\n",
      "iteration: 562900 loss: 0.0003 lr: 0.002\n",
      "iteration: 563000 loss: 0.0003 lr: 0.002\n",
      "iteration: 563100 loss: 0.0003 lr: 0.002\n",
      "iteration: 563200 loss: 0.0003 lr: 0.002\n",
      "iteration: 563300 loss: 0.0003 lr: 0.002\n",
      "iteration: 563400 loss: 0.0003 lr: 0.002\n",
      "iteration: 563500 loss: 0.0003 lr: 0.002\n",
      "iteration: 563600 loss: 0.0003 lr: 0.002\n",
      "iteration: 563700 loss: 0.0004 lr: 0.002\n",
      "iteration: 563800 loss: 0.0004 lr: 0.002\n",
      "iteration: 563900 loss: 0.0004 lr: 0.002\n",
      "iteration: 564000 loss: 0.0003 lr: 0.002\n",
      "iteration: 564100 loss: 0.0003 lr: 0.002\n",
      "iteration: 564200 loss: 0.0003 lr: 0.002\n",
      "iteration: 564300 loss: 0.0003 lr: 0.002\n",
      "iteration: 564400 loss: 0.0003 lr: 0.002\n",
      "iteration: 564500 loss: 0.0003 lr: 0.002\n",
      "iteration: 564600 loss: 0.0003 lr: 0.002\n",
      "iteration: 564700 loss: 0.0004 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 564800 loss: 0.0004 lr: 0.002\n",
      "iteration: 564900 loss: 0.0003 lr: 0.002\n",
      "iteration: 565000 loss: 0.0004 lr: 0.002\n",
      "iteration: 565100 loss: 0.0004 lr: 0.002\n",
      "iteration: 565200 loss: 0.0003 lr: 0.002\n",
      "iteration: 565300 loss: 0.0003 lr: 0.002\n",
      "iteration: 565400 loss: 0.0003 lr: 0.002\n",
      "iteration: 565500 loss: 0.0004 lr: 0.002\n",
      "iteration: 565600 loss: 0.0004 lr: 0.002\n",
      "iteration: 565700 loss: 0.0003 lr: 0.002\n",
      "iteration: 565800 loss: 0.0004 lr: 0.002\n",
      "iteration: 565900 loss: 0.0002 lr: 0.002\n",
      "iteration: 566000 loss: 0.0003 lr: 0.002\n",
      "iteration: 566100 loss: 0.0003 lr: 0.002\n",
      "iteration: 566200 loss: 0.0003 lr: 0.002\n",
      "iteration: 566300 loss: 0.0003 lr: 0.002\n",
      "iteration: 566400 loss: 0.0004 lr: 0.002\n",
      "iteration: 566500 loss: 0.0004 lr: 0.002\n",
      "iteration: 566600 loss: 0.0003 lr: 0.002\n",
      "iteration: 566700 loss: 0.0003 lr: 0.002\n",
      "iteration: 566800 loss: 0.0003 lr: 0.002\n",
      "iteration: 566900 loss: 0.0003 lr: 0.002\n",
      "iteration: 567000 loss: 0.0003 lr: 0.002\n",
      "iteration: 567100 loss: 0.0003 lr: 0.002\n",
      "iteration: 567200 loss: 0.0003 lr: 0.002\n",
      "iteration: 567300 loss: 0.0003 lr: 0.002\n",
      "iteration: 567400 loss: 0.0004 lr: 0.002\n",
      "iteration: 567500 loss: 0.0004 lr: 0.002\n",
      "iteration: 567600 loss: 0.0003 lr: 0.002\n",
      "iteration: 567700 loss: 0.0002 lr: 0.002\n",
      "iteration: 567800 loss: 0.0003 lr: 0.002\n",
      "iteration: 567900 loss: 0.0003 lr: 0.002\n",
      "iteration: 568000 loss: 0.0003 lr: 0.002\n",
      "iteration: 568100 loss: 0.0003 lr: 0.002\n",
      "iteration: 568200 loss: 0.0002 lr: 0.002\n",
      "iteration: 568300 loss: 0.0004 lr: 0.002\n",
      "iteration: 568400 loss: 0.0004 lr: 0.002\n",
      "iteration: 568500 loss: 0.0003 lr: 0.002\n",
      "iteration: 568600 loss: 0.0002 lr: 0.002\n",
      "iteration: 568700 loss: 0.0003 lr: 0.002\n",
      "iteration: 568800 loss: 0.0003 lr: 0.002\n",
      "iteration: 568900 loss: 0.0004 lr: 0.002\n",
      "iteration: 569000 loss: 0.0003 lr: 0.002\n",
      "iteration: 569100 loss: 0.0003 lr: 0.002\n",
      "iteration: 569200 loss: 0.0004 lr: 0.002\n",
      "iteration: 569300 loss: 0.0003 lr: 0.002\n",
      "iteration: 569400 loss: 0.0004 lr: 0.002\n",
      "iteration: 569500 loss: 0.0003 lr: 0.002\n",
      "iteration: 569600 loss: 0.0003 lr: 0.002\n",
      "iteration: 569700 loss: 0.0003 lr: 0.002\n",
      "iteration: 569800 loss: 0.0003 lr: 0.002\n",
      "iteration: 569900 loss: 0.0003 lr: 0.002\n",
      "iteration: 570000 loss: 0.0004 lr: 0.002\n",
      "iteration: 570100 loss: 0.0003 lr: 0.002\n",
      "iteration: 570200 loss: 0.0003 lr: 0.002\n",
      "iteration: 570300 loss: 0.0004 lr: 0.002\n",
      "iteration: 570400 loss: 0.0003 lr: 0.002\n",
      "iteration: 570500 loss: 0.0003 lr: 0.002\n",
      "iteration: 570600 loss: 0.0003 lr: 0.002\n",
      "iteration: 570700 loss: 0.0003 lr: 0.002\n",
      "iteration: 570800 loss: 0.0003 lr: 0.002\n",
      "iteration: 570900 loss: 0.0003 lr: 0.002\n",
      "iteration: 571000 loss: 0.0003 lr: 0.002\n",
      "iteration: 571100 loss: 0.0003 lr: 0.002\n",
      "iteration: 571200 loss: 0.0004 lr: 0.002\n",
      "iteration: 571300 loss: 0.0003 lr: 0.002\n",
      "iteration: 571400 loss: 0.0004 lr: 0.002\n",
      "iteration: 571500 loss: 0.0004 lr: 0.002\n",
      "iteration: 571600 loss: 0.0004 lr: 0.002\n",
      "iteration: 571700 loss: 0.0004 lr: 0.002\n",
      "iteration: 571800 loss: 0.0002 lr: 0.002\n",
      "iteration: 571900 loss: 0.0003 lr: 0.002\n",
      "iteration: 572000 loss: 0.0003 lr: 0.002\n",
      "iteration: 572100 loss: 0.0004 lr: 0.002\n",
      "iteration: 572200 loss: 0.0003 lr: 0.002\n",
      "iteration: 572300 loss: 0.0003 lr: 0.002\n",
      "iteration: 572400 loss: 0.0003 lr: 0.002\n",
      "iteration: 572500 loss: 0.0003 lr: 0.002\n",
      "iteration: 572600 loss: 0.0003 lr: 0.002\n",
      "iteration: 572700 loss: 0.0003 lr: 0.002\n",
      "iteration: 572800 loss: 0.0003 lr: 0.002\n",
      "iteration: 572900 loss: 0.0003 lr: 0.002\n",
      "iteration: 573000 loss: 0.0004 lr: 0.002\n",
      "iteration: 573100 loss: 0.0003 lr: 0.002\n",
      "iteration: 573200 loss: 0.0003 lr: 0.002\n",
      "iteration: 573300 loss: 0.0004 lr: 0.002\n",
      "iteration: 573400 loss: 0.0004 lr: 0.002\n",
      "iteration: 573500 loss: 0.0003 lr: 0.002\n",
      "iteration: 573600 loss: 0.0004 lr: 0.002\n",
      "iteration: 573700 loss: 0.0003 lr: 0.002\n",
      "iteration: 573800 loss: 0.0003 lr: 0.002\n",
      "iteration: 573900 loss: 0.0004 lr: 0.002\n",
      "iteration: 574000 loss: 0.0003 lr: 0.002\n",
      "iteration: 574100 loss: 0.0003 lr: 0.002\n",
      "iteration: 574200 loss: 0.0004 lr: 0.002\n",
      "iteration: 574300 loss: 0.0003 lr: 0.002\n",
      "iteration: 574400 loss: 0.0004 lr: 0.002\n",
      "iteration: 574500 loss: 0.0003 lr: 0.002\n",
      "iteration: 574600 loss: 0.0002 lr: 0.002\n",
      "iteration: 574700 loss: 0.0003 lr: 0.002\n",
      "iteration: 574800 loss: 0.0002 lr: 0.002\n",
      "iteration: 574900 loss: 0.0003 lr: 0.002\n",
      "iteration: 575000 loss: 0.0004 lr: 0.002\n",
      "iteration: 575100 loss: 0.0003 lr: 0.002\n",
      "iteration: 575200 loss: 0.0004 lr: 0.002\n",
      "iteration: 575300 loss: 0.0003 lr: 0.002\n",
      "iteration: 575400 loss: 0.0004 lr: 0.002\n",
      "iteration: 575500 loss: 0.0003 lr: 0.002\n",
      "iteration: 575600 loss: 0.0003 lr: 0.002\n",
      "iteration: 575700 loss: 0.0003 lr: 0.002\n",
      "iteration: 575800 loss: 0.0003 lr: 0.002\n",
      "iteration: 575900 loss: 0.0003 lr: 0.002\n",
      "iteration: 576000 loss: 0.0003 lr: 0.002\n",
      "iteration: 576100 loss: 0.0003 lr: 0.002\n",
      "iteration: 576200 loss: 0.0003 lr: 0.002\n",
      "iteration: 576300 loss: 0.0004 lr: 0.002\n",
      "iteration: 576400 loss: 0.0003 lr: 0.002\n",
      "iteration: 576500 loss: 0.0004 lr: 0.002\n",
      "iteration: 576600 loss: 0.0003 lr: 0.002\n",
      "iteration: 576700 loss: 0.0003 lr: 0.002\n",
      "iteration: 576800 loss: 0.0003 lr: 0.002\n",
      "iteration: 576900 loss: 0.0003 lr: 0.002\n",
      "iteration: 577000 loss: 0.0004 lr: 0.002\n",
      "iteration: 577100 loss: 0.0004 lr: 0.002\n",
      "iteration: 577200 loss: 0.0003 lr: 0.002\n",
      "iteration: 577300 loss: 0.0003 lr: 0.002\n",
      "iteration: 577400 loss: 0.0004 lr: 0.002\n",
      "iteration: 577500 loss: 0.0004 lr: 0.002\n",
      "iteration: 577600 loss: 0.0004 lr: 0.002\n",
      "iteration: 577700 loss: 0.0003 lr: 0.002\n",
      "iteration: 577800 loss: 0.0004 lr: 0.002\n",
      "iteration: 577900 loss: 0.0003 lr: 0.002\n",
      "iteration: 578000 loss: 0.0004 lr: 0.002\n",
      "iteration: 578100 loss: 0.0004 lr: 0.002\n",
      "iteration: 578200 loss: 0.0004 lr: 0.002\n",
      "iteration: 578300 loss: 0.0003 lr: 0.002\n",
      "iteration: 578400 loss: 0.0003 lr: 0.002\n",
      "iteration: 578500 loss: 0.0005 lr: 0.002\n",
      "iteration: 578600 loss: 0.0003 lr: 0.002\n",
      "iteration: 578700 loss: 0.0004 lr: 0.002\n",
      "iteration: 578800 loss: 0.0003 lr: 0.002\n",
      "iteration: 578900 loss: 0.0003 lr: 0.002\n",
      "iteration: 579000 loss: 0.0003 lr: 0.002\n",
      "iteration: 579100 loss: 0.0003 lr: 0.002\n",
      "iteration: 579200 loss: 0.0003 lr: 0.002\n",
      "iteration: 579300 loss: 0.0003 lr: 0.002\n",
      "iteration: 579400 loss: 0.0002 lr: 0.002\n",
      "iteration: 579500 loss: 0.0003 lr: 0.002\n",
      "iteration: 579600 loss: 0.0003 lr: 0.002\n",
      "iteration: 579700 loss: 0.0003 lr: 0.002\n",
      "iteration: 579800 loss: 0.0003 lr: 0.002\n",
      "iteration: 579900 loss: 0.0003 lr: 0.002\n",
      "iteration: 580000 loss: 0.0003 lr: 0.002\n",
      "iteration: 580100 loss: 0.0003 lr: 0.002\n",
      "iteration: 580200 loss: 0.0004 lr: 0.002\n",
      "iteration: 580300 loss: 0.0004 lr: 0.002\n",
      "iteration: 580400 loss: 0.0003 lr: 0.002\n",
      "iteration: 580500 loss: 0.0003 lr: 0.002\n",
      "iteration: 580600 loss: 0.0004 lr: 0.002\n",
      "iteration: 580700 loss: 0.0004 lr: 0.002\n",
      "iteration: 580800 loss: 0.0004 lr: 0.002\n",
      "iteration: 580900 loss: 0.0003 lr: 0.002\n",
      "iteration: 581000 loss: 0.0003 lr: 0.002\n",
      "iteration: 581100 loss: 0.0003 lr: 0.002\n",
      "iteration: 581200 loss: 0.0003 lr: 0.002\n",
      "iteration: 581300 loss: 0.0003 lr: 0.002\n",
      "iteration: 581400 loss: 0.0004 lr: 0.002\n",
      "iteration: 581500 loss: 0.0004 lr: 0.002\n",
      "iteration: 581600 loss: 0.0004 lr: 0.002\n",
      "iteration: 581700 loss: 0.0003 lr: 0.002\n",
      "iteration: 581800 loss: 0.0004 lr: 0.002\n",
      "iteration: 581900 loss: 0.0003 lr: 0.002\n",
      "iteration: 582000 loss: 0.0003 lr: 0.002\n",
      "iteration: 582100 loss: 0.0003 lr: 0.002\n",
      "iteration: 582200 loss: 0.0003 lr: 0.002\n",
      "iteration: 582300 loss: 0.0003 lr: 0.002\n",
      "iteration: 582400 loss: 0.0003 lr: 0.002\n",
      "iteration: 582500 loss: 0.0003 lr: 0.002\n",
      "iteration: 582600 loss: 0.0003 lr: 0.002\n",
      "iteration: 582700 loss: 0.0003 lr: 0.002\n",
      "iteration: 582800 loss: 0.0003 lr: 0.002\n",
      "iteration: 582900 loss: 0.0003 lr: 0.002\n",
      "iteration: 583000 loss: 0.0004 lr: 0.002\n",
      "iteration: 583100 loss: 0.0003 lr: 0.002\n",
      "iteration: 583200 loss: 0.0003 lr: 0.002\n",
      "iteration: 583300 loss: 0.0003 lr: 0.002\n",
      "iteration: 583400 loss: 0.0004 lr: 0.002\n",
      "iteration: 583500 loss: 0.0003 lr: 0.002\n",
      "iteration: 583600 loss: 0.0004 lr: 0.002\n",
      "iteration: 583700 loss: 0.0003 lr: 0.002\n",
      "iteration: 583800 loss: 0.0004 lr: 0.002\n",
      "iteration: 583900 loss: 0.0003 lr: 0.002\n",
      "iteration: 584000 loss: 0.0004 lr: 0.002\n",
      "iteration: 584100 loss: 0.0003 lr: 0.002\n",
      "iteration: 584200 loss: 0.0003 lr: 0.002\n",
      "iteration: 584300 loss: 0.0003 lr: 0.002\n",
      "iteration: 584400 loss: 0.0004 lr: 0.002\n",
      "iteration: 584500 loss: 0.0003 lr: 0.002\n",
      "iteration: 584600 loss: 0.0004 lr: 0.002\n",
      "iteration: 584700 loss: 0.0004 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 584800 loss: 0.0003 lr: 0.002\n",
      "iteration: 584900 loss: 0.0003 lr: 0.002\n",
      "iteration: 585000 loss: 0.0003 lr: 0.002\n",
      "iteration: 585100 loss: 0.0003 lr: 0.002\n",
      "iteration: 585200 loss: 0.0003 lr: 0.002\n",
      "iteration: 585300 loss: 0.0003 lr: 0.002\n",
      "iteration: 585400 loss: 0.0003 lr: 0.002\n",
      "iteration: 585500 loss: 0.0003 lr: 0.002\n",
      "iteration: 585600 loss: 0.0004 lr: 0.002\n",
      "iteration: 585700 loss: 0.0003 lr: 0.002\n",
      "iteration: 585800 loss: 0.0004 lr: 0.002\n",
      "iteration: 585900 loss: 0.0003 lr: 0.002\n",
      "iteration: 586000 loss: 0.0003 lr: 0.002\n",
      "iteration: 586100 loss: 0.0004 lr: 0.002\n",
      "iteration: 586200 loss: 0.0003 lr: 0.002\n",
      "iteration: 586300 loss: 0.0003 lr: 0.002\n",
      "iteration: 586400 loss: 0.0004 lr: 0.002\n",
      "iteration: 586500 loss: 0.0004 lr: 0.002\n",
      "iteration: 586600 loss: 0.0004 lr: 0.002\n",
      "iteration: 586700 loss: 0.0003 lr: 0.002\n",
      "iteration: 586800 loss: 0.0004 lr: 0.002\n",
      "iteration: 586900 loss: 0.0003 lr: 0.002\n",
      "iteration: 587000 loss: 0.0003 lr: 0.002\n",
      "iteration: 587100 loss: 0.0004 lr: 0.002\n",
      "iteration: 587200 loss: 0.0003 lr: 0.002\n",
      "iteration: 587300 loss: 0.0004 lr: 0.002\n",
      "iteration: 587400 loss: 0.0003 lr: 0.002\n",
      "iteration: 587500 loss: 0.0004 lr: 0.002\n",
      "iteration: 587600 loss: 0.0004 lr: 0.002\n",
      "iteration: 587700 loss: 0.0004 lr: 0.002\n",
      "iteration: 587800 loss: 0.0003 lr: 0.002\n",
      "iteration: 587900 loss: 0.0003 lr: 0.002\n",
      "iteration: 588000 loss: 0.0004 lr: 0.002\n",
      "iteration: 588100 loss: 0.0003 lr: 0.002\n",
      "iteration: 588200 loss: 0.0003 lr: 0.002\n",
      "iteration: 588300 loss: 0.0004 lr: 0.002\n",
      "iteration: 588400 loss: 0.0003 lr: 0.002\n",
      "iteration: 588500 loss: 0.0003 lr: 0.002\n",
      "iteration: 588600 loss: 0.0003 lr: 0.002\n",
      "iteration: 588700 loss: 0.0003 lr: 0.002\n",
      "iteration: 588800 loss: 0.0003 lr: 0.002\n",
      "iteration: 588900 loss: 0.0003 lr: 0.002\n",
      "iteration: 589000 loss: 0.0003 lr: 0.002\n",
      "iteration: 589100 loss: 0.0003 lr: 0.002\n",
      "iteration: 589200 loss: 0.0003 lr: 0.002\n",
      "iteration: 589300 loss: 0.0003 lr: 0.002\n",
      "iteration: 589400 loss: 0.0004 lr: 0.002\n",
      "iteration: 589500 loss: 0.0003 lr: 0.002\n",
      "iteration: 589600 loss: 0.0004 lr: 0.002\n",
      "iteration: 589700 loss: 0.0003 lr: 0.002\n",
      "iteration: 589800 loss: 0.0003 lr: 0.002\n",
      "iteration: 589900 loss: 0.0003 lr: 0.002\n",
      "iteration: 590000 loss: 0.0003 lr: 0.002\n",
      "iteration: 590100 loss: 0.0004 lr: 0.002\n",
      "iteration: 590200 loss: 0.0003 lr: 0.002\n",
      "iteration: 590300 loss: 0.0004 lr: 0.002\n",
      "iteration: 590400 loss: 0.0003 lr: 0.002\n",
      "iteration: 590500 loss: 0.0003 lr: 0.002\n",
      "iteration: 590600 loss: 0.0003 lr: 0.002\n",
      "iteration: 590700 loss: 0.0003 lr: 0.002\n",
      "iteration: 590800 loss: 0.0004 lr: 0.002\n",
      "iteration: 590900 loss: 0.0003 lr: 0.002\n",
      "iteration: 591000 loss: 0.0003 lr: 0.002\n",
      "iteration: 591100 loss: 0.0003 lr: 0.002\n",
      "iteration: 591200 loss: 0.0006 lr: 0.002\n",
      "iteration: 591300 loss: 0.0003 lr: 0.002\n",
      "iteration: 591400 loss: 0.0004 lr: 0.002\n",
      "iteration: 591500 loss: 0.0003 lr: 0.002\n",
      "iteration: 591600 loss: 0.0003 lr: 0.002\n",
      "iteration: 591700 loss: 0.0003 lr: 0.002\n",
      "iteration: 591800 loss: 0.0004 lr: 0.002\n",
      "iteration: 591900 loss: 0.0003 lr: 0.002\n",
      "iteration: 592000 loss: 0.0004 lr: 0.002\n",
      "iteration: 592100 loss: 0.0003 lr: 0.002\n",
      "iteration: 592200 loss: 0.0003 lr: 0.002\n",
      "iteration: 592300 loss: 0.0003 lr: 0.002\n",
      "iteration: 592400 loss: 0.0003 lr: 0.002\n",
      "iteration: 592500 loss: 0.0003 lr: 0.002\n",
      "iteration: 592600 loss: 0.0003 lr: 0.002\n",
      "iteration: 592700 loss: 0.0003 lr: 0.002\n",
      "iteration: 592800 loss: 0.0003 lr: 0.002\n",
      "iteration: 592900 loss: 0.0003 lr: 0.002\n",
      "iteration: 593000 loss: 0.0003 lr: 0.002\n",
      "iteration: 593100 loss: 0.0002 lr: 0.002\n",
      "iteration: 593200 loss: 0.0003 lr: 0.002\n",
      "iteration: 593300 loss: 0.0003 lr: 0.002\n",
      "iteration: 593400 loss: 0.0005 lr: 0.002\n",
      "iteration: 593500 loss: 0.0003 lr: 0.002\n",
      "iteration: 593600 loss: 0.0004 lr: 0.002\n",
      "iteration: 593700 loss: 0.0003 lr: 0.002\n",
      "iteration: 593800 loss: 0.0003 lr: 0.002\n",
      "iteration: 593900 loss: 0.0004 lr: 0.002\n",
      "iteration: 594000 loss: 0.0004 lr: 0.002\n",
      "iteration: 594100 loss: 0.0003 lr: 0.002\n",
      "iteration: 594200 loss: 0.0003 lr: 0.002\n",
      "iteration: 594300 loss: 0.0003 lr: 0.002\n",
      "iteration: 594400 loss: 0.0004 lr: 0.002\n",
      "iteration: 594500 loss: 0.0003 lr: 0.002\n",
      "iteration: 594600 loss: 0.0004 lr: 0.002\n",
      "iteration: 594700 loss: 0.0004 lr: 0.002\n",
      "iteration: 594800 loss: 0.0003 lr: 0.002\n",
      "iteration: 594900 loss: 0.0002 lr: 0.002\n",
      "iteration: 595000 loss: 0.0003 lr: 0.002\n",
      "iteration: 595100 loss: 0.0004 lr: 0.002\n",
      "iteration: 595200 loss: 0.0003 lr: 0.002\n",
      "iteration: 595300 loss: 0.0004 lr: 0.002\n",
      "iteration: 595400 loss: 0.0003 lr: 0.002\n",
      "iteration: 595500 loss: 0.0005 lr: 0.002\n",
      "iteration: 595600 loss: 0.0003 lr: 0.002\n",
      "iteration: 595700 loss: 0.0004 lr: 0.002\n",
      "iteration: 595800 loss: 0.0003 lr: 0.002\n",
      "iteration: 595900 loss: 0.0003 lr: 0.002\n",
      "iteration: 596000 loss: 0.0003 lr: 0.002\n",
      "iteration: 596100 loss: 0.0003 lr: 0.002\n",
      "iteration: 596200 loss: 0.0004 lr: 0.002\n",
      "iteration: 596300 loss: 0.0003 lr: 0.002\n",
      "iteration: 596400 loss: 0.0004 lr: 0.002\n",
      "iteration: 596500 loss: 0.0003 lr: 0.002\n",
      "iteration: 596600 loss: 0.0003 lr: 0.002\n",
      "iteration: 596700 loss: 0.0003 lr: 0.002\n",
      "iteration: 596800 loss: 0.0003 lr: 0.002\n",
      "iteration: 596900 loss: 0.0003 lr: 0.002\n",
      "iteration: 597000 loss: 0.0003 lr: 0.002\n",
      "iteration: 597100 loss: 0.0004 lr: 0.002\n",
      "iteration: 597200 loss: 0.0003 lr: 0.002\n",
      "iteration: 597300 loss: 0.0003 lr: 0.002\n",
      "iteration: 597400 loss: 0.0003 lr: 0.002\n",
      "iteration: 597500 loss: 0.0003 lr: 0.002\n",
      "iteration: 597600 loss: 0.0003 lr: 0.002\n",
      "iteration: 597700 loss: 0.0004 lr: 0.002\n",
      "iteration: 597800 loss: 0.0003 lr: 0.002\n",
      "iteration: 597900 loss: 0.0003 lr: 0.002\n",
      "iteration: 598000 loss: 0.0003 lr: 0.002\n",
      "iteration: 598100 loss: 0.0003 lr: 0.002\n",
      "iteration: 598200 loss: 0.0003 lr: 0.002\n",
      "iteration: 598300 loss: 0.0003 lr: 0.002\n",
      "iteration: 598400 loss: 0.0003 lr: 0.002\n",
      "iteration: 598500 loss: 0.0003 lr: 0.002\n",
      "iteration: 598600 loss: 0.0003 lr: 0.002\n",
      "iteration: 598700 loss: 0.0003 lr: 0.002\n",
      "iteration: 598800 loss: 0.0003 lr: 0.002\n",
      "iteration: 598900 loss: 0.0004 lr: 0.002\n",
      "iteration: 599000 loss: 0.0004 lr: 0.002\n",
      "iteration: 599100 loss: 0.0003 lr: 0.002\n",
      "iteration: 599200 loss: 0.0003 lr: 0.002\n",
      "iteration: 599300 loss: 0.0003 lr: 0.002\n",
      "iteration: 599400 loss: 0.0003 lr: 0.002\n",
      "iteration: 599500 loss: 0.0004 lr: 0.002\n",
      "iteration: 599600 loss: 0.0003 lr: 0.002\n",
      "iteration: 599700 loss: 0.0003 lr: 0.002\n",
      "iteration: 599800 loss: 0.0003 lr: 0.002\n",
      "iteration: 599900 loss: 0.0003 lr: 0.002\n",
      "iteration: 600000 loss: 0.0003 lr: 0.002\n",
      "iteration: 600100 loss: 0.0004 lr: 0.002\n",
      "iteration: 600200 loss: 0.0003 lr: 0.002\n",
      "iteration: 600300 loss: 0.0003 lr: 0.002\n",
      "iteration: 600400 loss: 0.0003 lr: 0.002\n",
      "iteration: 600500 loss: 0.0004 lr: 0.002\n",
      "iteration: 600600 loss: 0.0003 lr: 0.002\n",
      "iteration: 600700 loss: 0.0003 lr: 0.002\n",
      "iteration: 600800 loss: 0.0003 lr: 0.002\n",
      "iteration: 600900 loss: 0.0002 lr: 0.002\n",
      "iteration: 601000 loss: 0.0003 lr: 0.002\n",
      "iteration: 601100 loss: 0.0003 lr: 0.002\n",
      "iteration: 601200 loss: 0.0003 lr: 0.002\n",
      "iteration: 601300 loss: 0.0003 lr: 0.002\n",
      "iteration: 601400 loss: 0.0003 lr: 0.002\n",
      "iteration: 601500 loss: 0.0004 lr: 0.002\n",
      "iteration: 601600 loss: 0.0004 lr: 0.002\n",
      "iteration: 601700 loss: 0.0003 lr: 0.002\n",
      "iteration: 601800 loss: 0.0002 lr: 0.002\n",
      "iteration: 601900 loss: 0.0003 lr: 0.002\n",
      "iteration: 602000 loss: 0.0004 lr: 0.002\n",
      "iteration: 602100 loss: 0.0003 lr: 0.002\n",
      "iteration: 602200 loss: 0.0003 lr: 0.002\n",
      "iteration: 602300 loss: 0.0003 lr: 0.002\n",
      "iteration: 602400 loss: 0.0003 lr: 0.002\n",
      "iteration: 602500 loss: 0.0003 lr: 0.002\n",
      "iteration: 602600 loss: 0.0003 lr: 0.002\n",
      "iteration: 602700 loss: 0.0003 lr: 0.002\n",
      "iteration: 602800 loss: 0.0003 lr: 0.002\n",
      "iteration: 602900 loss: 0.0004 lr: 0.002\n",
      "iteration: 603000 loss: 0.0003 lr: 0.002\n",
      "iteration: 603100 loss: 0.0003 lr: 0.002\n",
      "iteration: 603200 loss: 0.0003 lr: 0.002\n",
      "iteration: 603300 loss: 0.0003 lr: 0.002\n",
      "iteration: 603400 loss: 0.0004 lr: 0.002\n",
      "iteration: 603500 loss: 0.0003 lr: 0.002\n",
      "iteration: 603600 loss: 0.0003 lr: 0.002\n",
      "iteration: 603700 loss: 0.0002 lr: 0.002\n",
      "iteration: 603800 loss: 0.0003 lr: 0.002\n",
      "iteration: 603900 loss: 0.0003 lr: 0.002\n",
      "iteration: 604000 loss: 0.0003 lr: 0.002\n",
      "iteration: 604100 loss: 0.0003 lr: 0.002\n",
      "iteration: 604200 loss: 0.0002 lr: 0.002\n",
      "iteration: 604300 loss: 0.0003 lr: 0.002\n",
      "iteration: 604400 loss: 0.0003 lr: 0.002\n",
      "iteration: 604500 loss: 0.0004 lr: 0.002\n",
      "iteration: 604600 loss: 0.0003 lr: 0.002\n",
      "iteration: 604700 loss: 0.0003 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 604800 loss: 0.0003 lr: 0.002\n",
      "iteration: 604900 loss: 0.0004 lr: 0.002\n",
      "iteration: 605000 loss: 0.0003 lr: 0.002\n",
      "iteration: 605100 loss: 0.0004 lr: 0.002\n",
      "iteration: 605200 loss: 0.0003 lr: 0.002\n",
      "iteration: 605300 loss: 0.0003 lr: 0.002\n",
      "iteration: 605400 loss: 0.0003 lr: 0.002\n",
      "iteration: 605500 loss: 0.0003 lr: 0.002\n",
      "iteration: 605600 loss: 0.0003 lr: 0.002\n",
      "iteration: 605700 loss: 0.0003 lr: 0.002\n",
      "iteration: 605800 loss: 0.0003 lr: 0.002\n",
      "iteration: 605900 loss: 0.0004 lr: 0.002\n",
      "iteration: 606000 loss: 0.0003 lr: 0.002\n",
      "iteration: 606100 loss: 0.0003 lr: 0.002\n",
      "iteration: 606200 loss: 0.0002 lr: 0.002\n",
      "iteration: 606300 loss: 0.0003 lr: 0.002\n",
      "iteration: 606400 loss: 0.0003 lr: 0.002\n",
      "iteration: 606500 loss: 0.0004 lr: 0.002\n",
      "iteration: 606600 loss: 0.0003 lr: 0.002\n",
      "iteration: 606700 loss: 0.0003 lr: 0.002\n",
      "iteration: 606800 loss: 0.0003 lr: 0.002\n",
      "iteration: 606900 loss: 0.0003 lr: 0.002\n",
      "iteration: 607000 loss: 0.0003 lr: 0.002\n",
      "iteration: 607100 loss: 0.0003 lr: 0.002\n",
      "iteration: 607200 loss: 0.0003 lr: 0.002\n",
      "iteration: 607300 loss: 0.0003 lr: 0.002\n",
      "iteration: 607400 loss: 0.0003 lr: 0.002\n",
      "iteration: 607500 loss: 0.0005 lr: 0.002\n",
      "iteration: 607600 loss: 0.0004 lr: 0.002\n",
      "iteration: 607700 loss: 0.0003 lr: 0.002\n",
      "iteration: 607800 loss: 0.0003 lr: 0.002\n",
      "iteration: 607900 loss: 0.0004 lr: 0.002\n",
      "iteration: 608000 loss: 0.0003 lr: 0.002\n",
      "iteration: 608100 loss: 0.0003 lr: 0.002\n",
      "iteration: 608200 loss: 0.0004 lr: 0.002\n",
      "iteration: 608300 loss: 0.0004 lr: 0.002\n",
      "iteration: 608400 loss: 0.0003 lr: 0.002\n",
      "iteration: 608500 loss: 0.0003 lr: 0.002\n",
      "iteration: 608600 loss: 0.0003 lr: 0.002\n",
      "iteration: 608700 loss: 0.0003 lr: 0.002\n",
      "iteration: 608800 loss: 0.0003 lr: 0.002\n",
      "iteration: 608900 loss: 0.0004 lr: 0.002\n",
      "iteration: 609000 loss: 0.0003 lr: 0.002\n",
      "iteration: 609100 loss: 0.0003 lr: 0.002\n",
      "iteration: 609200 loss: 0.0003 lr: 0.002\n",
      "iteration: 609300 loss: 0.0003 lr: 0.002\n",
      "iteration: 609400 loss: 0.0003 lr: 0.002\n",
      "iteration: 609500 loss: 0.0003 lr: 0.002\n",
      "iteration: 609600 loss: 0.0003 lr: 0.002\n",
      "iteration: 609700 loss: 0.0003 lr: 0.002\n",
      "iteration: 609800 loss: 0.0004 lr: 0.002\n",
      "iteration: 609900 loss: 0.0003 lr: 0.002\n",
      "iteration: 610000 loss: 0.0003 lr: 0.002\n",
      "iteration: 610100 loss: 0.0003 lr: 0.002\n",
      "iteration: 610200 loss: 0.0002 lr: 0.002\n",
      "iteration: 610300 loss: 0.0004 lr: 0.002\n",
      "iteration: 610400 loss: 0.0004 lr: 0.002\n",
      "iteration: 610500 loss: 0.0004 lr: 0.002\n",
      "iteration: 610600 loss: 0.0003 lr: 0.002\n",
      "iteration: 610700 loss: 0.0003 lr: 0.002\n",
      "iteration: 610800 loss: 0.0003 lr: 0.002\n",
      "iteration: 610900 loss: 0.0003 lr: 0.002\n",
      "iteration: 611000 loss: 0.0003 lr: 0.002\n",
      "iteration: 611100 loss: 0.0003 lr: 0.002\n",
      "iteration: 611200 loss: 0.0004 lr: 0.002\n",
      "iteration: 611300 loss: 0.0004 lr: 0.002\n",
      "iteration: 611400 loss: 0.0004 lr: 0.002\n",
      "iteration: 611500 loss: 0.0003 lr: 0.002\n",
      "iteration: 611600 loss: 0.0004 lr: 0.002\n",
      "iteration: 611700 loss: 0.0003 lr: 0.002\n",
      "iteration: 611800 loss: 0.0003 lr: 0.002\n",
      "iteration: 611900 loss: 0.0004 lr: 0.002\n",
      "iteration: 612000 loss: 0.0003 lr: 0.002\n",
      "iteration: 612100 loss: 0.0004 lr: 0.002\n",
      "iteration: 612200 loss: 0.0004 lr: 0.002\n",
      "iteration: 612300 loss: 0.0004 lr: 0.002\n",
      "iteration: 612400 loss: 0.0003 lr: 0.002\n",
      "iteration: 612500 loss: 0.0003 lr: 0.002\n",
      "iteration: 612600 loss: 0.0003 lr: 0.002\n",
      "iteration: 612700 loss: 0.0003 lr: 0.002\n",
      "iteration: 612800 loss: 0.0003 lr: 0.002\n",
      "iteration: 612900 loss: 0.0003 lr: 0.002\n",
      "iteration: 613000 loss: 0.0003 lr: 0.002\n",
      "iteration: 613100 loss: 0.0003 lr: 0.002\n",
      "iteration: 613200 loss: 0.0003 lr: 0.002\n",
      "iteration: 613300 loss: 0.0003 lr: 0.002\n",
      "iteration: 613400 loss: 0.0004 lr: 0.002\n",
      "iteration: 613500 loss: 0.0003 lr: 0.002\n",
      "iteration: 613600 loss: 0.0003 lr: 0.002\n",
      "iteration: 613700 loss: 0.0003 lr: 0.002\n",
      "iteration: 613800 loss: 0.0003 lr: 0.002\n",
      "iteration: 613900 loss: 0.0003 lr: 0.002\n",
      "iteration: 614000 loss: 0.0003 lr: 0.002\n",
      "iteration: 614100 loss: 0.0003 lr: 0.002\n",
      "iteration: 614200 loss: 0.0003 lr: 0.002\n",
      "iteration: 614300 loss: 0.0003 lr: 0.002\n",
      "iteration: 614400 loss: 0.0003 lr: 0.002\n",
      "iteration: 614500 loss: 0.0004 lr: 0.002\n",
      "iteration: 614600 loss: 0.0003 lr: 0.002\n",
      "iteration: 614700 loss: 0.0003 lr: 0.002\n",
      "iteration: 614800 loss: 0.0004 lr: 0.002\n",
      "iteration: 614900 loss: 0.0003 lr: 0.002\n",
      "iteration: 615000 loss: 0.0003 lr: 0.002\n",
      "iteration: 615100 loss: 0.0003 lr: 0.002\n",
      "iteration: 615200 loss: 0.0003 lr: 0.002\n",
      "iteration: 615300 loss: 0.0004 lr: 0.002\n",
      "iteration: 615400 loss: 0.0004 lr: 0.002\n",
      "iteration: 615500 loss: 0.0003 lr: 0.002\n",
      "iteration: 615600 loss: 0.0003 lr: 0.002\n",
      "iteration: 615700 loss: 0.0003 lr: 0.002\n",
      "iteration: 615800 loss: 0.0003 lr: 0.002\n",
      "iteration: 615900 loss: 0.0003 lr: 0.002\n",
      "iteration: 616000 loss: 0.0003 lr: 0.002\n",
      "iteration: 616100 loss: 0.0003 lr: 0.002\n",
      "iteration: 616200 loss: 0.0004 lr: 0.002\n",
      "iteration: 616300 loss: 0.0003 lr: 0.002\n",
      "iteration: 616400 loss: 0.0003 lr: 0.002\n",
      "iteration: 616500 loss: 0.0003 lr: 0.002\n",
      "iteration: 616600 loss: 0.0004 lr: 0.002\n",
      "iteration: 616700 loss: 0.0004 lr: 0.002\n",
      "iteration: 616800 loss: 0.0003 lr: 0.002\n",
      "iteration: 616900 loss: 0.0004 lr: 0.002\n",
      "iteration: 617000 loss: 0.0003 lr: 0.002\n",
      "iteration: 617100 loss: 0.0003 lr: 0.002\n",
      "iteration: 617200 loss: 0.0003 lr: 0.002\n",
      "iteration: 617300 loss: 0.0004 lr: 0.002\n",
      "iteration: 617400 loss: 0.0004 lr: 0.002\n",
      "iteration: 617500 loss: 0.0003 lr: 0.002\n",
      "iteration: 617600 loss: 0.0003 lr: 0.002\n",
      "iteration: 617700 loss: 0.0004 lr: 0.002\n",
      "iteration: 617800 loss: 0.0003 lr: 0.002\n",
      "iteration: 617900 loss: 0.0003 lr: 0.002\n",
      "iteration: 618000 loss: 0.0004 lr: 0.002\n",
      "iteration: 618100 loss: 0.0003 lr: 0.002\n",
      "iteration: 618200 loss: 0.0003 lr: 0.002\n",
      "iteration: 618300 loss: 0.0003 lr: 0.002\n",
      "iteration: 618400 loss: 0.0003 lr: 0.002\n",
      "iteration: 618500 loss: 0.0003 lr: 0.002\n",
      "iteration: 618600 loss: 0.0003 lr: 0.002\n",
      "iteration: 618700 loss: 0.0004 lr: 0.002\n",
      "iteration: 618800 loss: 0.0003 lr: 0.002\n",
      "iteration: 618900 loss: 0.0003 lr: 0.002\n",
      "iteration: 619000 loss: 0.0003 lr: 0.002\n",
      "iteration: 619100 loss: 0.0003 lr: 0.002\n",
      "iteration: 619200 loss: 0.0003 lr: 0.002\n",
      "iteration: 619300 loss: 0.0003 lr: 0.002\n",
      "iteration: 619400 loss: 0.0003 lr: 0.002\n",
      "iteration: 619500 loss: 0.0003 lr: 0.002\n",
      "iteration: 619600 loss: 0.0003 lr: 0.002\n",
      "iteration: 619700 loss: 0.0002 lr: 0.002\n",
      "iteration: 619800 loss: 0.0003 lr: 0.002\n",
      "iteration: 619900 loss: 0.0003 lr: 0.002\n",
      "iteration: 620000 loss: 0.0003 lr: 0.002\n",
      "iteration: 620100 loss: 0.0003 lr: 0.002\n",
      "iteration: 620200 loss: 0.0003 lr: 0.002\n",
      "iteration: 620300 loss: 0.0003 lr: 0.002\n",
      "iteration: 620400 loss: 0.0003 lr: 0.002\n",
      "iteration: 620500 loss: 0.0003 lr: 0.002\n",
      "iteration: 620600 loss: 0.0003 lr: 0.002\n",
      "iteration: 620700 loss: 0.0004 lr: 0.002\n",
      "iteration: 620800 loss: 0.0003 lr: 0.002\n",
      "iteration: 620900 loss: 0.0003 lr: 0.002\n",
      "iteration: 621000 loss: 0.0004 lr: 0.002\n",
      "iteration: 621100 loss: 0.0002 lr: 0.002\n",
      "iteration: 621200 loss: 0.0003 lr: 0.002\n",
      "iteration: 621300 loss: 0.0002 lr: 0.002\n",
      "iteration: 621400 loss: 0.0003 lr: 0.002\n",
      "iteration: 621500 loss: 0.0004 lr: 0.002\n",
      "iteration: 621600 loss: 0.0003 lr: 0.002\n",
      "iteration: 621700 loss: 0.0003 lr: 0.002\n",
      "iteration: 621800 loss: 0.0003 lr: 0.002\n",
      "iteration: 621900 loss: 0.0003 lr: 0.002\n",
      "iteration: 622000 loss: 0.0003 lr: 0.002\n",
      "iteration: 622100 loss: 0.0003 lr: 0.002\n",
      "iteration: 622200 loss: 0.0003 lr: 0.002\n",
      "iteration: 622300 loss: 0.0003 lr: 0.002\n",
      "iteration: 622400 loss: 0.0002 lr: 0.002\n",
      "iteration: 622500 loss: 0.0004 lr: 0.002\n",
      "iteration: 622600 loss: 0.0003 lr: 0.002\n",
      "iteration: 622700 loss: 0.0003 lr: 0.002\n",
      "iteration: 622800 loss: 0.0003 lr: 0.002\n",
      "iteration: 622900 loss: 0.0003 lr: 0.002\n",
      "iteration: 623000 loss: 0.0004 lr: 0.002\n",
      "iteration: 623100 loss: 0.0003 lr: 0.002\n",
      "iteration: 623200 loss: 0.0003 lr: 0.002\n",
      "iteration: 623300 loss: 0.0003 lr: 0.002\n",
      "iteration: 623400 loss: 0.0004 lr: 0.002\n",
      "iteration: 623500 loss: 0.0004 lr: 0.002\n",
      "iteration: 623600 loss: 0.0003 lr: 0.002\n",
      "iteration: 623700 loss: 0.0003 lr: 0.002\n",
      "iteration: 623800 loss: 0.0004 lr: 0.002\n",
      "iteration: 623900 loss: 0.0004 lr: 0.002\n",
      "iteration: 624000 loss: 0.0003 lr: 0.002\n",
      "iteration: 624100 loss: 0.0004 lr: 0.002\n",
      "iteration: 624200 loss: 0.0003 lr: 0.002\n",
      "iteration: 624300 loss: 0.0003 lr: 0.002\n",
      "iteration: 624400 loss: 0.0003 lr: 0.002\n",
      "iteration: 624500 loss: 0.0004 lr: 0.002\n",
      "iteration: 624600 loss: 0.0004 lr: 0.002\n",
      "iteration: 624700 loss: 0.0004 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 624800 loss: 0.0003 lr: 0.002\n",
      "iteration: 624900 loss: 0.0003 lr: 0.002\n",
      "iteration: 625000 loss: 0.0003 lr: 0.002\n",
      "iteration: 625100 loss: 0.0003 lr: 0.002\n",
      "iteration: 625200 loss: 0.0002 lr: 0.002\n",
      "iteration: 625300 loss: 0.0004 lr: 0.002\n",
      "iteration: 625400 loss: 0.0003 lr: 0.002\n",
      "iteration: 625500 loss: 0.0003 lr: 0.002\n",
      "iteration: 625600 loss: 0.0003 lr: 0.002\n",
      "iteration: 625700 loss: 0.0002 lr: 0.002\n",
      "iteration: 625800 loss: 0.0004 lr: 0.002\n",
      "iteration: 625900 loss: 0.0004 lr: 0.002\n",
      "iteration: 626000 loss: 0.0002 lr: 0.002\n",
      "iteration: 626100 loss: 0.0004 lr: 0.002\n",
      "iteration: 626200 loss: 0.0003 lr: 0.002\n",
      "iteration: 626300 loss: 0.0003 lr: 0.002\n",
      "iteration: 626400 loss: 0.0003 lr: 0.002\n",
      "iteration: 626500 loss: 0.0003 lr: 0.002\n",
      "iteration: 626600 loss: 0.0003 lr: 0.002\n",
      "iteration: 626700 loss: 0.0003 lr: 0.002\n",
      "iteration: 626800 loss: 0.0003 lr: 0.002\n",
      "iteration: 626900 loss: 0.0003 lr: 0.002\n",
      "iteration: 627000 loss: 0.0003 lr: 0.002\n",
      "iteration: 627100 loss: 0.0003 lr: 0.002\n",
      "iteration: 627200 loss: 0.0003 lr: 0.002\n",
      "iteration: 627300 loss: 0.0003 lr: 0.002\n",
      "iteration: 627400 loss: 0.0004 lr: 0.002\n",
      "iteration: 627500 loss: 0.0004 lr: 0.002\n",
      "iteration: 627600 loss: 0.0004 lr: 0.002\n",
      "iteration: 627700 loss: 0.0004 lr: 0.002\n",
      "iteration: 627800 loss: 0.0003 lr: 0.002\n",
      "iteration: 627900 loss: 0.0003 lr: 0.002\n",
      "iteration: 628000 loss: 0.0004 lr: 0.002\n",
      "iteration: 628100 loss: 0.0003 lr: 0.002\n",
      "iteration: 628200 loss: 0.0002 lr: 0.002\n",
      "iteration: 628300 loss: 0.0003 lr: 0.002\n",
      "iteration: 628400 loss: 0.0006 lr: 0.002\n",
      "iteration: 628500 loss: 0.0004 lr: 0.002\n",
      "iteration: 628600 loss: 0.0003 lr: 0.002\n",
      "iteration: 628700 loss: 0.0003 lr: 0.002\n",
      "iteration: 628800 loss: 0.0003 lr: 0.002\n",
      "iteration: 628900 loss: 0.0004 lr: 0.002\n",
      "iteration: 629000 loss: 0.0003 lr: 0.002\n",
      "iteration: 629100 loss: 0.0003 lr: 0.002\n",
      "iteration: 629200 loss: 0.0003 lr: 0.002\n",
      "iteration: 629300 loss: 0.0003 lr: 0.002\n",
      "iteration: 629400 loss: 0.0003 lr: 0.002\n",
      "iteration: 629500 loss: 0.0002 lr: 0.002\n",
      "iteration: 629600 loss: 0.0003 lr: 0.002\n",
      "iteration: 629700 loss: 0.0003 lr: 0.002\n",
      "iteration: 629800 loss: 0.0003 lr: 0.002\n",
      "iteration: 629900 loss: 0.0003 lr: 0.002\n",
      "iteration: 630000 loss: 0.0003 lr: 0.002\n",
      "iteration: 630100 loss: 0.0002 lr: 0.002\n",
      "iteration: 630200 loss: 0.0003 lr: 0.002\n",
      "iteration: 630300 loss: 0.0003 lr: 0.002\n",
      "iteration: 630400 loss: 0.0003 lr: 0.002\n",
      "iteration: 630500 loss: 0.0003 lr: 0.002\n",
      "iteration: 630600 loss: 0.0003 lr: 0.002\n",
      "iteration: 630700 loss: 0.0003 lr: 0.002\n",
      "iteration: 630800 loss: 0.0004 lr: 0.002\n",
      "iteration: 630900 loss: 0.0002 lr: 0.002\n",
      "iteration: 631000 loss: 0.0003 lr: 0.002\n",
      "iteration: 631100 loss: 0.0003 lr: 0.002\n",
      "iteration: 631200 loss: 0.0004 lr: 0.002\n",
      "iteration: 631300 loss: 0.0003 lr: 0.002\n",
      "iteration: 631400 loss: 0.0003 lr: 0.002\n",
      "iteration: 631500 loss: 0.0004 lr: 0.002\n",
      "iteration: 631600 loss: 0.0003 lr: 0.002\n",
      "iteration: 631700 loss: 0.0004 lr: 0.002\n",
      "iteration: 631800 loss: 0.0003 lr: 0.002\n",
      "iteration: 631900 loss: 0.0003 lr: 0.002\n",
      "iteration: 632000 loss: 0.0002 lr: 0.002\n",
      "iteration: 632100 loss: 0.0003 lr: 0.002\n",
      "iteration: 632200 loss: 0.0004 lr: 0.002\n",
      "iteration: 632300 loss: 0.0003 lr: 0.002\n",
      "iteration: 632400 loss: 0.0002 lr: 0.002\n",
      "iteration: 632500 loss: 0.0003 lr: 0.002\n",
      "iteration: 632600 loss: 0.0003 lr: 0.002\n",
      "iteration: 632700 loss: 0.0004 lr: 0.002\n",
      "iteration: 632800 loss: 0.0002 lr: 0.002\n",
      "iteration: 632900 loss: 0.0003 lr: 0.002\n",
      "iteration: 633000 loss: 0.0004 lr: 0.002\n",
      "iteration: 633100 loss: 0.0003 lr: 0.002\n",
      "iteration: 633200 loss: 0.0003 lr: 0.002\n",
      "iteration: 633300 loss: 0.0003 lr: 0.002\n",
      "iteration: 633400 loss: 0.0003 lr: 0.002\n",
      "iteration: 633500 loss: 0.0004 lr: 0.002\n",
      "iteration: 633600 loss: 0.0005 lr: 0.002\n",
      "iteration: 633700 loss: 0.0003 lr: 0.002\n",
      "iteration: 633800 loss: 0.0004 lr: 0.002\n",
      "iteration: 633900 loss: 0.0003 lr: 0.002\n",
      "iteration: 634000 loss: 0.0003 lr: 0.002\n",
      "iteration: 634100 loss: 0.0003 lr: 0.002\n",
      "iteration: 634200 loss: 0.0003 lr: 0.002\n",
      "iteration: 634300 loss: 0.0003 lr: 0.002\n",
      "iteration: 634400 loss: 0.0003 lr: 0.002\n",
      "iteration: 634500 loss: 0.0003 lr: 0.002\n",
      "iteration: 634600 loss: 0.0003 lr: 0.002\n",
      "iteration: 634700 loss: 0.0003 lr: 0.002\n",
      "iteration: 634800 loss: 0.0003 lr: 0.002\n",
      "iteration: 634900 loss: 0.0004 lr: 0.002\n",
      "iteration: 635000 loss: 0.0003 lr: 0.002\n",
      "iteration: 635100 loss: 0.0003 lr: 0.002\n",
      "iteration: 635200 loss: 0.0003 lr: 0.002\n",
      "iteration: 635300 loss: 0.0004 lr: 0.002\n",
      "iteration: 635400 loss: 0.0003 lr: 0.002\n",
      "iteration: 635500 loss: 0.0002 lr: 0.002\n",
      "iteration: 635600 loss: 0.0004 lr: 0.002\n",
      "iteration: 635700 loss: 0.0003 lr: 0.002\n",
      "iteration: 635800 loss: 0.0003 lr: 0.002\n",
      "iteration: 635900 loss: 0.0002 lr: 0.002\n",
      "iteration: 636000 loss: 0.0003 lr: 0.002\n",
      "iteration: 636100 loss: 0.0003 lr: 0.002\n",
      "iteration: 636200 loss: 0.0003 lr: 0.002\n",
      "iteration: 636300 loss: 0.0003 lr: 0.002\n",
      "iteration: 636400 loss: 0.0002 lr: 0.002\n",
      "iteration: 636500 loss: 0.0004 lr: 0.002\n",
      "iteration: 636600 loss: 0.0004 lr: 0.002\n",
      "iteration: 636700 loss: 0.0003 lr: 0.002\n",
      "iteration: 636800 loss: 0.0003 lr: 0.002\n",
      "iteration: 636900 loss: 0.0004 lr: 0.002\n",
      "iteration: 637000 loss: 0.0003 lr: 0.002\n",
      "iteration: 637100 loss: 0.0003 lr: 0.002\n",
      "iteration: 637200 loss: 0.0003 lr: 0.002\n",
      "iteration: 637300 loss: 0.0003 lr: 0.002\n",
      "iteration: 637400 loss: 0.0003 lr: 0.002\n",
      "iteration: 637500 loss: 0.0004 lr: 0.002\n",
      "iteration: 637600 loss: 0.0004 lr: 0.002\n",
      "iteration: 637700 loss: 0.0003 lr: 0.002\n",
      "iteration: 637800 loss: 0.0003 lr: 0.002\n",
      "iteration: 637900 loss: 0.0004 lr: 0.002\n",
      "iteration: 638000 loss: 0.0003 lr: 0.002\n",
      "iteration: 638100 loss: 0.0003 lr: 0.002\n",
      "iteration: 638200 loss: 0.0003 lr: 0.002\n",
      "iteration: 638300 loss: 0.0003 lr: 0.002\n",
      "iteration: 638400 loss: 0.0003 lr: 0.002\n",
      "iteration: 638500 loss: 0.0003 lr: 0.002\n",
      "iteration: 638600 loss: 0.0003 lr: 0.002\n",
      "iteration: 638700 loss: 0.0002 lr: 0.002\n",
      "iteration: 638800 loss: 0.0003 lr: 0.002\n",
      "iteration: 638900 loss: 0.0002 lr: 0.002\n",
      "iteration: 639000 loss: 0.0003 lr: 0.002\n",
      "iteration: 639100 loss: 0.0004 lr: 0.002\n",
      "iteration: 639200 loss: 0.0003 lr: 0.002\n",
      "iteration: 639300 loss: 0.0003 lr: 0.002\n",
      "iteration: 639400 loss: 0.0003 lr: 0.002\n",
      "iteration: 639500 loss: 0.0003 lr: 0.002\n",
      "iteration: 639600 loss: 0.0003 lr: 0.002\n",
      "iteration: 639700 loss: 0.0003 lr: 0.002\n",
      "iteration: 639800 loss: 0.0004 lr: 0.002\n",
      "iteration: 639900 loss: 0.0004 lr: 0.002\n",
      "iteration: 640000 loss: 0.0003 lr: 0.002\n",
      "iteration: 640100 loss: 0.0003 lr: 0.002\n",
      "iteration: 640200 loss: 0.0003 lr: 0.002\n",
      "iteration: 640300 loss: 0.0003 lr: 0.002\n",
      "iteration: 640400 loss: 0.0002 lr: 0.002\n",
      "iteration: 640500 loss: 0.0003 lr: 0.002\n",
      "iteration: 640600 loss: 0.0003 lr: 0.002\n",
      "iteration: 640700 loss: 0.0003 lr: 0.002\n",
      "iteration: 640800 loss: 0.0004 lr: 0.002\n",
      "iteration: 640900 loss: 0.0003 lr: 0.002\n",
      "iteration: 641000 loss: 0.0003 lr: 0.002\n",
      "iteration: 641100 loss: 0.0003 lr: 0.002\n",
      "iteration: 641200 loss: 0.0004 lr: 0.002\n",
      "iteration: 641300 loss: 0.0003 lr: 0.002\n",
      "iteration: 641400 loss: 0.0003 lr: 0.002\n",
      "iteration: 641500 loss: 0.0003 lr: 0.002\n",
      "iteration: 641600 loss: 0.0003 lr: 0.002\n",
      "iteration: 641700 loss: 0.0003 lr: 0.002\n",
      "iteration: 641800 loss: 0.0003 lr: 0.002\n",
      "iteration: 641900 loss: 0.0003 lr: 0.002\n",
      "iteration: 642000 loss: 0.0003 lr: 0.002\n",
      "iteration: 642100 loss: 0.0003 lr: 0.002\n",
      "iteration: 642200 loss: 0.0003 lr: 0.002\n",
      "iteration: 642300 loss: 0.0003 lr: 0.002\n",
      "iteration: 642400 loss: 0.0003 lr: 0.002\n",
      "iteration: 642500 loss: 0.0003 lr: 0.002\n",
      "iteration: 642600 loss: 0.0004 lr: 0.002\n",
      "iteration: 642700 loss: 0.0003 lr: 0.002\n",
      "iteration: 642800 loss: 0.0004 lr: 0.002\n",
      "iteration: 642900 loss: 0.0003 lr: 0.002\n",
      "iteration: 643000 loss: 0.0003 lr: 0.002\n",
      "iteration: 643100 loss: 0.0003 lr: 0.002\n",
      "iteration: 643200 loss: 0.0003 lr: 0.002\n",
      "iteration: 643300 loss: 0.0004 lr: 0.002\n",
      "iteration: 643400 loss: 0.0003 lr: 0.002\n",
      "iteration: 643500 loss: 0.0003 lr: 0.002\n",
      "iteration: 643600 loss: 0.0002 lr: 0.002\n",
      "iteration: 643700 loss: 0.0003 lr: 0.002\n",
      "iteration: 643800 loss: 0.0002 lr: 0.002\n",
      "iteration: 643900 loss: 0.0004 lr: 0.002\n",
      "iteration: 644000 loss: 0.0003 lr: 0.002\n",
      "iteration: 644100 loss: 0.0003 lr: 0.002\n",
      "iteration: 644200 loss: 0.0003 lr: 0.002\n",
      "iteration: 644300 loss: 0.0004 lr: 0.002\n",
      "iteration: 644400 loss: 0.0003 lr: 0.002\n",
      "iteration: 644500 loss: 0.0003 lr: 0.002\n",
      "iteration: 644600 loss: 0.0003 lr: 0.002\n",
      "iteration: 644700 loss: 0.0002 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 644800 loss: 0.0003 lr: 0.002\n",
      "iteration: 644900 loss: 0.0003 lr: 0.002\n",
      "iteration: 645000 loss: 0.0004 lr: 0.002\n",
      "iteration: 645100 loss: 0.0003 lr: 0.002\n",
      "iteration: 645200 loss: 0.0003 lr: 0.002\n",
      "iteration: 645300 loss: 0.0003 lr: 0.002\n",
      "iteration: 645400 loss: 0.0003 lr: 0.002\n",
      "iteration: 645500 loss: 0.0003 lr: 0.002\n",
      "iteration: 645600 loss: 0.0002 lr: 0.002\n",
      "iteration: 645700 loss: 0.0003 lr: 0.002\n",
      "iteration: 645800 loss: 0.0003 lr: 0.002\n",
      "iteration: 645900 loss: 0.0003 lr: 0.002\n",
      "iteration: 646000 loss: 0.0003 lr: 0.002\n",
      "iteration: 646100 loss: 0.0004 lr: 0.002\n",
      "iteration: 646200 loss: 0.0003 lr: 0.002\n",
      "iteration: 646300 loss: 0.0003 lr: 0.002\n",
      "iteration: 646400 loss: 0.0003 lr: 0.002\n",
      "iteration: 646500 loss: 0.0003 lr: 0.002\n",
      "iteration: 646600 loss: 0.0003 lr: 0.002\n",
      "iteration: 646700 loss: 0.0003 lr: 0.002\n",
      "iteration: 646800 loss: 0.0004 lr: 0.002\n",
      "iteration: 646900 loss: 0.0003 lr: 0.002\n",
      "iteration: 647000 loss: 0.0004 lr: 0.002\n",
      "iteration: 647100 loss: 0.0003 lr: 0.002\n",
      "iteration: 647200 loss: 0.0003 lr: 0.002\n",
      "iteration: 647300 loss: 0.0003 lr: 0.002\n",
      "iteration: 647400 loss: 0.0004 lr: 0.002\n",
      "iteration: 647500 loss: 0.0003 lr: 0.002\n",
      "iteration: 647600 loss: 0.0003 lr: 0.002\n",
      "iteration: 647700 loss: 0.0003 lr: 0.002\n",
      "iteration: 647800 loss: 0.0002 lr: 0.002\n",
      "iteration: 647900 loss: 0.0003 lr: 0.002\n",
      "iteration: 648000 loss: 0.0003 lr: 0.002\n",
      "iteration: 648100 loss: 0.0003 lr: 0.002\n",
      "iteration: 648200 loss: 0.0003 lr: 0.002\n",
      "iteration: 648300 loss: 0.0003 lr: 0.002\n",
      "iteration: 648400 loss: 0.0004 lr: 0.002\n",
      "iteration: 648500 loss: 0.0003 lr: 0.002\n",
      "iteration: 648600 loss: 0.0003 lr: 0.002\n",
      "iteration: 648700 loss: 0.0003 lr: 0.002\n",
      "iteration: 648800 loss: 0.0003 lr: 0.002\n",
      "iteration: 648900 loss: 0.0004 lr: 0.002\n",
      "iteration: 649000 loss: 0.0003 lr: 0.002\n",
      "iteration: 649100 loss: 0.0003 lr: 0.002\n",
      "iteration: 649200 loss: 0.0003 lr: 0.002\n",
      "iteration: 649300 loss: 0.0003 lr: 0.002\n",
      "iteration: 649400 loss: 0.0003 lr: 0.002\n",
      "iteration: 649500 loss: 0.0004 lr: 0.002\n",
      "iteration: 649600 loss: 0.0003 lr: 0.002\n",
      "iteration: 649700 loss: 0.0003 lr: 0.002\n",
      "iteration: 649800 loss: 0.0003 lr: 0.002\n",
      "iteration: 649900 loss: 0.0003 lr: 0.002\n",
      "iteration: 650000 loss: 0.0003 lr: 0.002\n",
      "iteration: 650100 loss: 0.0003 lr: 0.002\n",
      "iteration: 650200 loss: 0.0004 lr: 0.002\n",
      "iteration: 650300 loss: 0.0003 lr: 0.002\n",
      "iteration: 650400 loss: 0.0003 lr: 0.002\n",
      "iteration: 650500 loss: 0.0003 lr: 0.002\n",
      "iteration: 650600 loss: 0.0003 lr: 0.002\n",
      "iteration: 650700 loss: 0.0003 lr: 0.002\n",
      "iteration: 650800 loss: 0.0003 lr: 0.002\n",
      "iteration: 650900 loss: 0.0003 lr: 0.002\n",
      "iteration: 651000 loss: 0.0003 lr: 0.002\n",
      "iteration: 651100 loss: 0.0004 lr: 0.002\n",
      "iteration: 651200 loss: 0.0003 lr: 0.002\n",
      "iteration: 651300 loss: 0.0003 lr: 0.002\n",
      "iteration: 651400 loss: 0.0004 lr: 0.002\n",
      "iteration: 651500 loss: 0.0002 lr: 0.002\n",
      "iteration: 651600 loss: 0.0003 lr: 0.002\n",
      "iteration: 651700 loss: 0.0003 lr: 0.002\n",
      "iteration: 651800 loss: 0.0003 lr: 0.002\n",
      "iteration: 651900 loss: 0.0004 lr: 0.002\n",
      "iteration: 652000 loss: 0.0003 lr: 0.002\n",
      "iteration: 652100 loss: 0.0003 lr: 0.002\n",
      "iteration: 652200 loss: 0.0003 lr: 0.002\n",
      "iteration: 652300 loss: 0.0004 lr: 0.002\n",
      "iteration: 652400 loss: 0.0004 lr: 0.002\n",
      "iteration: 652500 loss: 0.0002 lr: 0.002\n",
      "iteration: 652600 loss: 0.0004 lr: 0.002\n",
      "iteration: 652700 loss: 0.0003 lr: 0.002\n",
      "iteration: 652800 loss: 0.0003 lr: 0.002\n",
      "iteration: 652900 loss: 0.0003 lr: 0.002\n",
      "iteration: 653000 loss: 0.0003 lr: 0.002\n",
      "iteration: 653100 loss: 0.0003 lr: 0.002\n",
      "iteration: 653200 loss: 0.0004 lr: 0.002\n",
      "iteration: 653300 loss: 0.0003 lr: 0.002\n",
      "iteration: 653400 loss: 0.0003 lr: 0.002\n",
      "iteration: 653500 loss: 0.0003 lr: 0.002\n",
      "iteration: 653600 loss: 0.0003 lr: 0.002\n",
      "iteration: 653700 loss: 0.0003 lr: 0.002\n",
      "iteration: 653800 loss: 0.0003 lr: 0.002\n",
      "iteration: 653900 loss: 0.0003 lr: 0.002\n",
      "iteration: 654000 loss: 0.0002 lr: 0.002\n",
      "iteration: 654100 loss: 0.0003 lr: 0.002\n",
      "iteration: 654200 loss: 0.0004 lr: 0.002\n",
      "iteration: 654300 loss: 0.0003 lr: 0.002\n",
      "iteration: 654400 loss: 0.0004 lr: 0.002\n",
      "iteration: 654500 loss: 0.0002 lr: 0.002\n",
      "iteration: 654600 loss: 0.0004 lr: 0.002\n",
      "iteration: 654700 loss: 0.0002 lr: 0.002\n",
      "iteration: 654800 loss: 0.0003 lr: 0.002\n",
      "iteration: 654900 loss: 0.0003 lr: 0.002\n",
      "iteration: 655000 loss: 0.0004 lr: 0.002\n",
      "iteration: 655100 loss: 0.0003 lr: 0.002\n",
      "iteration: 655200 loss: 0.0003 lr: 0.002\n",
      "iteration: 655300 loss: 0.0004 lr: 0.002\n",
      "iteration: 655400 loss: 0.0003 lr: 0.002\n",
      "iteration: 655500 loss: 0.0003 lr: 0.002\n",
      "iteration: 655600 loss: 0.0003 lr: 0.002\n",
      "iteration: 655700 loss: 0.0003 lr: 0.002\n",
      "iteration: 655800 loss: 0.0004 lr: 0.002\n",
      "iteration: 655900 loss: 0.0004 lr: 0.002\n",
      "iteration: 656000 loss: 0.0003 lr: 0.002\n",
      "iteration: 656100 loss: 0.0003 lr: 0.002\n",
      "iteration: 656200 loss: 0.0004 lr: 0.002\n",
      "iteration: 656300 loss: 0.0003 lr: 0.002\n",
      "iteration: 656400 loss: 0.0004 lr: 0.002\n",
      "iteration: 656500 loss: 0.0004 lr: 0.002\n",
      "iteration: 656600 loss: 0.0003 lr: 0.002\n",
      "iteration: 656700 loss: 0.0002 lr: 0.002\n",
      "iteration: 656800 loss: 0.0003 lr: 0.002\n",
      "iteration: 656900 loss: 0.0003 lr: 0.002\n",
      "iteration: 657000 loss: 0.0003 lr: 0.002\n",
      "iteration: 657100 loss: 0.0003 lr: 0.002\n",
      "iteration: 657200 loss: 0.0003 lr: 0.002\n",
      "iteration: 657300 loss: 0.0003 lr: 0.002\n",
      "iteration: 657400 loss: 0.0004 lr: 0.002\n",
      "iteration: 657500 loss: 0.0003 lr: 0.002\n",
      "iteration: 657600 loss: 0.0003 lr: 0.002\n",
      "iteration: 657700 loss: 0.0003 lr: 0.002\n",
      "iteration: 657800 loss: 0.0003 lr: 0.002\n",
      "iteration: 657900 loss: 0.0002 lr: 0.002\n",
      "iteration: 658000 loss: 0.0002 lr: 0.002\n",
      "iteration: 658100 loss: 0.0003 lr: 0.002\n",
      "iteration: 658200 loss: 0.0002 lr: 0.002\n",
      "iteration: 658300 loss: 0.0003 lr: 0.002\n",
      "iteration: 658400 loss: 0.0002 lr: 0.002\n",
      "iteration: 658500 loss: 0.0004 lr: 0.002\n",
      "iteration: 658600 loss: 0.0002 lr: 0.002\n",
      "iteration: 658700 loss: 0.0003 lr: 0.002\n",
      "iteration: 658800 loss: 0.0003 lr: 0.002\n",
      "iteration: 658900 loss: 0.0003 lr: 0.002\n",
      "iteration: 659000 loss: 0.0003 lr: 0.002\n",
      "iteration: 659100 loss: 0.0003 lr: 0.002\n",
      "iteration: 659200 loss: 0.0003 lr: 0.002\n",
      "iteration: 659300 loss: 0.0003 lr: 0.002\n",
      "iteration: 659400 loss: 0.0003 lr: 0.002\n",
      "iteration: 659500 loss: 0.0003 lr: 0.002\n",
      "iteration: 659600 loss: 0.0003 lr: 0.002\n",
      "iteration: 659700 loss: 0.0003 lr: 0.002\n",
      "iteration: 659800 loss: 0.0003 lr: 0.002\n",
      "iteration: 659900 loss: 0.0002 lr: 0.002\n",
      "iteration: 660000 loss: 0.0003 lr: 0.002\n",
      "iteration: 660100 loss: 0.0003 lr: 0.002\n",
      "iteration: 660200 loss: 0.0002 lr: 0.002\n",
      "iteration: 660300 loss: 0.0003 lr: 0.002\n",
      "iteration: 660400 loss: 0.0003 lr: 0.002\n",
      "iteration: 660500 loss: 0.0003 lr: 0.002\n",
      "iteration: 660600 loss: 0.0003 lr: 0.002\n",
      "iteration: 660700 loss: 0.0003 lr: 0.002\n",
      "iteration: 660800 loss: 0.0003 lr: 0.002\n",
      "iteration: 660900 loss: 0.0003 lr: 0.002\n",
      "iteration: 661000 loss: 0.0004 lr: 0.002\n",
      "iteration: 661100 loss: 0.0003 lr: 0.002\n",
      "iteration: 661200 loss: 0.0003 lr: 0.002\n",
      "iteration: 661300 loss: 0.0003 lr: 0.002\n",
      "iteration: 661400 loss: 0.0004 lr: 0.002\n",
      "iteration: 661500 loss: 0.0003 lr: 0.002\n",
      "iteration: 661600 loss: 0.0003 lr: 0.002\n",
      "iteration: 661700 loss: 0.0004 lr: 0.002\n",
      "iteration: 661800 loss: 0.0002 lr: 0.002\n",
      "iteration: 661900 loss: 0.0003 lr: 0.002\n",
      "iteration: 662000 loss: 0.0004 lr: 0.002\n",
      "iteration: 662100 loss: 0.0003 lr: 0.002\n",
      "iteration: 662200 loss: 0.0003 lr: 0.002\n",
      "iteration: 662300 loss: 0.0003 lr: 0.002\n",
      "iteration: 662400 loss: 0.0002 lr: 0.002\n",
      "iteration: 662500 loss: 0.0002 lr: 0.002\n",
      "iteration: 662600 loss: 0.0003 lr: 0.002\n",
      "iteration: 662700 loss: 0.0003 lr: 0.002\n",
      "iteration: 662800 loss: 0.0003 lr: 0.002\n",
      "iteration: 662900 loss: 0.0003 lr: 0.002\n",
      "iteration: 663000 loss: 0.0003 lr: 0.002\n",
      "iteration: 663100 loss: 0.0003 lr: 0.002\n",
      "iteration: 663200 loss: 0.0003 lr: 0.002\n",
      "iteration: 663300 loss: 0.0003 lr: 0.002\n",
      "iteration: 663400 loss: 0.0003 lr: 0.002\n",
      "iteration: 663500 loss: 0.0004 lr: 0.002\n",
      "iteration: 663600 loss: 0.0004 lr: 0.002\n",
      "iteration: 663700 loss: 0.0003 lr: 0.002\n",
      "iteration: 663800 loss: 0.0003 lr: 0.002\n",
      "iteration: 663900 loss: 0.0002 lr: 0.002\n",
      "iteration: 664000 loss: 0.0003 lr: 0.002\n",
      "iteration: 664100 loss: 0.0004 lr: 0.002\n",
      "iteration: 664200 loss: 0.0003 lr: 0.002\n",
      "iteration: 664300 loss: 0.0003 lr: 0.002\n",
      "iteration: 664400 loss: 0.0003 lr: 0.002\n",
      "iteration: 664500 loss: 0.0003 lr: 0.002\n",
      "iteration: 664600 loss: 0.0004 lr: 0.002\n",
      "iteration: 664700 loss: 0.0003 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 664800 loss: 0.0004 lr: 0.002\n",
      "iteration: 664900 loss: 0.0003 lr: 0.002\n",
      "iteration: 665000 loss: 0.0003 lr: 0.002\n",
      "iteration: 665100 loss: 0.0002 lr: 0.002\n",
      "iteration: 665200 loss: 0.0003 lr: 0.002\n",
      "iteration: 665300 loss: 0.0004 lr: 0.002\n",
      "iteration: 665400 loss: 0.0003 lr: 0.002\n",
      "iteration: 665500 loss: 0.0003 lr: 0.002\n",
      "iteration: 665600 loss: 0.0003 lr: 0.002\n",
      "iteration: 665700 loss: 0.0004 lr: 0.002\n",
      "iteration: 665800 loss: 0.0003 lr: 0.002\n",
      "iteration: 665900 loss: 0.0004 lr: 0.002\n",
      "iteration: 666000 loss: 0.0003 lr: 0.002\n",
      "iteration: 666100 loss: 0.0003 lr: 0.002\n",
      "iteration: 666200 loss: 0.0003 lr: 0.002\n",
      "iteration: 666300 loss: 0.0004 lr: 0.002\n",
      "iteration: 666400 loss: 0.0004 lr: 0.002\n",
      "iteration: 666500 loss: 0.0003 lr: 0.002\n",
      "iteration: 666600 loss: 0.0003 lr: 0.002\n",
      "iteration: 666700 loss: 0.0003 lr: 0.002\n",
      "iteration: 666800 loss: 0.0003 lr: 0.002\n",
      "iteration: 666900 loss: 0.0003 lr: 0.002\n",
      "iteration: 667000 loss: 0.0003 lr: 0.002\n",
      "iteration: 667100 loss: 0.0003 lr: 0.002\n",
      "iteration: 667200 loss: 0.0003 lr: 0.002\n",
      "iteration: 667300 loss: 0.0004 lr: 0.002\n",
      "iteration: 667400 loss: 0.0003 lr: 0.002\n",
      "iteration: 667500 loss: 0.0002 lr: 0.002\n",
      "iteration: 667600 loss: 0.0002 lr: 0.002\n",
      "iteration: 667700 loss: 0.0003 lr: 0.002\n",
      "iteration: 667800 loss: 0.0003 lr: 0.002\n",
      "iteration: 667900 loss: 0.0002 lr: 0.002\n",
      "iteration: 668000 loss: 0.0002 lr: 0.002\n",
      "iteration: 668100 loss: 0.0003 lr: 0.002\n",
      "iteration: 668200 loss: 0.0003 lr: 0.002\n",
      "iteration: 668300 loss: 0.0003 lr: 0.002\n",
      "iteration: 668400 loss: 0.0003 lr: 0.002\n",
      "iteration: 668500 loss: 0.0003 lr: 0.002\n",
      "iteration: 668600 loss: 0.0003 lr: 0.002\n",
      "iteration: 668700 loss: 0.0003 lr: 0.002\n",
      "iteration: 668800 loss: 0.0003 lr: 0.002\n",
      "iteration: 668900 loss: 0.0003 lr: 0.002\n",
      "iteration: 669000 loss: 0.0003 lr: 0.002\n",
      "iteration: 669100 loss: 0.0003 lr: 0.002\n",
      "iteration: 669200 loss: 0.0003 lr: 0.002\n",
      "iteration: 669300 loss: 0.0003 lr: 0.002\n",
      "iteration: 669400 loss: 0.0003 lr: 0.002\n",
      "iteration: 669500 loss: 0.0003 lr: 0.002\n",
      "iteration: 669600 loss: 0.0006 lr: 0.002\n",
      "iteration: 669700 loss: 0.0004 lr: 0.002\n",
      "iteration: 669800 loss: 0.0003 lr: 0.002\n",
      "iteration: 669900 loss: 0.0003 lr: 0.002\n",
      "iteration: 670000 loss: 0.0004 lr: 0.002\n",
      "iteration: 670100 loss: 0.0003 lr: 0.002\n",
      "iteration: 670200 loss: 0.0003 lr: 0.002\n",
      "iteration: 670300 loss: 0.0003 lr: 0.002\n",
      "iteration: 670400 loss: 0.0003 lr: 0.002\n",
      "iteration: 670500 loss: 0.0003 lr: 0.002\n",
      "iteration: 670600 loss: 0.0003 lr: 0.002\n",
      "iteration: 670700 loss: 0.0003 lr: 0.002\n",
      "iteration: 670800 loss: 0.0003 lr: 0.002\n",
      "iteration: 670900 loss: 0.0003 lr: 0.002\n",
      "iteration: 671000 loss: 0.0003 lr: 0.002\n",
      "iteration: 671100 loss: 0.0004 lr: 0.002\n",
      "iteration: 671200 loss: 0.0003 lr: 0.002\n",
      "iteration: 671300 loss: 0.0003 lr: 0.002\n",
      "iteration: 671400 loss: 0.0003 lr: 0.002\n",
      "iteration: 671500 loss: 0.0003 lr: 0.002\n",
      "iteration: 671600 loss: 0.0002 lr: 0.002\n",
      "iteration: 671700 loss: 0.0003 lr: 0.002\n",
      "iteration: 671800 loss: 0.0002 lr: 0.002\n",
      "iteration: 671900 loss: 0.0003 lr: 0.002\n",
      "iteration: 672000 loss: 0.0003 lr: 0.002\n",
      "iteration: 672100 loss: 0.0003 lr: 0.002\n",
      "iteration: 672200 loss: 0.0003 lr: 0.002\n",
      "iteration: 672300 loss: 0.0003 lr: 0.002\n",
      "iteration: 672400 loss: 0.0003 lr: 0.002\n",
      "iteration: 672500 loss: 0.0003 lr: 0.002\n",
      "iteration: 672600 loss: 0.0004 lr: 0.002\n",
      "iteration: 672700 loss: 0.0003 lr: 0.002\n",
      "iteration: 672800 loss: 0.0003 lr: 0.002\n",
      "iteration: 672900 loss: 0.0004 lr: 0.002\n",
      "iteration: 673000 loss: 0.0003 lr: 0.002\n",
      "iteration: 673100 loss: 0.0003 lr: 0.002\n",
      "iteration: 673200 loss: 0.0004 lr: 0.002\n",
      "iteration: 673300 loss: 0.0005 lr: 0.002\n",
      "iteration: 673400 loss: 0.0003 lr: 0.002\n",
      "iteration: 673500 loss: 0.0003 lr: 0.002\n",
      "iteration: 673600 loss: 0.0003 lr: 0.002\n",
      "iteration: 673700 loss: 0.0003 lr: 0.002\n",
      "iteration: 673800 loss: 0.0002 lr: 0.002\n",
      "iteration: 673900 loss: 0.0003 lr: 0.002\n",
      "iteration: 674000 loss: 0.0003 lr: 0.002\n",
      "iteration: 674100 loss: 0.0003 lr: 0.002\n",
      "iteration: 674200 loss: 0.0003 lr: 0.002\n",
      "iteration: 674300 loss: 0.0003 lr: 0.002\n",
      "iteration: 674400 loss: 0.0003 lr: 0.002\n",
      "iteration: 674500 loss: 0.0003 lr: 0.002\n",
      "iteration: 674600 loss: 0.0003 lr: 0.002\n",
      "iteration: 674700 loss: 0.0003 lr: 0.002\n",
      "iteration: 674800 loss: 0.0003 lr: 0.002\n",
      "iteration: 674900 loss: 0.0003 lr: 0.002\n",
      "iteration: 675000 loss: 0.0003 lr: 0.002\n",
      "iteration: 675100 loss: 0.0003 lr: 0.002\n",
      "iteration: 675200 loss: 0.0003 lr: 0.002\n",
      "iteration: 675300 loss: 0.0003 lr: 0.002\n",
      "iteration: 675400 loss: 0.0003 lr: 0.002\n",
      "iteration: 675500 loss: 0.0003 lr: 0.002\n",
      "iteration: 675600 loss: 0.0003 lr: 0.002\n",
      "iteration: 675700 loss: 0.0002 lr: 0.002\n",
      "iteration: 675800 loss: 0.0003 lr: 0.002\n",
      "iteration: 675900 loss: 0.0003 lr: 0.002\n",
      "iteration: 676000 loss: 0.0003 lr: 0.002\n",
      "iteration: 676100 loss: 0.0003 lr: 0.002\n",
      "iteration: 676200 loss: 0.0002 lr: 0.002\n",
      "iteration: 676300 loss: 0.0003 lr: 0.002\n",
      "iteration: 676400 loss: 0.0002 lr: 0.002\n",
      "iteration: 676500 loss: 0.0003 lr: 0.002\n",
      "iteration: 676600 loss: 0.0003 lr: 0.002\n",
      "iteration: 676700 loss: 0.0004 lr: 0.002\n",
      "iteration: 676800 loss: 0.0003 lr: 0.002\n",
      "iteration: 676900 loss: 0.0002 lr: 0.002\n",
      "iteration: 677000 loss: 0.0003 lr: 0.002\n",
      "iteration: 677100 loss: 0.0003 lr: 0.002\n",
      "iteration: 677200 loss: 0.0002 lr: 0.002\n",
      "iteration: 677300 loss: 0.0003 lr: 0.002\n",
      "iteration: 677400 loss: 0.0003 lr: 0.002\n",
      "iteration: 677500 loss: 0.0003 lr: 0.002\n",
      "iteration: 677600 loss: 0.0003 lr: 0.002\n",
      "iteration: 677700 loss: 0.0003 lr: 0.002\n",
      "iteration: 677800 loss: 0.0004 lr: 0.002\n",
      "iteration: 677900 loss: 0.0003 lr: 0.002\n",
      "iteration: 678000 loss: 0.0003 lr: 0.002\n",
      "iteration: 678100 loss: 0.0004 lr: 0.002\n",
      "iteration: 678200 loss: 0.0003 lr: 0.002\n",
      "iteration: 678300 loss: 0.0003 lr: 0.002\n",
      "iteration: 678400 loss: 0.0002 lr: 0.002\n",
      "iteration: 678500 loss: 0.0003 lr: 0.002\n",
      "iteration: 678600 loss: 0.0002 lr: 0.002\n",
      "iteration: 678700 loss: 0.0003 lr: 0.002\n",
      "iteration: 678800 loss: 0.0004 lr: 0.002\n",
      "iteration: 678900 loss: 0.0003 lr: 0.002\n",
      "iteration: 679000 loss: 0.0003 lr: 0.002\n",
      "iteration: 679100 loss: 0.0003 lr: 0.002\n",
      "iteration: 679200 loss: 0.0003 lr: 0.002\n",
      "iteration: 679300 loss: 0.0003 lr: 0.002\n",
      "iteration: 679400 loss: 0.0003 lr: 0.002\n",
      "iteration: 679500 loss: 0.0003 lr: 0.002\n",
      "iteration: 679600 loss: 0.0004 lr: 0.002\n",
      "iteration: 679700 loss: 0.0004 lr: 0.002\n",
      "iteration: 679800 loss: 0.0003 lr: 0.002\n",
      "iteration: 679900 loss: 0.0004 lr: 0.002\n",
      "iteration: 680000 loss: 0.0003 lr: 0.002\n",
      "iteration: 680100 loss: 0.0003 lr: 0.002\n",
      "iteration: 680200 loss: 0.0003 lr: 0.002\n",
      "iteration: 680300 loss: 0.0003 lr: 0.002\n",
      "iteration: 680400 loss: 0.0002 lr: 0.002\n",
      "iteration: 680500 loss: 0.0003 lr: 0.002\n",
      "iteration: 680600 loss: 0.0003 lr: 0.002\n",
      "iteration: 680700 loss: 0.0003 lr: 0.002\n",
      "iteration: 680800 loss: 0.0003 lr: 0.002\n",
      "iteration: 680900 loss: 0.0003 lr: 0.002\n",
      "iteration: 681000 loss: 0.0003 lr: 0.002\n",
      "iteration: 681100 loss: 0.0003 lr: 0.002\n",
      "iteration: 681200 loss: 0.0003 lr: 0.002\n",
      "iteration: 681300 loss: 0.0004 lr: 0.002\n",
      "iteration: 681400 loss: 0.0003 lr: 0.002\n",
      "iteration: 681500 loss: 0.0003 lr: 0.002\n",
      "iteration: 681600 loss: 0.0004 lr: 0.002\n",
      "iteration: 681700 loss: 0.0003 lr: 0.002\n",
      "iteration: 681800 loss: 0.0003 lr: 0.002\n",
      "iteration: 681900 loss: 0.0003 lr: 0.002\n",
      "iteration: 682000 loss: 0.0003 lr: 0.002\n",
      "iteration: 682100 loss: 0.0003 lr: 0.002\n",
      "iteration: 682200 loss: 0.0003 lr: 0.002\n",
      "iteration: 682300 loss: 0.0003 lr: 0.002\n",
      "iteration: 682400 loss: 0.0003 lr: 0.002\n",
      "iteration: 682500 loss: 0.0002 lr: 0.002\n",
      "iteration: 682600 loss: 0.0003 lr: 0.002\n",
      "iteration: 682700 loss: 0.0003 lr: 0.002\n",
      "iteration: 682800 loss: 0.0003 lr: 0.002\n",
      "iteration: 682900 loss: 0.0004 lr: 0.002\n",
      "iteration: 683000 loss: 0.0003 lr: 0.002\n",
      "iteration: 683100 loss: 0.0003 lr: 0.002\n",
      "iteration: 683200 loss: 0.0003 lr: 0.002\n",
      "iteration: 683300 loss: 0.0002 lr: 0.002\n",
      "iteration: 683400 loss: 0.0003 lr: 0.002\n",
      "iteration: 683500 loss: 0.0003 lr: 0.002\n",
      "iteration: 683600 loss: 0.0003 lr: 0.002\n",
      "iteration: 683700 loss: 0.0003 lr: 0.002\n",
      "iteration: 683800 loss: 0.0003 lr: 0.002\n",
      "iteration: 683900 loss: 0.0003 lr: 0.002\n",
      "iteration: 684000 loss: 0.0003 lr: 0.002\n",
      "iteration: 684100 loss: 0.0003 lr: 0.002\n",
      "iteration: 684200 loss: 0.0003 lr: 0.002\n",
      "iteration: 684300 loss: 0.0002 lr: 0.002\n",
      "iteration: 684400 loss: 0.0004 lr: 0.002\n",
      "iteration: 684500 loss: 0.0003 lr: 0.002\n",
      "iteration: 684600 loss: 0.0003 lr: 0.002\n",
      "iteration: 684700 loss: 0.0003 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 684800 loss: 0.0002 lr: 0.002\n",
      "iteration: 684900 loss: 0.0004 lr: 0.002\n",
      "iteration: 685000 loss: 0.0002 lr: 0.002\n",
      "iteration: 685100 loss: 0.0004 lr: 0.002\n",
      "iteration: 685200 loss: 0.0002 lr: 0.002\n",
      "iteration: 685300 loss: 0.0005 lr: 0.002\n",
      "iteration: 685400 loss: 0.0003 lr: 0.002\n",
      "iteration: 685500 loss: 0.0002 lr: 0.002\n",
      "iteration: 685600 loss: 0.0003 lr: 0.002\n",
      "iteration: 685700 loss: 0.0003 lr: 0.002\n",
      "iteration: 685800 loss: 0.0003 lr: 0.002\n",
      "iteration: 685900 loss: 0.0002 lr: 0.002\n",
      "iteration: 686000 loss: 0.0003 lr: 0.002\n",
      "iteration: 686100 loss: 0.0003 lr: 0.002\n",
      "iteration: 686200 loss: 0.0003 lr: 0.002\n",
      "iteration: 686300 loss: 0.0004 lr: 0.002\n",
      "iteration: 686400 loss: 0.0004 lr: 0.002\n",
      "iteration: 686500 loss: 0.0003 lr: 0.002\n",
      "iteration: 686600 loss: 0.0003 lr: 0.002\n",
      "iteration: 686700 loss: 0.0003 lr: 0.002\n",
      "iteration: 686800 loss: 0.0004 lr: 0.002\n",
      "iteration: 686900 loss: 0.0003 lr: 0.002\n",
      "iteration: 687000 loss: 0.0003 lr: 0.002\n",
      "iteration: 687100 loss: 0.0003 lr: 0.002\n",
      "iteration: 687200 loss: 0.0003 lr: 0.002\n",
      "iteration: 687300 loss: 0.0004 lr: 0.002\n",
      "iteration: 687400 loss: 0.0004 lr: 0.002\n",
      "iteration: 687500 loss: 0.0002 lr: 0.002\n",
      "iteration: 687600 loss: 0.0003 lr: 0.002\n",
      "iteration: 687700 loss: 0.0003 lr: 0.002\n",
      "iteration: 687800 loss: 0.0003 lr: 0.002\n",
      "iteration: 687900 loss: 0.0003 lr: 0.002\n",
      "iteration: 688000 loss: 0.0003 lr: 0.002\n",
      "iteration: 688100 loss: 0.0003 lr: 0.002\n",
      "iteration: 688200 loss: 0.0003 lr: 0.002\n",
      "iteration: 688300 loss: 0.0003 lr: 0.002\n",
      "iteration: 688400 loss: 0.0003 lr: 0.002\n",
      "iteration: 688500 loss: 0.0002 lr: 0.002\n",
      "iteration: 688600 loss: 0.0003 lr: 0.002\n",
      "iteration: 688700 loss: 0.0003 lr: 0.002\n",
      "iteration: 688800 loss: 0.0003 lr: 0.002\n",
      "iteration: 688900 loss: 0.0003 lr: 0.002\n",
      "iteration: 689000 loss: 0.0003 lr: 0.002\n",
      "iteration: 689100 loss: 0.0004 lr: 0.002\n",
      "iteration: 689200 loss: 0.0002 lr: 0.002\n",
      "iteration: 689300 loss: 0.0003 lr: 0.002\n",
      "iteration: 689400 loss: 0.0003 lr: 0.002\n",
      "iteration: 689500 loss: 0.0002 lr: 0.002\n",
      "iteration: 689600 loss: 0.0003 lr: 0.002\n",
      "iteration: 689700 loss: 0.0004 lr: 0.002\n",
      "iteration: 689800 loss: 0.0002 lr: 0.002\n",
      "iteration: 689900 loss: 0.0002 lr: 0.002\n",
      "iteration: 690000 loss: 0.0003 lr: 0.002\n",
      "iteration: 690100 loss: 0.0003 lr: 0.002\n",
      "iteration: 690200 loss: 0.0002 lr: 0.002\n",
      "iteration: 690300 loss: 0.0003 lr: 0.002\n",
      "iteration: 690400 loss: 0.0003 lr: 0.002\n",
      "iteration: 690500 loss: 0.0002 lr: 0.002\n",
      "iteration: 690600 loss: 0.0003 lr: 0.002\n",
      "iteration: 690700 loss: 0.0003 lr: 0.002\n",
      "iteration: 690800 loss: 0.0003 lr: 0.002\n",
      "iteration: 690900 loss: 0.0004 lr: 0.002\n",
      "iteration: 691000 loss: 0.0003 lr: 0.002\n",
      "iteration: 691100 loss: 0.0003 lr: 0.002\n",
      "iteration: 691200 loss: 0.0003 lr: 0.002\n",
      "iteration: 691300 loss: 0.0003 lr: 0.002\n",
      "iteration: 691400 loss: 0.0003 lr: 0.002\n",
      "iteration: 691500 loss: 0.0003 lr: 0.002\n",
      "iteration: 691600 loss: 0.0003 lr: 0.002\n",
      "iteration: 691700 loss: 0.0003 lr: 0.002\n",
      "iteration: 691800 loss: 0.0003 lr: 0.002\n",
      "iteration: 691900 loss: 0.0002 lr: 0.002\n",
      "iteration: 692000 loss: 0.0003 lr: 0.002\n",
      "iteration: 692100 loss: 0.0003 lr: 0.002\n",
      "iteration: 692200 loss: 0.0003 lr: 0.002\n",
      "iteration: 692300 loss: 0.0003 lr: 0.002\n",
      "iteration: 692400 loss: 0.0003 lr: 0.002\n",
      "iteration: 692500 loss: 0.0003 lr: 0.002\n",
      "iteration: 692600 loss: 0.0003 lr: 0.002\n",
      "iteration: 692700 loss: 0.0003 lr: 0.002\n",
      "iteration: 692800 loss: 0.0003 lr: 0.002\n",
      "iteration: 692900 loss: 0.0003 lr: 0.002\n",
      "iteration: 693000 loss: 0.0004 lr: 0.002\n",
      "iteration: 693100 loss: 0.0003 lr: 0.002\n",
      "iteration: 693200 loss: 0.0004 lr: 0.002\n",
      "iteration: 693300 loss: 0.0003 lr: 0.002\n",
      "iteration: 693400 loss: 0.0004 lr: 0.002\n",
      "iteration: 693500 loss: 0.0003 lr: 0.002\n",
      "iteration: 693600 loss: 0.0003 lr: 0.002\n",
      "iteration: 693700 loss: 0.0003 lr: 0.002\n",
      "iteration: 693800 loss: 0.0004 lr: 0.002\n",
      "iteration: 693900 loss: 0.0003 lr: 0.002\n",
      "iteration: 694000 loss: 0.0003 lr: 0.002\n",
      "iteration: 694100 loss: 0.0002 lr: 0.002\n",
      "iteration: 694200 loss: 0.0003 lr: 0.002\n",
      "iteration: 694300 loss: 0.0003 lr: 0.002\n",
      "iteration: 694400 loss: 0.0003 lr: 0.002\n",
      "iteration: 694500 loss: 0.0004 lr: 0.002\n",
      "iteration: 694600 loss: 0.0003 lr: 0.002\n",
      "iteration: 694700 loss: 0.0003 lr: 0.002\n",
      "iteration: 694800 loss: 0.0003 lr: 0.002\n",
      "iteration: 694900 loss: 0.0003 lr: 0.002\n",
      "iteration: 695000 loss: 0.0003 lr: 0.002\n",
      "iteration: 695100 loss: 0.0003 lr: 0.002\n",
      "iteration: 695200 loss: 0.0003 lr: 0.002\n",
      "iteration: 695300 loss: 0.0003 lr: 0.002\n",
      "iteration: 695400 loss: 0.0002 lr: 0.002\n",
      "iteration: 695500 loss: 0.0003 lr: 0.002\n",
      "iteration: 695600 loss: 0.0003 lr: 0.002\n",
      "iteration: 695700 loss: 0.0003 lr: 0.002\n",
      "iteration: 695800 loss: 0.0002 lr: 0.002\n",
      "iteration: 695900 loss: 0.0003 lr: 0.002\n",
      "iteration: 696000 loss: 0.0003 lr: 0.002\n",
      "iteration: 696100 loss: 0.0003 lr: 0.002\n",
      "iteration: 696200 loss: 0.0003 lr: 0.002\n",
      "iteration: 696300 loss: 0.0003 lr: 0.002\n",
      "iteration: 696400 loss: 0.0003 lr: 0.002\n",
      "iteration: 696500 loss: 0.0003 lr: 0.002\n",
      "iteration: 696600 loss: 0.0003 lr: 0.002\n",
      "iteration: 696700 loss: 0.0003 lr: 0.002\n",
      "iteration: 696800 loss: 0.0003 lr: 0.002\n",
      "iteration: 696900 loss: 0.0003 lr: 0.002\n",
      "iteration: 697000 loss: 0.0002 lr: 0.002\n",
      "iteration: 697100 loss: 0.0003 lr: 0.002\n",
      "iteration: 697200 loss: 0.0003 lr: 0.002\n",
      "iteration: 697300 loss: 0.0003 lr: 0.002\n",
      "iteration: 697400 loss: 0.0003 lr: 0.002\n",
      "iteration: 697500 loss: 0.0003 lr: 0.002\n",
      "iteration: 697600 loss: 0.0003 lr: 0.002\n",
      "iteration: 697700 loss: 0.0003 lr: 0.002\n",
      "iteration: 697800 loss: 0.0002 lr: 0.002\n",
      "iteration: 697900 loss: 0.0003 lr: 0.002\n",
      "iteration: 698000 loss: 0.0003 lr: 0.002\n",
      "iteration: 698100 loss: 0.0002 lr: 0.002\n",
      "iteration: 698200 loss: 0.0003 lr: 0.002\n",
      "iteration: 698300 loss: 0.0003 lr: 0.002\n",
      "iteration: 698400 loss: 0.0004 lr: 0.002\n",
      "iteration: 698500 loss: 0.0002 lr: 0.002\n",
      "iteration: 698600 loss: 0.0003 lr: 0.002\n",
      "iteration: 698700 loss: 0.0004 lr: 0.002\n",
      "iteration: 698800 loss: 0.0003 lr: 0.002\n",
      "iteration: 698900 loss: 0.0003 lr: 0.002\n",
      "iteration: 699000 loss: 0.0003 lr: 0.002\n",
      "iteration: 699100 loss: 0.0003 lr: 0.002\n",
      "iteration: 699200 loss: 0.0003 lr: 0.002\n",
      "iteration: 699300 loss: 0.0003 lr: 0.002\n",
      "iteration: 699400 loss: 0.0003 lr: 0.002\n",
      "iteration: 699500 loss: 0.0003 lr: 0.002\n",
      "iteration: 699600 loss: 0.0003 lr: 0.002\n",
      "iteration: 699700 loss: 0.0003 lr: 0.002\n",
      "iteration: 699800 loss: 0.0003 lr: 0.002\n",
      "iteration: 699900 loss: 0.0003 lr: 0.002\n",
      "iteration: 700000 loss: 0.0002 lr: 0.002\n",
      "iteration: 700100 loss: 0.0003 lr: 0.002\n",
      "iteration: 700200 loss: 0.0003 lr: 0.002\n",
      "iteration: 700300 loss: 0.0003 lr: 0.002\n",
      "iteration: 700400 loss: 0.0003 lr: 0.002\n",
      "iteration: 700500 loss: 0.0003 lr: 0.002\n",
      "iteration: 700600 loss: 0.0003 lr: 0.002\n",
      "iteration: 700700 loss: 0.0003 lr: 0.002\n",
      "iteration: 700800 loss: 0.0003 lr: 0.002\n",
      "iteration: 700900 loss: 0.0002 lr: 0.002\n",
      "iteration: 701000 loss: 0.0003 lr: 0.002\n",
      "iteration: 701100 loss: 0.0003 lr: 0.002\n",
      "iteration: 701200 loss: 0.0004 lr: 0.002\n",
      "iteration: 701300 loss: 0.0004 lr: 0.002\n",
      "iteration: 701400 loss: 0.0003 lr: 0.002\n",
      "iteration: 701500 loss: 0.0003 lr: 0.002\n",
      "iteration: 701600 loss: 0.0003 lr: 0.002\n",
      "iteration: 701700 loss: 0.0003 lr: 0.002\n",
      "iteration: 701800 loss: 0.0004 lr: 0.002\n",
      "iteration: 701900 loss: 0.0002 lr: 0.002\n",
      "iteration: 702000 loss: 0.0002 lr: 0.002\n",
      "iteration: 702100 loss: 0.0003 lr: 0.002\n",
      "iteration: 702200 loss: 0.0003 lr: 0.002\n",
      "iteration: 702300 loss: 0.0003 lr: 0.002\n",
      "iteration: 702400 loss: 0.0003 lr: 0.002\n",
      "iteration: 702500 loss: 0.0003 lr: 0.002\n",
      "iteration: 702600 loss: 0.0004 lr: 0.002\n",
      "iteration: 702700 loss: 0.0003 lr: 0.002\n",
      "iteration: 702800 loss: 0.0003 lr: 0.002\n",
      "iteration: 702900 loss: 0.0004 lr: 0.002\n",
      "iteration: 703000 loss: 0.0004 lr: 0.002\n",
      "iteration: 703100 loss: 0.0003 lr: 0.002\n",
      "iteration: 703200 loss: 0.0003 lr: 0.002\n",
      "iteration: 703300 loss: 0.0003 lr: 0.002\n",
      "iteration: 703400 loss: 0.0003 lr: 0.002\n",
      "iteration: 703500 loss: 0.0003 lr: 0.002\n",
      "iteration: 703600 loss: 0.0002 lr: 0.002\n",
      "iteration: 703700 loss: 0.0004 lr: 0.002\n",
      "iteration: 703800 loss: 0.0004 lr: 0.002\n",
      "iteration: 703900 loss: 0.0003 lr: 0.002\n",
      "iteration: 704000 loss: 0.0003 lr: 0.002\n",
      "iteration: 704100 loss: 0.0003 lr: 0.002\n",
      "iteration: 704200 loss: 0.0003 lr: 0.002\n",
      "iteration: 704300 loss: 0.0003 lr: 0.002\n",
      "iteration: 704400 loss: 0.0003 lr: 0.002\n",
      "iteration: 704500 loss: 0.0003 lr: 0.002\n",
      "iteration: 704600 loss: 0.0003 lr: 0.002\n",
      "iteration: 704700 loss: 0.0003 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 704800 loss: 0.0003 lr: 0.002\n",
      "iteration: 704900 loss: 0.0003 lr: 0.002\n",
      "iteration: 705000 loss: 0.0003 lr: 0.002\n",
      "iteration: 705100 loss: 0.0002 lr: 0.002\n",
      "iteration: 705200 loss: 0.0004 lr: 0.002\n",
      "iteration: 705300 loss: 0.0004 lr: 0.002\n",
      "iteration: 705400 loss: 0.0005 lr: 0.002\n",
      "iteration: 705500 loss: 0.0003 lr: 0.002\n",
      "iteration: 705600 loss: 0.0003 lr: 0.002\n",
      "iteration: 705700 loss: 0.0003 lr: 0.002\n",
      "iteration: 705800 loss: 0.0003 lr: 0.002\n",
      "iteration: 705900 loss: 0.0003 lr: 0.002\n",
      "iteration: 706000 loss: 0.0003 lr: 0.002\n",
      "iteration: 706100 loss: 0.0003 lr: 0.002\n",
      "iteration: 706200 loss: 0.0003 lr: 0.002\n",
      "iteration: 706300 loss: 0.0003 lr: 0.002\n",
      "iteration: 706400 loss: 0.0003 lr: 0.002\n",
      "iteration: 706500 loss: 0.0003 lr: 0.002\n",
      "iteration: 706600 loss: 0.0003 lr: 0.002\n",
      "iteration: 706700 loss: 0.0003 lr: 0.002\n",
      "iteration: 706800 loss: 0.0004 lr: 0.002\n",
      "iteration: 706900 loss: 0.0003 lr: 0.002\n",
      "iteration: 707000 loss: 0.0003 lr: 0.002\n",
      "iteration: 707100 loss: 0.0003 lr: 0.002\n",
      "iteration: 707200 loss: 0.0003 lr: 0.002\n",
      "iteration: 707300 loss: 0.0002 lr: 0.002\n",
      "iteration: 707400 loss: 0.0003 lr: 0.002\n",
      "iteration: 707500 loss: 0.0003 lr: 0.002\n",
      "iteration: 707600 loss: 0.0004 lr: 0.002\n",
      "iteration: 707700 loss: 0.0003 lr: 0.002\n",
      "iteration: 707800 loss: 0.0004 lr: 0.002\n",
      "iteration: 707900 loss: 0.0003 lr: 0.002\n",
      "iteration: 708000 loss: 0.0004 lr: 0.002\n",
      "iteration: 708100 loss: 0.0003 lr: 0.002\n",
      "iteration: 708200 loss: 0.0003 lr: 0.002\n",
      "iteration: 708300 loss: 0.0003 lr: 0.002\n",
      "iteration: 708400 loss: 0.0003 lr: 0.002\n",
      "iteration: 708500 loss: 0.0003 lr: 0.002\n",
      "iteration: 708600 loss: 0.0003 lr: 0.002\n",
      "iteration: 708700 loss: 0.0003 lr: 0.002\n",
      "iteration: 708800 loss: 0.0003 lr: 0.002\n",
      "iteration: 708900 loss: 0.0003 lr: 0.002\n",
      "iteration: 709000 loss: 0.0003 lr: 0.002\n",
      "iteration: 709100 loss: 0.0003 lr: 0.002\n",
      "iteration: 709200 loss: 0.0003 lr: 0.002\n",
      "iteration: 709300 loss: 0.0004 lr: 0.002\n",
      "iteration: 709400 loss: 0.0003 lr: 0.002\n",
      "iteration: 709500 loss: 0.0002 lr: 0.002\n",
      "iteration: 709600 loss: 0.0003 lr: 0.002\n",
      "iteration: 709700 loss: 0.0003 lr: 0.002\n",
      "iteration: 709800 loss: 0.0002 lr: 0.002\n",
      "iteration: 709900 loss: 0.0002 lr: 0.002\n",
      "iteration: 710000 loss: 0.0003 lr: 0.002\n",
      "iteration: 710100 loss: 0.0003 lr: 0.002\n",
      "iteration: 710200 loss: 0.0004 lr: 0.002\n",
      "iteration: 710300 loss: 0.0003 lr: 0.002\n",
      "iteration: 710400 loss: 0.0003 lr: 0.002\n",
      "iteration: 710500 loss: 0.0003 lr: 0.002\n",
      "iteration: 710600 loss: 0.0003 lr: 0.002\n",
      "iteration: 710700 loss: 0.0004 lr: 0.002\n",
      "iteration: 710800 loss: 0.0003 lr: 0.002\n",
      "iteration: 710900 loss: 0.0003 lr: 0.002\n",
      "iteration: 711000 loss: 0.0002 lr: 0.002\n",
      "iteration: 711100 loss: 0.0003 lr: 0.002\n",
      "iteration: 711200 loss: 0.0003 lr: 0.002\n",
      "iteration: 711300 loss: 0.0003 lr: 0.002\n",
      "iteration: 711400 loss: 0.0003 lr: 0.002\n",
      "iteration: 711500 loss: 0.0003 lr: 0.002\n",
      "iteration: 711600 loss: 0.0004 lr: 0.002\n",
      "iteration: 711700 loss: 0.0003 lr: 0.002\n",
      "iteration: 711800 loss: 0.0002 lr: 0.002\n",
      "iteration: 711900 loss: 0.0003 lr: 0.002\n",
      "iteration: 712000 loss: 0.0003 lr: 0.002\n",
      "iteration: 712100 loss: 0.0004 lr: 0.002\n",
      "iteration: 712200 loss: 0.0004 lr: 0.002\n",
      "iteration: 712300 loss: 0.0003 lr: 0.002\n",
      "iteration: 712400 loss: 0.0002 lr: 0.002\n",
      "iteration: 712500 loss: 0.0003 lr: 0.002\n",
      "iteration: 712600 loss: 0.0003 lr: 0.002\n",
      "iteration: 712700 loss: 0.0003 lr: 0.002\n",
      "iteration: 712800 loss: 0.0002 lr: 0.002\n",
      "iteration: 712900 loss: 0.0003 lr: 0.002\n",
      "iteration: 713000 loss: 0.0003 lr: 0.002\n",
      "iteration: 713100 loss: 0.0004 lr: 0.002\n",
      "iteration: 713200 loss: 0.0004 lr: 0.002\n",
      "iteration: 713300 loss: 0.0003 lr: 0.002\n",
      "iteration: 713400 loss: 0.0003 lr: 0.002\n",
      "iteration: 713500 loss: 0.0003 lr: 0.002\n",
      "iteration: 713600 loss: 0.0003 lr: 0.002\n",
      "iteration: 713700 loss: 0.0004 lr: 0.002\n",
      "iteration: 713800 loss: 0.0002 lr: 0.002\n",
      "iteration: 713900 loss: 0.0003 lr: 0.002\n",
      "iteration: 714000 loss: 0.0003 lr: 0.002\n",
      "iteration: 714100 loss: 0.0003 lr: 0.002\n",
      "iteration: 714200 loss: 0.0003 lr: 0.002\n",
      "iteration: 714300 loss: 0.0003 lr: 0.002\n",
      "iteration: 714400 loss: 0.0003 lr: 0.002\n",
      "iteration: 714500 loss: 0.0003 lr: 0.002\n",
      "iteration: 714600 loss: 0.0003 lr: 0.002\n",
      "iteration: 714700 loss: 0.0003 lr: 0.002\n",
      "iteration: 714800 loss: 0.0003 lr: 0.002\n",
      "iteration: 714900 loss: 0.0003 lr: 0.002\n",
      "iteration: 715000 loss: 0.0003 lr: 0.002\n",
      "iteration: 715100 loss: 0.0002 lr: 0.002\n",
      "iteration: 715200 loss: 0.0003 lr: 0.002\n",
      "iteration: 715300 loss: 0.0004 lr: 0.002\n",
      "iteration: 715400 loss: 0.0003 lr: 0.002\n",
      "iteration: 715500 loss: 0.0003 lr: 0.002\n",
      "iteration: 715600 loss: 0.0002 lr: 0.002\n",
      "iteration: 715700 loss: 0.0004 lr: 0.002\n",
      "iteration: 715800 loss: 0.0003 lr: 0.002\n",
      "iteration: 715900 loss: 0.0003 lr: 0.002\n",
      "iteration: 716000 loss: 0.0003 lr: 0.002\n",
      "iteration: 716100 loss: 0.0003 lr: 0.002\n",
      "iteration: 716200 loss: 0.0003 lr: 0.002\n",
      "iteration: 716300 loss: 0.0002 lr: 0.002\n",
      "iteration: 716400 loss: 0.0003 lr: 0.002\n",
      "iteration: 716500 loss: 0.0003 lr: 0.002\n",
      "iteration: 716600 loss: 0.0002 lr: 0.002\n",
      "iteration: 716700 loss: 0.0004 lr: 0.002\n",
      "iteration: 716800 loss: 0.0003 lr: 0.002\n",
      "iteration: 716900 loss: 0.0003 lr: 0.002\n",
      "iteration: 717000 loss: 0.0003 lr: 0.002\n",
      "iteration: 717100 loss: 0.0003 lr: 0.002\n",
      "iteration: 717200 loss: 0.0003 lr: 0.002\n",
      "iteration: 717300 loss: 0.0003 lr: 0.002\n",
      "iteration: 717400 loss: 0.0003 lr: 0.002\n",
      "iteration: 717500 loss: 0.0003 lr: 0.002\n",
      "iteration: 717600 loss: 0.0003 lr: 0.002\n",
      "iteration: 717700 loss: 0.0002 lr: 0.002\n",
      "iteration: 717800 loss: 0.0003 lr: 0.002\n",
      "iteration: 717900 loss: 0.0003 lr: 0.002\n",
      "iteration: 718000 loss: 0.0003 lr: 0.002\n",
      "iteration: 718100 loss: 0.0003 lr: 0.002\n",
      "iteration: 718200 loss: 0.0003 lr: 0.002\n",
      "iteration: 718300 loss: 0.0003 lr: 0.002\n",
      "iteration: 718400 loss: 0.0004 lr: 0.002\n",
      "iteration: 718500 loss: 0.0004 lr: 0.002\n",
      "iteration: 718600 loss: 0.0003 lr: 0.002\n",
      "iteration: 718700 loss: 0.0003 lr: 0.002\n",
      "iteration: 718800 loss: 0.0003 lr: 0.002\n",
      "iteration: 718900 loss: 0.0003 lr: 0.002\n",
      "iteration: 719000 loss: 0.0003 lr: 0.002\n",
      "iteration: 719100 loss: 0.0003 lr: 0.002\n",
      "iteration: 719200 loss: 0.0004 lr: 0.002\n",
      "iteration: 719300 loss: 0.0003 lr: 0.002\n",
      "iteration: 719400 loss: 0.0003 lr: 0.002\n",
      "iteration: 719500 loss: 0.0004 lr: 0.002\n",
      "iteration: 719600 loss: 0.0002 lr: 0.002\n",
      "iteration: 719700 loss: 0.0003 lr: 0.002\n",
      "iteration: 719800 loss: 0.0002 lr: 0.002\n",
      "iteration: 719900 loss: 0.0003 lr: 0.002\n",
      "iteration: 720000 loss: 0.0003 lr: 0.002\n",
      "iteration: 720100 loss: 0.0003 lr: 0.002\n",
      "iteration: 720200 loss: 0.0003 lr: 0.002\n",
      "iteration: 720300 loss: 0.0003 lr: 0.002\n",
      "iteration: 720400 loss: 0.0003 lr: 0.002\n",
      "iteration: 720500 loss: 0.0004 lr: 0.002\n",
      "iteration: 720600 loss: 0.0004 lr: 0.002\n",
      "iteration: 720700 loss: 0.0003 lr: 0.002\n",
      "iteration: 720800 loss: 0.0003 lr: 0.002\n",
      "iteration: 720900 loss: 0.0003 lr: 0.002\n",
      "iteration: 721000 loss: 0.0004 lr: 0.002\n",
      "iteration: 721100 loss: 0.0003 lr: 0.002\n",
      "iteration: 721200 loss: 0.0002 lr: 0.002\n",
      "iteration: 721300 loss: 0.0003 lr: 0.002\n",
      "iteration: 721400 loss: 0.0003 lr: 0.002\n",
      "iteration: 721500 loss: 0.0003 lr: 0.002\n",
      "iteration: 721600 loss: 0.0003 lr: 0.002\n",
      "iteration: 721700 loss: 0.0003 lr: 0.002\n",
      "iteration: 721800 loss: 0.0002 lr: 0.002\n",
      "iteration: 721900 loss: 0.0003 lr: 0.002\n",
      "iteration: 722000 loss: 0.0003 lr: 0.002\n",
      "iteration: 722100 loss: 0.0002 lr: 0.002\n",
      "iteration: 722200 loss: 0.0004 lr: 0.002\n",
      "iteration: 722300 loss: 0.0003 lr: 0.002\n",
      "iteration: 722400 loss: 0.0003 lr: 0.002\n",
      "iteration: 722500 loss: 0.0002 lr: 0.002\n",
      "iteration: 722600 loss: 0.0003 lr: 0.002\n",
      "iteration: 722700 loss: 0.0003 lr: 0.002\n",
      "iteration: 722800 loss: 0.0003 lr: 0.002\n",
      "iteration: 722900 loss: 0.0003 lr: 0.002\n",
      "iteration: 723000 loss: 0.0003 lr: 0.002\n",
      "iteration: 723100 loss: 0.0004 lr: 0.002\n",
      "iteration: 723200 loss: 0.0003 lr: 0.002\n",
      "iteration: 723300 loss: 0.0003 lr: 0.002\n",
      "iteration: 723400 loss: 0.0003 lr: 0.002\n",
      "iteration: 723500 loss: 0.0003 lr: 0.002\n",
      "iteration: 723600 loss: 0.0003 lr: 0.002\n",
      "iteration: 723700 loss: 0.0003 lr: 0.002\n",
      "iteration: 723800 loss: 0.0003 lr: 0.002\n",
      "iteration: 723900 loss: 0.0002 lr: 0.002\n",
      "iteration: 724000 loss: 0.0003 lr: 0.002\n",
      "iteration: 724100 loss: 0.0003 lr: 0.002\n",
      "iteration: 724200 loss: 0.0003 lr: 0.002\n",
      "iteration: 724300 loss: 0.0003 lr: 0.002\n",
      "iteration: 724400 loss: 0.0003 lr: 0.002\n",
      "iteration: 724500 loss: 0.0003 lr: 0.002\n",
      "iteration: 724600 loss: 0.0003 lr: 0.002\n",
      "iteration: 724700 loss: 0.0003 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 724800 loss: 0.0003 lr: 0.002\n",
      "iteration: 724900 loss: 0.0003 lr: 0.002\n",
      "iteration: 725000 loss: 0.0003 lr: 0.002\n",
      "iteration: 725100 loss: 0.0003 lr: 0.002\n",
      "iteration: 725200 loss: 0.0002 lr: 0.002\n",
      "iteration: 725300 loss: 0.0004 lr: 0.002\n",
      "iteration: 725400 loss: 0.0003 lr: 0.002\n",
      "iteration: 725500 loss: 0.0003 lr: 0.002\n",
      "iteration: 725600 loss: 0.0003 lr: 0.002\n",
      "iteration: 725700 loss: 0.0002 lr: 0.002\n",
      "iteration: 725800 loss: 0.0003 lr: 0.002\n",
      "iteration: 725900 loss: 0.0003 lr: 0.002\n",
      "iteration: 726000 loss: 0.0003 lr: 0.002\n",
      "iteration: 726100 loss: 0.0004 lr: 0.002\n",
      "iteration: 726200 loss: 0.0004 lr: 0.002\n",
      "iteration: 726300 loss: 0.0003 lr: 0.002\n",
      "iteration: 726400 loss: 0.0002 lr: 0.002\n",
      "iteration: 726500 loss: 0.0003 lr: 0.002\n",
      "iteration: 726600 loss: 0.0003 lr: 0.002\n",
      "iteration: 726700 loss: 0.0003 lr: 0.002\n",
      "iteration: 726800 loss: 0.0003 lr: 0.002\n",
      "iteration: 726900 loss: 0.0003 lr: 0.002\n",
      "iteration: 727000 loss: 0.0003 lr: 0.002\n",
      "iteration: 727100 loss: 0.0003 lr: 0.002\n",
      "iteration: 727200 loss: 0.0003 lr: 0.002\n",
      "iteration: 727300 loss: 0.0003 lr: 0.002\n",
      "iteration: 727400 loss: 0.0002 lr: 0.002\n",
      "iteration: 727500 loss: 0.0003 lr: 0.002\n",
      "iteration: 727600 loss: 0.0003 lr: 0.002\n",
      "iteration: 727700 loss: 0.0004 lr: 0.002\n",
      "iteration: 727800 loss: 0.0004 lr: 0.002\n",
      "iteration: 727900 loss: 0.0003 lr: 0.002\n",
      "iteration: 728000 loss: 0.0003 lr: 0.002\n",
      "iteration: 728100 loss: 0.0003 lr: 0.002\n",
      "iteration: 728200 loss: 0.0003 lr: 0.002\n",
      "iteration: 728300 loss: 0.0003 lr: 0.002\n",
      "iteration: 728400 loss: 0.0003 lr: 0.002\n",
      "iteration: 728500 loss: 0.0003 lr: 0.002\n",
      "iteration: 728600 loss: 0.0003 lr: 0.002\n",
      "iteration: 728700 loss: 0.0003 lr: 0.002\n",
      "iteration: 728800 loss: 0.0002 lr: 0.002\n",
      "iteration: 728900 loss: 0.0003 lr: 0.002\n",
      "iteration: 729000 loss: 0.0003 lr: 0.002\n",
      "iteration: 729100 loss: 0.0002 lr: 0.002\n",
      "iteration: 729200 loss: 0.0004 lr: 0.002\n",
      "iteration: 729300 loss: 0.0003 lr: 0.002\n",
      "iteration: 729400 loss: 0.0003 lr: 0.002\n",
      "iteration: 729500 loss: 0.0003 lr: 0.002\n",
      "iteration: 729600 loss: 0.0003 lr: 0.002\n",
      "iteration: 729700 loss: 0.0004 lr: 0.002\n",
      "iteration: 729800 loss: 0.0003 lr: 0.002\n",
      "iteration: 729900 loss: 0.0003 lr: 0.002\n",
      "iteration: 730000 loss: 0.0002 lr: 0.002\n",
      "iteration: 730100 loss: 0.0003 lr: 0.001\n",
      "iteration: 730200 loss: 0.0003 lr: 0.001\n",
      "iteration: 730300 loss: 0.0003 lr: 0.001\n",
      "iteration: 730400 loss: 0.0003 lr: 0.001\n",
      "iteration: 730500 loss: 0.0002 lr: 0.001\n",
      "iteration: 730600 loss: 0.0003 lr: 0.001\n",
      "iteration: 730700 loss: 0.0003 lr: 0.001\n",
      "iteration: 730800 loss: 0.0003 lr: 0.001\n",
      "iteration: 730900 loss: 0.0003 lr: 0.001\n",
      "iteration: 731000 loss: 0.0003 lr: 0.001\n",
      "iteration: 731100 loss: 0.0003 lr: 0.001\n",
      "iteration: 731200 loss: 0.0003 lr: 0.001\n",
      "iteration: 731300 loss: 0.0002 lr: 0.001\n",
      "iteration: 731400 loss: 0.0003 lr: 0.001\n",
      "iteration: 731500 loss: 0.0004 lr: 0.001\n",
      "iteration: 731600 loss: 0.0003 lr: 0.001\n",
      "iteration: 731700 loss: 0.0003 lr: 0.001\n",
      "iteration: 731800 loss: 0.0003 lr: 0.001\n",
      "iteration: 731900 loss: 0.0003 lr: 0.001\n",
      "iteration: 732000 loss: 0.0003 lr: 0.001\n",
      "iteration: 732100 loss: 0.0003 lr: 0.001\n",
      "iteration: 732200 loss: 0.0003 lr: 0.001\n",
      "iteration: 732300 loss: 0.0003 lr: 0.001\n",
      "iteration: 732400 loss: 0.0002 lr: 0.001\n",
      "iteration: 732500 loss: 0.0003 lr: 0.001\n",
      "iteration: 732600 loss: 0.0003 lr: 0.001\n",
      "iteration: 732700 loss: 0.0003 lr: 0.001\n",
      "iteration: 732800 loss: 0.0003 lr: 0.001\n",
      "iteration: 732900 loss: 0.0002 lr: 0.001\n",
      "iteration: 733000 loss: 0.0003 lr: 0.001\n",
      "iteration: 733100 loss: 0.0003 lr: 0.001\n",
      "iteration: 733200 loss: 0.0003 lr: 0.001\n",
      "iteration: 733300 loss: 0.0003 lr: 0.001\n",
      "iteration: 733400 loss: 0.0003 lr: 0.001\n",
      "iteration: 733500 loss: 0.0003 lr: 0.001\n",
      "iteration: 733600 loss: 0.0003 lr: 0.001\n",
      "iteration: 733700 loss: 0.0003 lr: 0.001\n",
      "iteration: 733800 loss: 0.0003 lr: 0.001\n",
      "iteration: 733900 loss: 0.0004 lr: 0.001\n",
      "iteration: 734000 loss: 0.0003 lr: 0.001\n",
      "iteration: 734100 loss: 0.0004 lr: 0.001\n",
      "iteration: 734200 loss: 0.0003 lr: 0.001\n",
      "iteration: 734300 loss: 0.0003 lr: 0.001\n",
      "iteration: 734400 loss: 0.0003 lr: 0.001\n",
      "iteration: 734500 loss: 0.0003 lr: 0.001\n",
      "iteration: 734600 loss: 0.0003 lr: 0.001\n",
      "iteration: 734700 loss: 0.0002 lr: 0.001\n",
      "iteration: 734800 loss: 0.0003 lr: 0.001\n",
      "iteration: 734900 loss: 0.0003 lr: 0.001\n",
      "iteration: 735000 loss: 0.0002 lr: 0.001\n",
      "iteration: 735100 loss: 0.0003 lr: 0.001\n",
      "iteration: 735200 loss: 0.0003 lr: 0.001\n",
      "iteration: 735300 loss: 0.0003 lr: 0.001\n",
      "iteration: 735400 loss: 0.0003 lr: 0.001\n",
      "iteration: 735500 loss: 0.0002 lr: 0.001\n",
      "iteration: 735600 loss: 0.0003 lr: 0.001\n",
      "iteration: 735700 loss: 0.0003 lr: 0.001\n",
      "iteration: 735800 loss: 0.0003 lr: 0.001\n",
      "iteration: 735900 loss: 0.0004 lr: 0.001\n",
      "iteration: 736000 loss: 0.0003 lr: 0.001\n",
      "iteration: 736100 loss: 0.0003 lr: 0.001\n",
      "iteration: 736200 loss: 0.0003 lr: 0.001\n",
      "iteration: 736300 loss: 0.0003 lr: 0.001\n",
      "iteration: 736400 loss: 0.0003 lr: 0.001\n",
      "iteration: 736500 loss: 0.0002 lr: 0.001\n",
      "iteration: 736600 loss: 0.0002 lr: 0.001\n",
      "iteration: 736700 loss: 0.0003 lr: 0.001\n",
      "iteration: 736800 loss: 0.0003 lr: 0.001\n",
      "iteration: 736900 loss: 0.0002 lr: 0.001\n",
      "iteration: 737000 loss: 0.0002 lr: 0.001\n",
      "iteration: 737100 loss: 0.0003 lr: 0.001\n",
      "iteration: 737200 loss: 0.0003 lr: 0.001\n",
      "iteration: 737300 loss: 0.0002 lr: 0.001\n",
      "iteration: 737400 loss: 0.0003 lr: 0.001\n",
      "iteration: 737500 loss: 0.0002 lr: 0.001\n",
      "iteration: 737600 loss: 0.0002 lr: 0.001\n",
      "iteration: 737700 loss: 0.0002 lr: 0.001\n",
      "iteration: 737800 loss: 0.0003 lr: 0.001\n",
      "iteration: 737900 loss: 0.0003 lr: 0.001\n",
      "iteration: 738000 loss: 0.0003 lr: 0.001\n",
      "iteration: 738100 loss: 0.0003 lr: 0.001\n",
      "iteration: 738200 loss: 0.0003 lr: 0.001\n",
      "iteration: 738300 loss: 0.0003 lr: 0.001\n",
      "iteration: 738400 loss: 0.0002 lr: 0.001\n",
      "iteration: 738500 loss: 0.0002 lr: 0.001\n",
      "iteration: 738600 loss: 0.0004 lr: 0.001\n",
      "iteration: 738700 loss: 0.0003 lr: 0.001\n",
      "iteration: 738800 loss: 0.0003 lr: 0.001\n",
      "iteration: 738900 loss: 0.0003 lr: 0.001\n",
      "iteration: 739000 loss: 0.0002 lr: 0.001\n",
      "iteration: 739100 loss: 0.0003 lr: 0.001\n",
      "iteration: 739200 loss: 0.0003 lr: 0.001\n",
      "iteration: 739300 loss: 0.0003 lr: 0.001\n",
      "iteration: 739400 loss: 0.0003 lr: 0.001\n",
      "iteration: 739500 loss: 0.0002 lr: 0.001\n",
      "iteration: 739600 loss: 0.0003 lr: 0.001\n",
      "iteration: 739700 loss: 0.0003 lr: 0.001\n",
      "iteration: 739800 loss: 0.0003 lr: 0.001\n",
      "iteration: 739900 loss: 0.0003 lr: 0.001\n",
      "iteration: 740000 loss: 0.0003 lr: 0.001\n",
      "iteration: 740100 loss: 0.0003 lr: 0.001\n",
      "iteration: 740200 loss: 0.0002 lr: 0.001\n",
      "iteration: 740300 loss: 0.0003 lr: 0.001\n",
      "iteration: 740400 loss: 0.0003 lr: 0.001\n",
      "iteration: 740500 loss: 0.0003 lr: 0.001\n",
      "iteration: 740600 loss: 0.0003 lr: 0.001\n",
      "iteration: 740700 loss: 0.0003 lr: 0.001\n",
      "iteration: 740800 loss: 0.0003 lr: 0.001\n",
      "iteration: 740900 loss: 0.0003 lr: 0.001\n",
      "iteration: 741000 loss: 0.0003 lr: 0.001\n",
      "iteration: 741100 loss: 0.0002 lr: 0.001\n",
      "iteration: 741200 loss: 0.0003 lr: 0.001\n",
      "iteration: 741300 loss: 0.0003 lr: 0.001\n",
      "iteration: 741400 loss: 0.0003 lr: 0.001\n",
      "iteration: 741500 loss: 0.0003 lr: 0.001\n",
      "iteration: 741600 loss: 0.0003 lr: 0.001\n",
      "iteration: 741700 loss: 0.0002 lr: 0.001\n",
      "iteration: 741800 loss: 0.0003 lr: 0.001\n",
      "iteration: 741900 loss: 0.0003 lr: 0.001\n",
      "iteration: 742000 loss: 0.0003 lr: 0.001\n",
      "iteration: 742100 loss: 0.0003 lr: 0.001\n",
      "iteration: 742200 loss: 0.0003 lr: 0.001\n",
      "iteration: 742300 loss: 0.0003 lr: 0.001\n",
      "iteration: 742400 loss: 0.0002 lr: 0.001\n",
      "iteration: 742500 loss: 0.0003 lr: 0.001\n",
      "iteration: 742600 loss: 0.0003 lr: 0.001\n",
      "iteration: 742700 loss: 0.0002 lr: 0.001\n",
      "iteration: 742800 loss: 0.0003 lr: 0.001\n",
      "iteration: 742900 loss: 0.0003 lr: 0.001\n",
      "iteration: 743000 loss: 0.0003 lr: 0.001\n",
      "iteration: 743100 loss: 0.0002 lr: 0.001\n",
      "iteration: 743200 loss: 0.0003 lr: 0.001\n",
      "iteration: 743300 loss: 0.0003 lr: 0.001\n",
      "iteration: 743400 loss: 0.0002 lr: 0.001\n",
      "iteration: 743500 loss: 0.0002 lr: 0.001\n",
      "iteration: 743600 loss: 0.0002 lr: 0.001\n",
      "iteration: 743700 loss: 0.0003 lr: 0.001\n",
      "iteration: 743800 loss: 0.0003 lr: 0.001\n",
      "iteration: 743900 loss: 0.0002 lr: 0.001\n",
      "iteration: 744000 loss: 0.0004 lr: 0.001\n",
      "iteration: 744100 loss: 0.0002 lr: 0.001\n",
      "iteration: 744200 loss: 0.0004 lr: 0.001\n",
      "iteration: 744300 loss: 0.0003 lr: 0.001\n",
      "iteration: 744400 loss: 0.0003 lr: 0.001\n",
      "iteration: 744500 loss: 0.0003 lr: 0.001\n",
      "iteration: 744600 loss: 0.0003 lr: 0.001\n",
      "iteration: 744700 loss: 0.0003 lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 744800 loss: 0.0003 lr: 0.001\n",
      "iteration: 744900 loss: 0.0003 lr: 0.001\n",
      "iteration: 745000 loss: 0.0003 lr: 0.001\n",
      "iteration: 745100 loss: 0.0003 lr: 0.001\n",
      "iteration: 745200 loss: 0.0002 lr: 0.001\n",
      "iteration: 745300 loss: 0.0003 lr: 0.001\n",
      "iteration: 745400 loss: 0.0003 lr: 0.001\n",
      "iteration: 745500 loss: 0.0003 lr: 0.001\n",
      "iteration: 745600 loss: 0.0002 lr: 0.001\n",
      "iteration: 745700 loss: 0.0003 lr: 0.001\n",
      "iteration: 745800 loss: 0.0003 lr: 0.001\n",
      "iteration: 745900 loss: 0.0003 lr: 0.001\n",
      "iteration: 746000 loss: 0.0002 lr: 0.001\n",
      "iteration: 746100 loss: 0.0003 lr: 0.001\n",
      "iteration: 746200 loss: 0.0003 lr: 0.001\n",
      "iteration: 746300 loss: 0.0002 lr: 0.001\n",
      "iteration: 746400 loss: 0.0003 lr: 0.001\n",
      "iteration: 746500 loss: 0.0003 lr: 0.001\n",
      "iteration: 746600 loss: 0.0004 lr: 0.001\n",
      "iteration: 746700 loss: 0.0002 lr: 0.001\n",
      "iteration: 746800 loss: 0.0003 lr: 0.001\n",
      "iteration: 746900 loss: 0.0003 lr: 0.001\n",
      "iteration: 747000 loss: 0.0003 lr: 0.001\n",
      "iteration: 747100 loss: 0.0003 lr: 0.001\n",
      "iteration: 747200 loss: 0.0003 lr: 0.001\n",
      "iteration: 747300 loss: 0.0003 lr: 0.001\n",
      "iteration: 747400 loss: 0.0003 lr: 0.001\n",
      "iteration: 747500 loss: 0.0003 lr: 0.001\n",
      "iteration: 747600 loss: 0.0004 lr: 0.001\n",
      "iteration: 747700 loss: 0.0003 lr: 0.001\n",
      "iteration: 747800 loss: 0.0003 lr: 0.001\n",
      "iteration: 747900 loss: 0.0003 lr: 0.001\n",
      "iteration: 748000 loss: 0.0003 lr: 0.001\n",
      "iteration: 748100 loss: 0.0003 lr: 0.001\n",
      "iteration: 748200 loss: 0.0002 lr: 0.001\n",
      "iteration: 748300 loss: 0.0003 lr: 0.001\n",
      "iteration: 748400 loss: 0.0004 lr: 0.001\n",
      "iteration: 748500 loss: 0.0003 lr: 0.001\n",
      "iteration: 748600 loss: 0.0003 lr: 0.001\n",
      "iteration: 748700 loss: 0.0002 lr: 0.001\n",
      "iteration: 748800 loss: 0.0003 lr: 0.001\n",
      "iteration: 748900 loss: 0.0003 lr: 0.001\n",
      "iteration: 749000 loss: 0.0002 lr: 0.001\n",
      "iteration: 749100 loss: 0.0003 lr: 0.001\n",
      "iteration: 749200 loss: 0.0003 lr: 0.001\n",
      "iteration: 749300 loss: 0.0003 lr: 0.001\n",
      "iteration: 749400 loss: 0.0003 lr: 0.001\n",
      "iteration: 749500 loss: 0.0003 lr: 0.001\n",
      "iteration: 749600 loss: 0.0002 lr: 0.001\n",
      "iteration: 749700 loss: 0.0003 lr: 0.001\n",
      "iteration: 749800 loss: 0.0003 lr: 0.001\n",
      "iteration: 749900 loss: 0.0003 lr: 0.001\n",
      "iteration: 750000 loss: 0.0003 lr: 0.001\n",
      "iteration: 750100 loss: 0.0003 lr: 0.001\n",
      "iteration: 750200 loss: 0.0002 lr: 0.001\n",
      "iteration: 750300 loss: 0.0003 lr: 0.001\n",
      "iteration: 750400 loss: 0.0002 lr: 0.001\n",
      "iteration: 750500 loss: 0.0003 lr: 0.001\n",
      "iteration: 750600 loss: 0.0002 lr: 0.001\n",
      "iteration: 750700 loss: 0.0003 lr: 0.001\n",
      "iteration: 750800 loss: 0.0003 lr: 0.001\n",
      "iteration: 750900 loss: 0.0002 lr: 0.001\n",
      "iteration: 751000 loss: 0.0003 lr: 0.001\n",
      "iteration: 751100 loss: 0.0003 lr: 0.001\n",
      "iteration: 751200 loss: 0.0003 lr: 0.001\n",
      "iteration: 751300 loss: 0.0002 lr: 0.001\n",
      "iteration: 751400 loss: 0.0002 lr: 0.001\n",
      "iteration: 751500 loss: 0.0003 lr: 0.001\n",
      "iteration: 751600 loss: 0.0003 lr: 0.001\n",
      "iteration: 751700 loss: 0.0003 lr: 0.001\n",
      "iteration: 751800 loss: 0.0002 lr: 0.001\n",
      "iteration: 751900 loss: 0.0003 lr: 0.001\n",
      "iteration: 752000 loss: 0.0003 lr: 0.001\n",
      "iteration: 752100 loss: 0.0003 lr: 0.001\n",
      "iteration: 752200 loss: 0.0002 lr: 0.001\n",
      "iteration: 752300 loss: 0.0002 lr: 0.001\n",
      "iteration: 752400 loss: 0.0003 lr: 0.001\n",
      "iteration: 752500 loss: 0.0003 lr: 0.001\n",
      "iteration: 752600 loss: 0.0002 lr: 0.001\n",
      "iteration: 752700 loss: 0.0002 lr: 0.001\n",
      "iteration: 752800 loss: 0.0003 lr: 0.001\n",
      "iteration: 752900 loss: 0.0002 lr: 0.001\n",
      "iteration: 753000 loss: 0.0004 lr: 0.001\n",
      "iteration: 753100 loss: 0.0004 lr: 0.001\n",
      "iteration: 753200 loss: 0.0002 lr: 0.001\n",
      "iteration: 753300 loss: 0.0003 lr: 0.001\n",
      "iteration: 753400 loss: 0.0004 lr: 0.001\n",
      "iteration: 753500 loss: 0.0003 lr: 0.001\n",
      "iteration: 753600 loss: 0.0003 lr: 0.001\n",
      "iteration: 753700 loss: 0.0003 lr: 0.001\n",
      "iteration: 753800 loss: 0.0003 lr: 0.001\n",
      "iteration: 753900 loss: 0.0003 lr: 0.001\n",
      "iteration: 754000 loss: 0.0002 lr: 0.001\n",
      "iteration: 754100 loss: 0.0003 lr: 0.001\n",
      "iteration: 754200 loss: 0.0003 lr: 0.001\n",
      "iteration: 754300 loss: 0.0003 lr: 0.001\n",
      "iteration: 754400 loss: 0.0002 lr: 0.001\n",
      "iteration: 754500 loss: 0.0003 lr: 0.001\n",
      "iteration: 754600 loss: 0.0003 lr: 0.001\n",
      "iteration: 754700 loss: 0.0004 lr: 0.001\n",
      "iteration: 754800 loss: 0.0002 lr: 0.001\n",
      "iteration: 754900 loss: 0.0003 lr: 0.001\n",
      "iteration: 755000 loss: 0.0003 lr: 0.001\n",
      "iteration: 755100 loss: 0.0003 lr: 0.001\n",
      "iteration: 755200 loss: 0.0002 lr: 0.001\n",
      "iteration: 755300 loss: 0.0002 lr: 0.001\n",
      "iteration: 755400 loss: 0.0003 lr: 0.001\n",
      "iteration: 755500 loss: 0.0003 lr: 0.001\n",
      "iteration: 755600 loss: 0.0003 lr: 0.001\n",
      "iteration: 755700 loss: 0.0003 lr: 0.001\n",
      "iteration: 755800 loss: 0.0003 lr: 0.001\n",
      "iteration: 755900 loss: 0.0003 lr: 0.001\n",
      "iteration: 756000 loss: 0.0003 lr: 0.001\n",
      "iteration: 756100 loss: 0.0002 lr: 0.001\n",
      "iteration: 756200 loss: 0.0002 lr: 0.001\n",
      "iteration: 756300 loss: 0.0002 lr: 0.001\n",
      "iteration: 756400 loss: 0.0003 lr: 0.001\n",
      "iteration: 756500 loss: 0.0003 lr: 0.001\n",
      "iteration: 756600 loss: 0.0004 lr: 0.001\n",
      "iteration: 756700 loss: 0.0003 lr: 0.001\n",
      "iteration: 756800 loss: 0.0002 lr: 0.001\n",
      "iteration: 756900 loss: 0.0002 lr: 0.001\n",
      "iteration: 757000 loss: 0.0003 lr: 0.001\n",
      "iteration: 757100 loss: 0.0002 lr: 0.001\n",
      "iteration: 757200 loss: 0.0004 lr: 0.001\n",
      "iteration: 757300 loss: 0.0002 lr: 0.001\n",
      "iteration: 757400 loss: 0.0003 lr: 0.001\n",
      "iteration: 757500 loss: 0.0003 lr: 0.001\n",
      "iteration: 757600 loss: 0.0003 lr: 0.001\n",
      "iteration: 757700 loss: 0.0003 lr: 0.001\n",
      "iteration: 757800 loss: 0.0003 lr: 0.001\n",
      "iteration: 757900 loss: 0.0003 lr: 0.001\n",
      "iteration: 758000 loss: 0.0002 lr: 0.001\n",
      "iteration: 758100 loss: 0.0003 lr: 0.001\n",
      "iteration: 758200 loss: 0.0003 lr: 0.001\n",
      "iteration: 758300 loss: 0.0002 lr: 0.001\n",
      "iteration: 758400 loss: 0.0003 lr: 0.001\n",
      "iteration: 758500 loss: 0.0002 lr: 0.001\n",
      "iteration: 758600 loss: 0.0004 lr: 0.001\n",
      "iteration: 758700 loss: 0.0003 lr: 0.001\n",
      "iteration: 758800 loss: 0.0003 lr: 0.001\n",
      "iteration: 758900 loss: 0.0003 lr: 0.001\n",
      "iteration: 759000 loss: 0.0003 lr: 0.001\n",
      "iteration: 759100 loss: 0.0002 lr: 0.001\n",
      "iteration: 759200 loss: 0.0003 lr: 0.001\n",
      "iteration: 759300 loss: 0.0003 lr: 0.001\n",
      "iteration: 759400 loss: 0.0003 lr: 0.001\n",
      "iteration: 759500 loss: 0.0003 lr: 0.001\n",
      "iteration: 759600 loss: 0.0003 lr: 0.001\n",
      "iteration: 759700 loss: 0.0003 lr: 0.001\n",
      "iteration: 759800 loss: 0.0004 lr: 0.001\n",
      "iteration: 759900 loss: 0.0002 lr: 0.001\n",
      "iteration: 760000 loss: 0.0002 lr: 0.001\n",
      "iteration: 760100 loss: 0.0003 lr: 0.001\n",
      "iteration: 760200 loss: 0.0002 lr: 0.001\n",
      "iteration: 760300 loss: 0.0003 lr: 0.001\n",
      "iteration: 760400 loss: 0.0003 lr: 0.001\n",
      "iteration: 760500 loss: 0.0002 lr: 0.001\n",
      "iteration: 760600 loss: 0.0003 lr: 0.001\n",
      "iteration: 760700 loss: 0.0003 lr: 0.001\n",
      "iteration: 760800 loss: 0.0003 lr: 0.001\n",
      "iteration: 760900 loss: 0.0004 lr: 0.001\n",
      "iteration: 761000 loss: 0.0003 lr: 0.001\n",
      "iteration: 761100 loss: 0.0002 lr: 0.001\n",
      "iteration: 761200 loss: 0.0004 lr: 0.001\n",
      "iteration: 761300 loss: 0.0003 lr: 0.001\n",
      "iteration: 761400 loss: 0.0003 lr: 0.001\n",
      "iteration: 761500 loss: 0.0003 lr: 0.001\n",
      "iteration: 761600 loss: 0.0002 lr: 0.001\n",
      "iteration: 761700 loss: 0.0002 lr: 0.001\n",
      "iteration: 761800 loss: 0.0003 lr: 0.001\n",
      "iteration: 761900 loss: 0.0003 lr: 0.001\n",
      "iteration: 762000 loss: 0.0003 lr: 0.001\n",
      "iteration: 762100 loss: 0.0003 lr: 0.001\n",
      "iteration: 762200 loss: 0.0002 lr: 0.001\n",
      "iteration: 762300 loss: 0.0003 lr: 0.001\n",
      "iteration: 762400 loss: 0.0003 lr: 0.001\n",
      "iteration: 762500 loss: 0.0003 lr: 0.001\n",
      "iteration: 762600 loss: 0.0002 lr: 0.001\n",
      "iteration: 762700 loss: 0.0003 lr: 0.001\n",
      "iteration: 762800 loss: 0.0002 lr: 0.001\n",
      "iteration: 762900 loss: 0.0003 lr: 0.001\n",
      "iteration: 763000 loss: 0.0003 lr: 0.001\n",
      "iteration: 763100 loss: 0.0003 lr: 0.001\n",
      "iteration: 763200 loss: 0.0003 lr: 0.001\n",
      "iteration: 763300 loss: 0.0003 lr: 0.001\n",
      "iteration: 763400 loss: 0.0003 lr: 0.001\n",
      "iteration: 763500 loss: 0.0003 lr: 0.001\n",
      "iteration: 763600 loss: 0.0003 lr: 0.001\n",
      "iteration: 763700 loss: 0.0003 lr: 0.001\n",
      "iteration: 763800 loss: 0.0003 lr: 0.001\n",
      "iteration: 763900 loss: 0.0003 lr: 0.001\n",
      "iteration: 764000 loss: 0.0003 lr: 0.001\n",
      "iteration: 764100 loss: 0.0003 lr: 0.001\n",
      "iteration: 764200 loss: 0.0002 lr: 0.001\n",
      "iteration: 764300 loss: 0.0003 lr: 0.001\n",
      "iteration: 764400 loss: 0.0002 lr: 0.001\n",
      "iteration: 764500 loss: 0.0003 lr: 0.001\n",
      "iteration: 764600 loss: 0.0002 lr: 0.001\n",
      "iteration: 764700 loss: 0.0003 lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 764800 loss: 0.0003 lr: 0.001\n",
      "iteration: 764900 loss: 0.0003 lr: 0.001\n",
      "iteration: 765000 loss: 0.0002 lr: 0.001\n",
      "iteration: 765100 loss: 0.0003 lr: 0.001\n",
      "iteration: 765200 loss: 0.0003 lr: 0.001\n",
      "iteration: 765300 loss: 0.0002 lr: 0.001\n",
      "iteration: 765400 loss: 0.0003 lr: 0.001\n",
      "iteration: 765500 loss: 0.0002 lr: 0.001\n",
      "iteration: 765600 loss: 0.0002 lr: 0.001\n",
      "iteration: 765700 loss: 0.0003 lr: 0.001\n",
      "iteration: 765800 loss: 0.0002 lr: 0.001\n",
      "iteration: 765900 loss: 0.0003 lr: 0.001\n",
      "iteration: 766000 loss: 0.0003 lr: 0.001\n",
      "iteration: 766100 loss: 0.0003 lr: 0.001\n",
      "iteration: 766200 loss: 0.0003 lr: 0.001\n",
      "iteration: 766300 loss: 0.0003 lr: 0.001\n",
      "iteration: 766400 loss: 0.0004 lr: 0.001\n",
      "iteration: 766500 loss: 0.0003 lr: 0.001\n",
      "iteration: 766600 loss: 0.0002 lr: 0.001\n",
      "iteration: 766700 loss: 0.0003 lr: 0.001\n",
      "iteration: 766800 loss: 0.0003 lr: 0.001\n",
      "iteration: 766900 loss: 0.0002 lr: 0.001\n",
      "iteration: 767000 loss: 0.0003 lr: 0.001\n",
      "iteration: 767100 loss: 0.0003 lr: 0.001\n",
      "iteration: 767200 loss: 0.0002 lr: 0.001\n",
      "iteration: 767300 loss: 0.0003 lr: 0.001\n",
      "iteration: 767400 loss: 0.0002 lr: 0.001\n",
      "iteration: 767500 loss: 0.0003 lr: 0.001\n",
      "iteration: 767600 loss: 0.0003 lr: 0.001\n",
      "iteration: 767700 loss: 0.0003 lr: 0.001\n",
      "iteration: 767800 loss: 0.0003 lr: 0.001\n",
      "iteration: 767900 loss: 0.0003 lr: 0.001\n",
      "iteration: 768000 loss: 0.0003 lr: 0.001\n",
      "iteration: 768100 loss: 0.0003 lr: 0.001\n",
      "iteration: 768200 loss: 0.0002 lr: 0.001\n",
      "iteration: 768300 loss: 0.0002 lr: 0.001\n",
      "iteration: 768400 loss: 0.0002 lr: 0.001\n",
      "iteration: 768500 loss: 0.0003 lr: 0.001\n",
      "iteration: 768600 loss: 0.0003 lr: 0.001\n",
      "iteration: 768700 loss: 0.0003 lr: 0.001\n",
      "iteration: 768800 loss: 0.0003 lr: 0.001\n",
      "iteration: 768900 loss: 0.0002 lr: 0.001\n",
      "iteration: 769000 loss: 0.0002 lr: 0.001\n",
      "iteration: 769100 loss: 0.0003 lr: 0.001\n",
      "iteration: 769200 loss: 0.0003 lr: 0.001\n",
      "iteration: 769300 loss: 0.0003 lr: 0.001\n",
      "iteration: 769400 loss: 0.0002 lr: 0.001\n",
      "iteration: 769500 loss: 0.0003 lr: 0.001\n",
      "iteration: 769600 loss: 0.0003 lr: 0.001\n",
      "iteration: 769700 loss: 0.0003 lr: 0.001\n",
      "iteration: 769800 loss: 0.0002 lr: 0.001\n",
      "iteration: 769900 loss: 0.0002 lr: 0.001\n",
      "iteration: 770000 loss: 0.0004 lr: 0.001\n",
      "iteration: 770100 loss: 0.0002 lr: 0.001\n",
      "iteration: 770200 loss: 0.0003 lr: 0.001\n",
      "iteration: 770300 loss: 0.0003 lr: 0.001\n",
      "iteration: 770400 loss: 0.0002 lr: 0.001\n",
      "iteration: 770500 loss: 0.0002 lr: 0.001\n",
      "iteration: 770600 loss: 0.0003 lr: 0.001\n",
      "iteration: 770700 loss: 0.0003 lr: 0.001\n",
      "iteration: 770800 loss: 0.0003 lr: 0.001\n",
      "iteration: 770900 loss: 0.0003 lr: 0.001\n",
      "iteration: 771000 loss: 0.0003 lr: 0.001\n",
      "iteration: 771100 loss: 0.0002 lr: 0.001\n",
      "iteration: 771200 loss: 0.0004 lr: 0.001\n",
      "iteration: 771300 loss: 0.0003 lr: 0.001\n",
      "iteration: 771400 loss: 0.0003 lr: 0.001\n",
      "iteration: 771500 loss: 0.0002 lr: 0.001\n",
      "iteration: 771600 loss: 0.0003 lr: 0.001\n",
      "iteration: 771700 loss: 0.0003 lr: 0.001\n",
      "iteration: 771800 loss: 0.0002 lr: 0.001\n",
      "iteration: 771900 loss: 0.0002 lr: 0.001\n",
      "iteration: 772000 loss: 0.0004 lr: 0.001\n",
      "iteration: 772100 loss: 0.0003 lr: 0.001\n",
      "iteration: 772200 loss: 0.0003 lr: 0.001\n",
      "iteration: 772300 loss: 0.0003 lr: 0.001\n",
      "iteration: 772400 loss: 0.0003 lr: 0.001\n",
      "iteration: 772500 loss: 0.0003 lr: 0.001\n",
      "iteration: 772600 loss: 0.0003 lr: 0.001\n",
      "iteration: 772700 loss: 0.0003 lr: 0.001\n",
      "iteration: 772800 loss: 0.0003 lr: 0.001\n",
      "iteration: 772900 loss: 0.0004 lr: 0.001\n",
      "iteration: 773000 loss: 0.0002 lr: 0.001\n",
      "iteration: 773100 loss: 0.0003 lr: 0.001\n",
      "iteration: 773200 loss: 0.0002 lr: 0.001\n",
      "iteration: 773300 loss: 0.0003 lr: 0.001\n",
      "iteration: 773400 loss: 0.0003 lr: 0.001\n",
      "iteration: 773500 loss: 0.0003 lr: 0.001\n",
      "iteration: 773600 loss: 0.0003 lr: 0.001\n",
      "iteration: 773700 loss: 0.0003 lr: 0.001\n",
      "iteration: 773800 loss: 0.0003 lr: 0.001\n",
      "iteration: 773900 loss: 0.0003 lr: 0.001\n",
      "iteration: 774000 loss: 0.0003 lr: 0.001\n",
      "iteration: 774100 loss: 0.0002 lr: 0.001\n",
      "iteration: 774200 loss: 0.0002 lr: 0.001\n",
      "iteration: 774300 loss: 0.0003 lr: 0.001\n",
      "iteration: 774400 loss: 0.0002 lr: 0.001\n",
      "iteration: 774500 loss: 0.0003 lr: 0.001\n",
      "iteration: 774600 loss: 0.0002 lr: 0.001\n",
      "iteration: 774700 loss: 0.0003 lr: 0.001\n",
      "iteration: 774800 loss: 0.0002 lr: 0.001\n",
      "iteration: 774900 loss: 0.0002 lr: 0.001\n",
      "iteration: 775000 loss: 0.0003 lr: 0.001\n",
      "iteration: 775100 loss: 0.0002 lr: 0.001\n",
      "iteration: 775200 loss: 0.0003 lr: 0.001\n",
      "iteration: 775300 loss: 0.0002 lr: 0.001\n",
      "iteration: 775400 loss: 0.0003 lr: 0.001\n",
      "iteration: 775500 loss: 0.0002 lr: 0.001\n",
      "iteration: 775600 loss: 0.0003 lr: 0.001\n",
      "iteration: 775700 loss: 0.0003 lr: 0.001\n",
      "iteration: 775800 loss: 0.0002 lr: 0.001\n",
      "iteration: 775900 loss: 0.0003 lr: 0.001\n",
      "iteration: 776000 loss: 0.0003 lr: 0.001\n",
      "iteration: 776100 loss: 0.0003 lr: 0.001\n",
      "iteration: 776200 loss: 0.0003 lr: 0.001\n",
      "iteration: 776300 loss: 0.0003 lr: 0.001\n",
      "iteration: 776400 loss: 0.0003 lr: 0.001\n",
      "iteration: 776500 loss: 0.0003 lr: 0.001\n",
      "iteration: 776600 loss: 0.0002 lr: 0.001\n",
      "iteration: 776700 loss: 0.0003 lr: 0.001\n",
      "iteration: 776800 loss: 0.0002 lr: 0.001\n",
      "iteration: 776900 loss: 0.0003 lr: 0.001\n",
      "iteration: 777000 loss: 0.0003 lr: 0.001\n",
      "iteration: 777100 loss: 0.0003 lr: 0.001\n",
      "iteration: 777200 loss: 0.0002 lr: 0.001\n",
      "iteration: 777300 loss: 0.0002 lr: 0.001\n",
      "iteration: 777400 loss: 0.0003 lr: 0.001\n",
      "iteration: 777500 loss: 0.0003 lr: 0.001\n",
      "iteration: 777600 loss: 0.0003 lr: 0.001\n",
      "iteration: 777700 loss: 0.0003 lr: 0.001\n",
      "iteration: 777800 loss: 0.0003 lr: 0.001\n",
      "iteration: 777900 loss: 0.0003 lr: 0.001\n",
      "iteration: 778000 loss: 0.0003 lr: 0.001\n",
      "iteration: 778100 loss: 0.0003 lr: 0.001\n",
      "iteration: 778200 loss: 0.0003 lr: 0.001\n",
      "iteration: 778300 loss: 0.0002 lr: 0.001\n",
      "iteration: 778400 loss: 0.0002 lr: 0.001\n",
      "iteration: 778500 loss: 0.0002 lr: 0.001\n",
      "iteration: 778600 loss: 0.0003 lr: 0.001\n",
      "iteration: 778700 loss: 0.0003 lr: 0.001\n",
      "iteration: 778800 loss: 0.0002 lr: 0.001\n",
      "iteration: 778900 loss: 0.0003 lr: 0.001\n",
      "iteration: 779000 loss: 0.0002 lr: 0.001\n",
      "iteration: 779100 loss: 0.0003 lr: 0.001\n",
      "iteration: 779200 loss: 0.0003 lr: 0.001\n",
      "iteration: 779300 loss: 0.0003 lr: 0.001\n",
      "iteration: 779400 loss: 0.0002 lr: 0.001\n",
      "iteration: 779500 loss: 0.0002 lr: 0.001\n",
      "iteration: 779600 loss: 0.0003 lr: 0.001\n",
      "iteration: 779700 loss: 0.0003 lr: 0.001\n",
      "iteration: 779800 loss: 0.0003 lr: 0.001\n",
      "iteration: 779900 loss: 0.0002 lr: 0.001\n",
      "iteration: 780000 loss: 0.0003 lr: 0.001\n",
      "iteration: 780100 loss: 0.0003 lr: 0.001\n",
      "iteration: 780200 loss: 0.0003 lr: 0.001\n",
      "iteration: 780300 loss: 0.0003 lr: 0.001\n",
      "iteration: 780400 loss: 0.0003 lr: 0.001\n",
      "iteration: 780500 loss: 0.0003 lr: 0.001\n",
      "iteration: 780600 loss: 0.0002 lr: 0.001\n",
      "iteration: 780700 loss: 0.0003 lr: 0.001\n",
      "iteration: 780800 loss: 0.0003 lr: 0.001\n",
      "iteration: 780900 loss: 0.0002 lr: 0.001\n",
      "iteration: 781000 loss: 0.0003 lr: 0.001\n",
      "iteration: 781100 loss: 0.0003 lr: 0.001\n",
      "iteration: 781200 loss: 0.0002 lr: 0.001\n",
      "iteration: 781300 loss: 0.0003 lr: 0.001\n",
      "iteration: 781400 loss: 0.0003 lr: 0.001\n",
      "iteration: 781500 loss: 0.0003 lr: 0.001\n",
      "iteration: 781600 loss: 0.0003 lr: 0.001\n",
      "iteration: 781700 loss: 0.0003 lr: 0.001\n",
      "iteration: 781800 loss: 0.0003 lr: 0.001\n",
      "iteration: 781900 loss: 0.0003 lr: 0.001\n",
      "iteration: 782000 loss: 0.0004 lr: 0.001\n",
      "iteration: 782100 loss: 0.0003 lr: 0.001\n",
      "iteration: 782200 loss: 0.0003 lr: 0.001\n",
      "iteration: 782300 loss: 0.0003 lr: 0.001\n",
      "iteration: 782400 loss: 0.0004 lr: 0.001\n",
      "iteration: 782500 loss: 0.0003 lr: 0.001\n",
      "iteration: 782600 loss: 0.0003 lr: 0.001\n",
      "iteration: 782700 loss: 0.0004 lr: 0.001\n",
      "iteration: 782800 loss: 0.0003 lr: 0.001\n",
      "iteration: 782900 loss: 0.0003 lr: 0.001\n",
      "iteration: 783000 loss: 0.0003 lr: 0.001\n",
      "iteration: 783100 loss: 0.0003 lr: 0.001\n",
      "iteration: 783200 loss: 0.0002 lr: 0.001\n",
      "iteration: 783300 loss: 0.0003 lr: 0.001\n",
      "iteration: 783400 loss: 0.0003 lr: 0.001\n",
      "iteration: 783500 loss: 0.0003 lr: 0.001\n",
      "iteration: 783600 loss: 0.0003 lr: 0.001\n",
      "iteration: 783700 loss: 0.0003 lr: 0.001\n",
      "iteration: 783800 loss: 0.0003 lr: 0.001\n",
      "iteration: 783900 loss: 0.0003 lr: 0.001\n",
      "iteration: 784000 loss: 0.0003 lr: 0.001\n",
      "iteration: 784100 loss: 0.0003 lr: 0.001\n",
      "iteration: 784200 loss: 0.0003 lr: 0.001\n",
      "iteration: 784300 loss: 0.0003 lr: 0.001\n",
      "iteration: 784400 loss: 0.0002 lr: 0.001\n",
      "iteration: 784500 loss: 0.0003 lr: 0.001\n",
      "iteration: 784600 loss: 0.0002 lr: 0.001\n",
      "iteration: 784700 loss: 0.0003 lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 784800 loss: 0.0002 lr: 0.001\n",
      "iteration: 784900 loss: 0.0003 lr: 0.001\n",
      "iteration: 785000 loss: 0.0003 lr: 0.001\n",
      "iteration: 785100 loss: 0.0002 lr: 0.001\n",
      "iteration: 785200 loss: 0.0003 lr: 0.001\n",
      "iteration: 785300 loss: 0.0003 lr: 0.001\n",
      "iteration: 785400 loss: 0.0003 lr: 0.001\n",
      "iteration: 785500 loss: 0.0003 lr: 0.001\n",
      "iteration: 785600 loss: 0.0003 lr: 0.001\n",
      "iteration: 785700 loss: 0.0002 lr: 0.001\n",
      "iteration: 785800 loss: 0.0003 lr: 0.001\n",
      "iteration: 785900 loss: 0.0003 lr: 0.001\n",
      "iteration: 786000 loss: 0.0003 lr: 0.001\n",
      "iteration: 786100 loss: 0.0003 lr: 0.001\n",
      "iteration: 786200 loss: 0.0002 lr: 0.001\n",
      "iteration: 786300 loss: 0.0002 lr: 0.001\n",
      "iteration: 786400 loss: 0.0003 lr: 0.001\n",
      "iteration: 786500 loss: 0.0002 lr: 0.001\n",
      "iteration: 786600 loss: 0.0002 lr: 0.001\n",
      "iteration: 786700 loss: 0.0003 lr: 0.001\n",
      "iteration: 786800 loss: 0.0004 lr: 0.001\n",
      "iteration: 786900 loss: 0.0002 lr: 0.001\n",
      "iteration: 787000 loss: 0.0002 lr: 0.001\n",
      "iteration: 787100 loss: 0.0003 lr: 0.001\n",
      "iteration: 787200 loss: 0.0003 lr: 0.001\n",
      "iteration: 787300 loss: 0.0003 lr: 0.001\n",
      "iteration: 787400 loss: 0.0003 lr: 0.001\n",
      "iteration: 787500 loss: 0.0003 lr: 0.001\n",
      "iteration: 787600 loss: 0.0003 lr: 0.001\n",
      "iteration: 787700 loss: 0.0003 lr: 0.001\n",
      "iteration: 787800 loss: 0.0002 lr: 0.001\n",
      "iteration: 787900 loss: 0.0003 lr: 0.001\n",
      "iteration: 788000 loss: 0.0003 lr: 0.001\n",
      "iteration: 788100 loss: 0.0003 lr: 0.001\n",
      "iteration: 788200 loss: 0.0002 lr: 0.001\n",
      "iteration: 788300 loss: 0.0002 lr: 0.001\n",
      "iteration: 788400 loss: 0.0002 lr: 0.001\n",
      "iteration: 788500 loss: 0.0002 lr: 0.001\n",
      "iteration: 788600 loss: 0.0002 lr: 0.001\n",
      "iteration: 788700 loss: 0.0004 lr: 0.001\n",
      "iteration: 788800 loss: 0.0002 lr: 0.001\n",
      "iteration: 788900 loss: 0.0004 lr: 0.001\n",
      "iteration: 789000 loss: 0.0002 lr: 0.001\n",
      "iteration: 789100 loss: 0.0003 lr: 0.001\n",
      "iteration: 789200 loss: 0.0004 lr: 0.001\n",
      "iteration: 789300 loss: 0.0003 lr: 0.001\n",
      "iteration: 789400 loss: 0.0003 lr: 0.001\n",
      "iteration: 789500 loss: 0.0003 lr: 0.001\n",
      "iteration: 789600 loss: 0.0003 lr: 0.001\n",
      "iteration: 789700 loss: 0.0003 lr: 0.001\n",
      "iteration: 789800 loss: 0.0002 lr: 0.001\n",
      "iteration: 789900 loss: 0.0002 lr: 0.001\n",
      "iteration: 790000 loss: 0.0002 lr: 0.001\n",
      "iteration: 790100 loss: 0.0003 lr: 0.001\n",
      "iteration: 790200 loss: 0.0003 lr: 0.001\n",
      "iteration: 790300 loss: 0.0003 lr: 0.001\n",
      "iteration: 790400 loss: 0.0003 lr: 0.001\n",
      "iteration: 790500 loss: 0.0002 lr: 0.001\n",
      "iteration: 790600 loss: 0.0003 lr: 0.001\n",
      "iteration: 790700 loss: 0.0002 lr: 0.001\n",
      "iteration: 790800 loss: 0.0003 lr: 0.001\n",
      "iteration: 790900 loss: 0.0003 lr: 0.001\n",
      "iteration: 791000 loss: 0.0003 lr: 0.001\n",
      "iteration: 791100 loss: 0.0003 lr: 0.001\n",
      "iteration: 791200 loss: 0.0003 lr: 0.001\n",
      "iteration: 791300 loss: 0.0003 lr: 0.001\n",
      "iteration: 791400 loss: 0.0002 lr: 0.001\n",
      "iteration: 791500 loss: 0.0003 lr: 0.001\n",
      "iteration: 791600 loss: 0.0003 lr: 0.001\n",
      "iteration: 791700 loss: 0.0003 lr: 0.001\n",
      "iteration: 791800 loss: 0.0003 lr: 0.001\n",
      "iteration: 791900 loss: 0.0002 lr: 0.001\n",
      "iteration: 792000 loss: 0.0003 lr: 0.001\n",
      "iteration: 792100 loss: 0.0003 lr: 0.001\n",
      "iteration: 792200 loss: 0.0003 lr: 0.001\n",
      "iteration: 792300 loss: 0.0002 lr: 0.001\n",
      "iteration: 792400 loss: 0.0003 lr: 0.001\n",
      "iteration: 792500 loss: 0.0003 lr: 0.001\n",
      "iteration: 792600 loss: 0.0003 lr: 0.001\n",
      "iteration: 792700 loss: 0.0002 lr: 0.001\n",
      "iteration: 792800 loss: 0.0002 lr: 0.001\n",
      "iteration: 792900 loss: 0.0003 lr: 0.001\n",
      "iteration: 793000 loss: 0.0003 lr: 0.001\n",
      "iteration: 793100 loss: 0.0003 lr: 0.001\n",
      "iteration: 793200 loss: 0.0002 lr: 0.001\n",
      "iteration: 793300 loss: 0.0002 lr: 0.001\n",
      "iteration: 793400 loss: 0.0003 lr: 0.001\n",
      "iteration: 793500 loss: 0.0004 lr: 0.001\n",
      "iteration: 793600 loss: 0.0003 lr: 0.001\n",
      "iteration: 793700 loss: 0.0003 lr: 0.001\n",
      "iteration: 793800 loss: 0.0003 lr: 0.001\n",
      "iteration: 793900 loss: 0.0002 lr: 0.001\n",
      "iteration: 794000 loss: 0.0004 lr: 0.001\n",
      "iteration: 794100 loss: 0.0002 lr: 0.001\n",
      "iteration: 794200 loss: 0.0003 lr: 0.001\n",
      "iteration: 794300 loss: 0.0003 lr: 0.001\n",
      "iteration: 794400 loss: 0.0003 lr: 0.001\n",
      "iteration: 794500 loss: 0.0002 lr: 0.001\n",
      "iteration: 794600 loss: 0.0003 lr: 0.001\n",
      "iteration: 794700 loss: 0.0002 lr: 0.001\n",
      "iteration: 794800 loss: 0.0002 lr: 0.001\n",
      "iteration: 794900 loss: 0.0002 lr: 0.001\n",
      "iteration: 795000 loss: 0.0003 lr: 0.001\n",
      "iteration: 795100 loss: 0.0003 lr: 0.001\n",
      "iteration: 795200 loss: 0.0003 lr: 0.001\n",
      "iteration: 795300 loss: 0.0003 lr: 0.001\n",
      "iteration: 795400 loss: 0.0002 lr: 0.001\n",
      "iteration: 795500 loss: 0.0003 lr: 0.001\n",
      "iteration: 795600 loss: 0.0003 lr: 0.001\n",
      "iteration: 795700 loss: 0.0002 lr: 0.001\n",
      "iteration: 795800 loss: 0.0002 lr: 0.001\n",
      "iteration: 795900 loss: 0.0002 lr: 0.001\n",
      "iteration: 796000 loss: 0.0002 lr: 0.001\n",
      "iteration: 796100 loss: 0.0002 lr: 0.001\n",
      "iteration: 796200 loss: 0.0004 lr: 0.001\n",
      "iteration: 796300 loss: 0.0003 lr: 0.001\n",
      "iteration: 796400 loss: 0.0002 lr: 0.001\n",
      "iteration: 796500 loss: 0.0002 lr: 0.001\n",
      "iteration: 796600 loss: 0.0003 lr: 0.001\n",
      "iteration: 796700 loss: 0.0003 lr: 0.001\n",
      "iteration: 796800 loss: 0.0003 lr: 0.001\n",
      "iteration: 796900 loss: 0.0002 lr: 0.001\n",
      "iteration: 797000 loss: 0.0003 lr: 0.001\n",
      "iteration: 797100 loss: 0.0002 lr: 0.001\n",
      "iteration: 797200 loss: 0.0003 lr: 0.001\n",
      "iteration: 797300 loss: 0.0003 lr: 0.001\n",
      "iteration: 797400 loss: 0.0002 lr: 0.001\n",
      "iteration: 797500 loss: 0.0003 lr: 0.001\n",
      "iteration: 797600 loss: 0.0003 lr: 0.001\n",
      "iteration: 797700 loss: 0.0002 lr: 0.001\n",
      "iteration: 797800 loss: 0.0003 lr: 0.001\n",
      "iteration: 797900 loss: 0.0002 lr: 0.001\n",
      "iteration: 798000 loss: 0.0003 lr: 0.001\n",
      "iteration: 798100 loss: 0.0003 lr: 0.001\n",
      "iteration: 798200 loss: 0.0003 lr: 0.001\n",
      "iteration: 798300 loss: 0.0002 lr: 0.001\n",
      "iteration: 798400 loss: 0.0002 lr: 0.001\n",
      "iteration: 798500 loss: 0.0003 lr: 0.001\n",
      "iteration: 798600 loss: 0.0002 lr: 0.001\n",
      "iteration: 798700 loss: 0.0003 lr: 0.001\n",
      "iteration: 798800 loss: 0.0002 lr: 0.001\n",
      "iteration: 798900 loss: 0.0003 lr: 0.001\n",
      "iteration: 799000 loss: 0.0003 lr: 0.001\n",
      "iteration: 799100 loss: 0.0002 lr: 0.001\n",
      "iteration: 799200 loss: 0.0003 lr: 0.001\n",
      "iteration: 799300 loss: 0.0003 lr: 0.001\n",
      "iteration: 799400 loss: 0.0003 lr: 0.001\n",
      "iteration: 799500 loss: 0.0003 lr: 0.001\n",
      "iteration: 799600 loss: 0.0003 lr: 0.001\n",
      "iteration: 799700 loss: 0.0002 lr: 0.001\n",
      "iteration: 799800 loss: 0.0003 lr: 0.001\n",
      "iteration: 799900 loss: 0.0002 lr: 0.001\n",
      "iteration: 800000 loss: 0.0003 lr: 0.001\n",
      "iteration: 800100 loss: 0.0003 lr: 0.001\n",
      "iteration: 800200 loss: 0.0003 lr: 0.001\n",
      "iteration: 800300 loss: 0.0002 lr: 0.001\n",
      "iteration: 800400 loss: 0.0002 lr: 0.001\n",
      "iteration: 800500 loss: 0.0003 lr: 0.001\n",
      "iteration: 800600 loss: 0.0002 lr: 0.001\n",
      "iteration: 800700 loss: 0.0003 lr: 0.001\n",
      "iteration: 800800 loss: 0.0003 lr: 0.001\n",
      "iteration: 800900 loss: 0.0002 lr: 0.001\n",
      "iteration: 801000 loss: 0.0003 lr: 0.001\n",
      "iteration: 801100 loss: 0.0003 lr: 0.001\n",
      "iteration: 801200 loss: 0.0003 lr: 0.001\n",
      "iteration: 801300 loss: 0.0003 lr: 0.001\n",
      "iteration: 801400 loss: 0.0003 lr: 0.001\n",
      "iteration: 801500 loss: 0.0003 lr: 0.001\n",
      "iteration: 801600 loss: 0.0003 lr: 0.001\n",
      "iteration: 801700 loss: 0.0003 lr: 0.001\n",
      "iteration: 801800 loss: 0.0003 lr: 0.001\n",
      "iteration: 801900 loss: 0.0003 lr: 0.001\n",
      "iteration: 802000 loss: 0.0002 lr: 0.001\n",
      "iteration: 802100 loss: 0.0003 lr: 0.001\n",
      "iteration: 802200 loss: 0.0003 lr: 0.001\n",
      "iteration: 802300 loss: 0.0003 lr: 0.001\n",
      "iteration: 802400 loss: 0.0003 lr: 0.001\n",
      "iteration: 802500 loss: 0.0003 lr: 0.001\n",
      "iteration: 802600 loss: 0.0004 lr: 0.001\n",
      "iteration: 802700 loss: 0.0002 lr: 0.001\n",
      "iteration: 802800 loss: 0.0002 lr: 0.001\n",
      "iteration: 802900 loss: 0.0002 lr: 0.001\n",
      "iteration: 803000 loss: 0.0003 lr: 0.001\n",
      "iteration: 803100 loss: 0.0003 lr: 0.001\n",
      "iteration: 803200 loss: 0.0003 lr: 0.001\n",
      "iteration: 803300 loss: 0.0002 lr: 0.001\n",
      "iteration: 803400 loss: 0.0003 lr: 0.001\n",
      "iteration: 803500 loss: 0.0003 lr: 0.001\n",
      "iteration: 803600 loss: 0.0003 lr: 0.001\n",
      "iteration: 803700 loss: 0.0002 lr: 0.001\n",
      "iteration: 803800 loss: 0.0002 lr: 0.001\n",
      "iteration: 803900 loss: 0.0003 lr: 0.001\n",
      "iteration: 804000 loss: 0.0003 lr: 0.001\n",
      "iteration: 804100 loss: 0.0002 lr: 0.001\n",
      "iteration: 804200 loss: 0.0002 lr: 0.001\n",
      "iteration: 804300 loss: 0.0002 lr: 0.001\n",
      "iteration: 804400 loss: 0.0003 lr: 0.001\n",
      "iteration: 804500 loss: 0.0003 lr: 0.001\n",
      "iteration: 804600 loss: 0.0003 lr: 0.001\n",
      "iteration: 804700 loss: 0.0004 lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 804800 loss: 0.0003 lr: 0.001\n",
      "iteration: 804900 loss: 0.0003 lr: 0.001\n",
      "iteration: 805000 loss: 0.0003 lr: 0.001\n",
      "iteration: 805100 loss: 0.0003 lr: 0.001\n",
      "iteration: 805200 loss: 0.0002 lr: 0.001\n",
      "iteration: 805300 loss: 0.0003 lr: 0.001\n",
      "iteration: 805400 loss: 0.0003 lr: 0.001\n",
      "iteration: 805500 loss: 0.0003 lr: 0.001\n",
      "iteration: 805600 loss: 0.0003 lr: 0.001\n",
      "iteration: 805700 loss: 0.0003 lr: 0.001\n",
      "iteration: 805800 loss: 0.0003 lr: 0.001\n",
      "iteration: 805900 loss: 0.0003 lr: 0.001\n",
      "iteration: 806000 loss: 0.0003 lr: 0.001\n",
      "iteration: 806100 loss: 0.0003 lr: 0.001\n",
      "iteration: 806200 loss: 0.0003 lr: 0.001\n",
      "iteration: 806300 loss: 0.0003 lr: 0.001\n",
      "iteration: 806400 loss: 0.0002 lr: 0.001\n",
      "iteration: 806500 loss: 0.0003 lr: 0.001\n",
      "iteration: 806600 loss: 0.0003 lr: 0.001\n",
      "iteration: 806700 loss: 0.0002 lr: 0.001\n",
      "iteration: 806800 loss: 0.0003 lr: 0.001\n",
      "iteration: 806900 loss: 0.0002 lr: 0.001\n",
      "iteration: 807000 loss: 0.0003 lr: 0.001\n",
      "iteration: 807100 loss: 0.0004 lr: 0.001\n",
      "iteration: 807200 loss: 0.0004 lr: 0.001\n",
      "iteration: 807300 loss: 0.0003 lr: 0.001\n",
      "iteration: 807400 loss: 0.0002 lr: 0.001\n",
      "iteration: 807500 loss: 0.0003 lr: 0.001\n",
      "iteration: 807600 loss: 0.0004 lr: 0.001\n",
      "iteration: 807700 loss: 0.0002 lr: 0.001\n",
      "iteration: 807800 loss: 0.0004 lr: 0.001\n",
      "iteration: 807900 loss: 0.0002 lr: 0.001\n",
      "iteration: 808000 loss: 0.0003 lr: 0.001\n",
      "iteration: 808100 loss: 0.0003 lr: 0.001\n",
      "iteration: 808200 loss: 0.0003 lr: 0.001\n",
      "iteration: 808300 loss: 0.0003 lr: 0.001\n",
      "iteration: 808400 loss: 0.0003 lr: 0.001\n",
      "iteration: 808500 loss: 0.0002 lr: 0.001\n",
      "iteration: 808600 loss: 0.0002 lr: 0.001\n",
      "iteration: 808700 loss: 0.0003 lr: 0.001\n",
      "iteration: 808800 loss: 0.0002 lr: 0.001\n",
      "iteration: 808900 loss: 0.0003 lr: 0.001\n",
      "iteration: 809000 loss: 0.0003 lr: 0.001\n",
      "iteration: 809100 loss: 0.0003 lr: 0.001\n",
      "iteration: 809200 loss: 0.0003 lr: 0.001\n",
      "iteration: 809300 loss: 0.0002 lr: 0.001\n",
      "iteration: 809400 loss: 0.0002 lr: 0.001\n",
      "iteration: 809500 loss: 0.0003 lr: 0.001\n",
      "iteration: 809600 loss: 0.0002 lr: 0.001\n",
      "iteration: 809700 loss: 0.0002 lr: 0.001\n",
      "iteration: 809800 loss: 0.0003 lr: 0.001\n",
      "iteration: 809900 loss: 0.0003 lr: 0.001\n",
      "iteration: 810000 loss: 0.0003 lr: 0.001\n",
      "iteration: 810100 loss: 0.0002 lr: 0.001\n",
      "iteration: 810200 loss: 0.0003 lr: 0.001\n",
      "iteration: 810300 loss: 0.0004 lr: 0.001\n",
      "iteration: 810400 loss: 0.0002 lr: 0.001\n",
      "iteration: 810500 loss: 0.0003 lr: 0.001\n",
      "iteration: 810600 loss: 0.0003 lr: 0.001\n",
      "iteration: 810700 loss: 0.0003 lr: 0.001\n",
      "iteration: 810800 loss: 0.0002 lr: 0.001\n",
      "iteration: 810900 loss: 0.0003 lr: 0.001\n",
      "iteration: 811000 loss: 0.0003 lr: 0.001\n",
      "iteration: 811100 loss: 0.0003 lr: 0.001\n",
      "iteration: 811200 loss: 0.0003 lr: 0.001\n",
      "iteration: 811300 loss: 0.0002 lr: 0.001\n",
      "iteration: 811400 loss: 0.0003 lr: 0.001\n",
      "iteration: 811500 loss: 0.0004 lr: 0.001\n",
      "iteration: 811600 loss: 0.0003 lr: 0.001\n",
      "iteration: 811700 loss: 0.0002 lr: 0.001\n",
      "iteration: 811800 loss: 0.0003 lr: 0.001\n",
      "iteration: 811900 loss: 0.0003 lr: 0.001\n",
      "iteration: 812000 loss: 0.0003 lr: 0.001\n",
      "iteration: 812100 loss: 0.0003 lr: 0.001\n",
      "iteration: 812200 loss: 0.0003 lr: 0.001\n",
      "iteration: 812300 loss: 0.0002 lr: 0.001\n",
      "iteration: 812400 loss: 0.0003 lr: 0.001\n",
      "iteration: 812500 loss: 0.0003 lr: 0.001\n",
      "iteration: 812600 loss: 0.0003 lr: 0.001\n",
      "iteration: 812700 loss: 0.0003 lr: 0.001\n",
      "iteration: 812800 loss: 0.0002 lr: 0.001\n",
      "iteration: 812900 loss: 0.0003 lr: 0.001\n",
      "iteration: 813000 loss: 0.0003 lr: 0.001\n",
      "iteration: 813100 loss: 0.0003 lr: 0.001\n",
      "iteration: 813200 loss: 0.0003 lr: 0.001\n",
      "iteration: 813300 loss: 0.0003 lr: 0.001\n",
      "iteration: 813400 loss: 0.0003 lr: 0.001\n",
      "iteration: 813500 loss: 0.0002 lr: 0.001\n",
      "iteration: 813600 loss: 0.0002 lr: 0.001\n",
      "iteration: 813700 loss: 0.0003 lr: 0.001\n",
      "iteration: 813800 loss: 0.0003 lr: 0.001\n",
      "iteration: 813900 loss: 0.0002 lr: 0.001\n",
      "iteration: 814000 loss: 0.0003 lr: 0.001\n",
      "iteration: 814100 loss: 0.0003 lr: 0.001\n",
      "iteration: 814200 loss: 0.0002 lr: 0.001\n",
      "iteration: 814300 loss: 0.0003 lr: 0.001\n",
      "iteration: 814400 loss: 0.0003 lr: 0.001\n",
      "iteration: 814500 loss: 0.0002 lr: 0.001\n",
      "iteration: 814600 loss: 0.0003 lr: 0.001\n",
      "iteration: 814700 loss: 0.0003 lr: 0.001\n",
      "iteration: 814800 loss: 0.0003 lr: 0.001\n",
      "iteration: 814900 loss: 0.0003 lr: 0.001\n",
      "iteration: 815000 loss: 0.0003 lr: 0.001\n",
      "iteration: 815100 loss: 0.0003 lr: 0.001\n",
      "iteration: 815200 loss: 0.0003 lr: 0.001\n",
      "iteration: 815300 loss: 0.0002 lr: 0.001\n",
      "iteration: 815400 loss: 0.0002 lr: 0.001\n",
      "iteration: 815500 loss: 0.0003 lr: 0.001\n",
      "iteration: 815600 loss: 0.0002 lr: 0.001\n",
      "iteration: 815700 loss: 0.0003 lr: 0.001\n",
      "iteration: 815800 loss: 0.0003 lr: 0.001\n",
      "iteration: 815900 loss: 0.0003 lr: 0.001\n",
      "iteration: 816000 loss: 0.0002 lr: 0.001\n",
      "iteration: 816100 loss: 0.0003 lr: 0.001\n",
      "iteration: 816200 loss: 0.0002 lr: 0.001\n",
      "iteration: 816300 loss: 0.0002 lr: 0.001\n",
      "iteration: 816400 loss: 0.0002 lr: 0.001\n",
      "iteration: 816500 loss: 0.0003 lr: 0.001\n",
      "iteration: 816600 loss: 0.0003 lr: 0.001\n",
      "iteration: 816700 loss: 0.0003 lr: 0.001\n",
      "iteration: 816800 loss: 0.0003 lr: 0.001\n",
      "iteration: 816900 loss: 0.0003 lr: 0.001\n",
      "iteration: 817000 loss: 0.0002 lr: 0.001\n",
      "iteration: 817100 loss: 0.0003 lr: 0.001\n",
      "iteration: 817200 loss: 0.0002 lr: 0.001\n",
      "iteration: 817300 loss: 0.0003 lr: 0.001\n",
      "iteration: 817400 loss: 0.0003 lr: 0.001\n",
      "iteration: 817500 loss: 0.0003 lr: 0.001\n",
      "iteration: 817600 loss: 0.0004 lr: 0.001\n",
      "iteration: 817700 loss: 0.0002 lr: 0.001\n",
      "iteration: 817800 loss: 0.0003 lr: 0.001\n",
      "iteration: 817900 loss: 0.0003 lr: 0.001\n",
      "iteration: 818000 loss: 0.0003 lr: 0.001\n",
      "iteration: 818100 loss: 0.0002 lr: 0.001\n",
      "iteration: 818200 loss: 0.0003 lr: 0.001\n",
      "iteration: 818300 loss: 0.0003 lr: 0.001\n",
      "iteration: 818400 loss: 0.0002 lr: 0.001\n",
      "iteration: 818500 loss: 0.0003 lr: 0.001\n",
      "iteration: 818600 loss: 0.0003 lr: 0.001\n",
      "iteration: 818700 loss: 0.0003 lr: 0.001\n",
      "iteration: 818800 loss: 0.0003 lr: 0.001\n",
      "iteration: 818900 loss: 0.0002 lr: 0.001\n",
      "iteration: 819000 loss: 0.0003 lr: 0.001\n",
      "iteration: 819100 loss: 0.0003 lr: 0.001\n",
      "iteration: 819200 loss: 0.0003 lr: 0.001\n",
      "iteration: 819300 loss: 0.0003 lr: 0.001\n",
      "iteration: 819400 loss: 0.0002 lr: 0.001\n",
      "iteration: 819500 loss: 0.0003 lr: 0.001\n",
      "iteration: 819600 loss: 0.0002 lr: 0.001\n",
      "iteration: 819700 loss: 0.0003 lr: 0.001\n",
      "iteration: 819800 loss: 0.0004 lr: 0.001\n",
      "iteration: 819900 loss: 0.0002 lr: 0.001\n",
      "iteration: 820000 loss: 0.0003 lr: 0.001\n",
      "iteration: 820100 loss: 0.0003 lr: 0.001\n",
      "iteration: 820200 loss: 0.0003 lr: 0.001\n",
      "iteration: 820300 loss: 0.0003 lr: 0.001\n",
      "iteration: 820400 loss: 0.0003 lr: 0.001\n",
      "iteration: 820500 loss: 0.0003 lr: 0.001\n",
      "iteration: 820600 loss: 0.0003 lr: 0.001\n",
      "iteration: 820700 loss: 0.0002 lr: 0.001\n",
      "iteration: 820800 loss: 0.0002 lr: 0.001\n",
      "iteration: 820900 loss: 0.0002 lr: 0.001\n",
      "iteration: 821000 loss: 0.0002 lr: 0.001\n",
      "iteration: 821100 loss: 0.0002 lr: 0.001\n",
      "iteration: 821200 loss: 0.0003 lr: 0.001\n",
      "iteration: 821300 loss: 0.0002 lr: 0.001\n",
      "iteration: 821400 loss: 0.0003 lr: 0.001\n",
      "iteration: 821500 loss: 0.0002 lr: 0.001\n",
      "iteration: 821600 loss: 0.0003 lr: 0.001\n",
      "iteration: 821700 loss: 0.0002 lr: 0.001\n",
      "iteration: 821800 loss: 0.0002 lr: 0.001\n",
      "iteration: 821900 loss: 0.0003 lr: 0.001\n",
      "iteration: 822000 loss: 0.0002 lr: 0.001\n",
      "iteration: 822100 loss: 0.0002 lr: 0.001\n",
      "iteration: 822200 loss: 0.0003 lr: 0.001\n",
      "iteration: 822300 loss: 0.0002 lr: 0.001\n",
      "iteration: 822400 loss: 0.0003 lr: 0.001\n",
      "iteration: 822500 loss: 0.0003 lr: 0.001\n",
      "iteration: 822600 loss: 0.0003 lr: 0.001\n",
      "iteration: 822700 loss: 0.0003 lr: 0.001\n",
      "iteration: 822800 loss: 0.0003 lr: 0.001\n",
      "iteration: 822900 loss: 0.0003 lr: 0.001\n",
      "iteration: 823000 loss: 0.0002 lr: 0.001\n",
      "iteration: 823100 loss: 0.0003 lr: 0.001\n",
      "iteration: 823200 loss: 0.0003 lr: 0.001\n",
      "iteration: 823300 loss: 0.0003 lr: 0.001\n",
      "iteration: 823400 loss: 0.0002 lr: 0.001\n",
      "iteration: 823500 loss: 0.0003 lr: 0.001\n",
      "iteration: 823600 loss: 0.0003 lr: 0.001\n",
      "iteration: 823700 loss: 0.0002 lr: 0.001\n",
      "iteration: 823800 loss: 0.0003 lr: 0.001\n",
      "iteration: 823900 loss: 0.0003 lr: 0.001\n",
      "iteration: 824000 loss: 0.0003 lr: 0.001\n",
      "iteration: 824100 loss: 0.0003 lr: 0.001\n",
      "iteration: 824200 loss: 0.0003 lr: 0.001\n",
      "iteration: 824300 loss: 0.0004 lr: 0.001\n",
      "iteration: 824400 loss: 0.0003 lr: 0.001\n",
      "iteration: 824500 loss: 0.0002 lr: 0.001\n",
      "iteration: 824600 loss: 0.0003 lr: 0.001\n",
      "iteration: 824700 loss: 0.0002 lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 824800 loss: 0.0003 lr: 0.001\n",
      "iteration: 824900 loss: 0.0003 lr: 0.001\n",
      "iteration: 825000 loss: 0.0003 lr: 0.001\n",
      "iteration: 825100 loss: 0.0004 lr: 0.001\n",
      "iteration: 825200 loss: 0.0004 lr: 0.001\n",
      "iteration: 825300 loss: 0.0003 lr: 0.001\n",
      "iteration: 825400 loss: 0.0003 lr: 0.001\n",
      "iteration: 825500 loss: 0.0002 lr: 0.001\n",
      "iteration: 825600 loss: 0.0003 lr: 0.001\n",
      "iteration: 825700 loss: 0.0003 lr: 0.001\n",
      "iteration: 825800 loss: 0.0003 lr: 0.001\n",
      "iteration: 825900 loss: 0.0002 lr: 0.001\n",
      "iteration: 826000 loss: 0.0003 lr: 0.001\n",
      "iteration: 826100 loss: 0.0003 lr: 0.001\n",
      "iteration: 826200 loss: 0.0003 lr: 0.001\n",
      "iteration: 826300 loss: 0.0003 lr: 0.001\n",
      "iteration: 826400 loss: 0.0002 lr: 0.001\n",
      "iteration: 826500 loss: 0.0003 lr: 0.001\n",
      "iteration: 826600 loss: 0.0003 lr: 0.001\n",
      "iteration: 826700 loss: 0.0003 lr: 0.001\n",
      "iteration: 826800 loss: 0.0003 lr: 0.001\n",
      "iteration: 826900 loss: 0.0002 lr: 0.001\n",
      "iteration: 827000 loss: 0.0003 lr: 0.001\n",
      "iteration: 827100 loss: 0.0003 lr: 0.001\n",
      "iteration: 827200 loss: 0.0002 lr: 0.001\n",
      "iteration: 827300 loss: 0.0004 lr: 0.001\n",
      "iteration: 827400 loss: 0.0003 lr: 0.001\n",
      "iteration: 827500 loss: 0.0003 lr: 0.001\n",
      "iteration: 827600 loss: 0.0003 lr: 0.001\n",
      "iteration: 827700 loss: 0.0003 lr: 0.001\n",
      "iteration: 827800 loss: 0.0002 lr: 0.001\n",
      "iteration: 827900 loss: 0.0003 lr: 0.001\n",
      "iteration: 828000 loss: 0.0003 lr: 0.001\n",
      "iteration: 828100 loss: 0.0002 lr: 0.001\n",
      "iteration: 828200 loss: 0.0003 lr: 0.001\n",
      "iteration: 828300 loss: 0.0003 lr: 0.001\n",
      "iteration: 828400 loss: 0.0003 lr: 0.001\n",
      "iteration: 828500 loss: 0.0004 lr: 0.001\n",
      "iteration: 828600 loss: 0.0003 lr: 0.001\n",
      "iteration: 828700 loss: 0.0002 lr: 0.001\n",
      "iteration: 828800 loss: 0.0004 lr: 0.001\n",
      "iteration: 828900 loss: 0.0004 lr: 0.001\n",
      "iteration: 829000 loss: 0.0003 lr: 0.001\n",
      "iteration: 829100 loss: 0.0002 lr: 0.001\n",
      "iteration: 829200 loss: 0.0002 lr: 0.001\n",
      "iteration: 829300 loss: 0.0003 lr: 0.001\n",
      "iteration: 829400 loss: 0.0003 lr: 0.001\n",
      "iteration: 829500 loss: 0.0003 lr: 0.001\n",
      "iteration: 829600 loss: 0.0004 lr: 0.001\n",
      "iteration: 829700 loss: 0.0003 lr: 0.001\n",
      "iteration: 829800 loss: 0.0003 lr: 0.001\n",
      "iteration: 829900 loss: 0.0002 lr: 0.001\n",
      "iteration: 830000 loss: 0.0002 lr: 0.001\n",
      "iteration: 830100 loss: 0.0003 lr: 0.001\n",
      "iteration: 830200 loss: 0.0003 lr: 0.001\n",
      "iteration: 830300 loss: 0.0003 lr: 0.001\n",
      "iteration: 830400 loss: 0.0003 lr: 0.001\n",
      "iteration: 830500 loss: 0.0002 lr: 0.001\n",
      "iteration: 830600 loss: 0.0003 lr: 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-af11a929550c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         [_, loss_val, summary] = sess.run([train_op, total_loss, merged_summaries],\n\u001b[1;32m--> 192\u001b[1;33m                                           feed_dict={learning_rate: current_lr})\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 958\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1181\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path, displayiters=100, saveiters=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anonymous-filename",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['paw', 'index', 'pinky', 'pellet'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\proj_pw85shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis_tf2\\\\lib\\\\site-packages\\\\deeplabcutcore\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\Documentation_data-proj_85shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\dlc-models\\\\iteration-0\\\\projFeb11-trainset85shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11/evaluation-results/  already exists!\n",
      "C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11\\evaluation-results\\iteration-0\\projFeb11-trainset85shuffle1  already exists!\n",
      "Running  DLC_resnet50_projFeb11shuffle1_830000  with # of trainingiterations: 830000\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11\\dlc-models\\iteration-0\\projFeb11-trainset85shuffle1\\train\\snapshot-830000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:00, 45.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-830000\n",
      "Results for 830000  training iterations: 85 1 train error: 0.82 pixels. Test error: 3.67  pixels.\n",
      "With pcutoff of 0.6  train error: 0.82 pixels. Test error: 3.76 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "authentic-stanford",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['paw', 'index', 'pinky', 'pellet'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\proj_pw85shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis_tf2\\\\lib\\\\site-packages\\\\deeplabcutcore\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\Documentation_data-proj_85shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\dlc-models\\\\iteration-0\\\\projFeb11-trainset85shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-830000 for model C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11\\dlc-models\\iteration-0\\projFeb11-trainset85shuffle1\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11\\dlc-models\\iteration-0\\projFeb11-trainset85shuffle1\\train\\snapshot-830000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                                                                                         | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Starting to analyze %  00089__x__TRIAL_FRONT.avi\n",
      "Loading  00089__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:08, 193.11it/s]                                                                                                                                                                                                                                                                                             \n",
      "  0%|                                                                                                                                                                                                                                                                                         | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00087__x__TRIAL_FRONT.avi\n",
      "Loading  00087__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:06, 238.04it/s]                                                                                                                                                                                                                                                                                             \n",
      "  0%|                                                                                                                                                                                                                                                                                         | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00086__x__TRIAL_FRONT.avi\n",
      "Loading  00086__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:06, 237.58it/s]                                                                                                                                                                                                                                                                                             \n",
      "  0%|                                                                                                                                                                                                                                                                                         | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00085__x__TRIAL_FRONT.avi\n",
      "Loading  00085__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:06, 237.97it/s]                                                                                                                                                                                                                                                                                             \n",
      "  0%|                                                                                                                                                                                                                                                                                         | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00088__x__TRIAL_FRONT.avi\n",
      "Loading  00088__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:06, 234.69it/s]                                                                                                                                                                                                                                                                                             \n",
      "  0%|                                                                                                                                                                                                                                                                                         | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00090__x__TRIAL_FRONT.avi\n",
      "Loading  00090__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:07, 223.44it/s]                                                                                                                                                                                                                                                                                             \n",
      "  0%|                                                                                                                                                                                                                                                                                         | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00081__x__TRIAL_FRONT.avi\n",
      "Loading  00081__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:07, 226.70it/s]                                                                                                                                                                                                                                                                                             \n",
      "  0%|                                                                                                                                                                                                                                                                                         | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00083__x__TRIAL_FRONT.avi\n",
      "Loading  00083__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:06, 240.15it/s]                                                                                                                                                                                                                                                                                             \n",
      "  0%|                                                                                                                                                                                                                                                                                         | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00082__x__TRIAL_FRONT.avi\n",
      "Loading  00082__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:07, 229.69it/s]                                                                                                                                                                                                                                                                                             \n",
      "  0%|                                                                                                                                                                                                                                                                                         | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00084__x__TRIAL_FRONT.avi\n",
      "Loading  00084__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:07, 225.82it/s]                                                                                                                                                                                                                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_projFeb11shuffle1_830000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config_path, videos=[video_path], videotype='avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "crucial-sharp",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 105.30it/s]\n",
      "4it [00:00, 97.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Filtering with median model 00084__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00087__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 125.04it/s]\n",
      "4it [00:00, 137.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model 00085__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00088__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00081__x__TRIAL_FRONT.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 93.06it/s]\n",
      "4it [00:00, 133.38it/s]\n",
      "4it [00:00, 93.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Filtering with median model 00083__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00086__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 133.36it/s]\n",
      "4it [00:00, 100.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model 00082__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00089__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00090__x__TRIAL_FRONT.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 142.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.filterpredictions(config_path, [video_path], videotype='avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "herbal-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                         | 0/1600 [00:00<?, ?it/s]C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\utils\\make_labeled_video.py:110: FutureWarning: circle is deprecated in favor of disk.circle will be removed in version 0.19\n",
      "  rr, cc = circle(yc,xc,dotsize,shape=(ny,nx))\n",
      "  3%|████████▊                                                                                                                                                                                                                                                                      | 52/1600 [00:00<00:03, 514.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00089__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 571.61it/s]\n",
      "  4%|██████████▊                                                                                                                                                                                                                                                                    | 64/1600 [00:00<00:02, 633.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00088__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 606.25it/s]\n",
      "  5%|████████████▎                                                                                                                                                                                                                                                                  | 73/1600 [00:00<00:02, 723.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00086__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 630.13it/s]\n",
      "  4%|██████████▊                                                                                                                                                                                                                                                                    | 64/1600 [00:00<00:02, 627.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00083__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 623.98it/s]\n",
      "  4%|██████████▊                                                                                                                                                                                                                                                                    | 64/1600 [00:00<00:02, 627.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00087__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 666.33it/s]\n",
      "  4%|███████████▌                                                                                                                                                                                                                                                                   | 68/1600 [00:00<00:02, 673.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00084__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 608.56it/s]\n",
      "  4%|███████████                                                                                                                                                                                                                                                                    | 65/1600 [00:00<00:02, 637.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00090__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 638.93it/s]\n",
      "  4%|███████████▏                                                                                                                                                                                                                                                                   | 66/1600 [00:00<00:02, 653.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00081__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 661.37it/s]\n",
      "  4%|██████████▋                                                                                                                                                                                                                                                                    | 63/1600 [00:00<00:02, 623.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00085__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 654.34it/s]\n",
      "  4%|██████████▊                                                                                                                                                                                                                                                                    | 64/1600 [00:00<00:02, 627.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00082__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 644.59it/s]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(config_path, [video_path], videotype='avi', filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-maximum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
