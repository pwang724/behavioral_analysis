{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lasting-gardening",
   "metadata": {},
   "source": [
    "### Training networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heard-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow\n",
    "tensorflow.__version__\n",
    "import deeplabcutcore as dlc\n",
    "import matplotlib as mpl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hairy-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = r'C:\\Users\\Peter\\Desktop\\DLC\\test-pw-2021-02-24'\n",
    "config_path = os.path.join(project_path, 'config.yaml')\n",
    "video_path = os.path.join(project_path, 'videos_pred_dlc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extensive-novel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['middle_fingers', 'index', 'pinky', 'pellet'],\n",
      " 'alpha_r': 0.02,\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': False,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testFeb24\\\\test_pw85shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\test-pw-2021-02-24\\\\dlc-models\\\\iteration-0\\\\testFeb24-trainset85shuffle1\\\\train\\\\snapshot-710000',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testFeb24\\\\Documentation_data-test_85shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\test-pw-2021-02-24',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\test-pw-2021-02-24\\\\dlc-models\\\\iteration-0\\\\testFeb24-trainset85shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with imgaug pose-dataset loader.\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "WARNING:tensorflow:From C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tf_slim\\layers\\layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\nnet\\losses.py:38: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Loading already trained DLC with backbone: resnet_50\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\Desktop\\DLC\\test-pw-2021-02-24\\dlc-models\\iteration-0\\testFeb24-trainset85shuffle1\\train\\snapshot-710000\n",
      "Display_iters overwritten as 1000\n",
      "Save_iters overwritten as 10000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\test-pw-2021-02-24\\\\dlc-models\\\\iteration-0\\\\testFeb24-trainset85shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'crop': False, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['middle_fingers', 'index', 'pinky', 'pellet'], 'alpha_r': 0.02, 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testFeb24\\\\test_pw85shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\test-pw-2021-02-24\\\\dlc-models\\\\iteration-0\\\\testFeb24-trainset85shuffle1\\\\train\\\\snapshot-710000', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testFeb24\\\\Documentation_data-test_85shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 4, 'pairwise_huber_loss': False, 'pairwise_predict': False, 'partaffinityfield_predict': False, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\test-pw-2021-02-24', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'output_stride': 16, 'deconvolutionstride': 2}\n",
      "Starting training....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d30db7d59217>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdlc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         [_, loss_val, summary] = sess.run([train_op, total_loss, merged_summaries],\n\u001b[1;32m--> 192\u001b[1;33m                                           feed_dict={learning_rate: current_lr})\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 958\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1181\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dlc.train_network(config_path, displayiters=1000, saveiters=10000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anonymous-filename",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n",
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['middle_fingers', 'index', 'pinky', 'pellet'],\n",
      " 'alpha_r': 0.02,\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': False,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testFeb24\\\\test_pw85shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testFeb24\\\\Documentation_data-test_85shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\test-pw-2021-02-24',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\test-pw-2021-02-24\\\\dlc-models\\\\iteration-0\\\\testFeb24-trainset85shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\Desktop\\DLC\\test-pw-2021-02-24/evaluation-results/  already exists!\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\test-pw-2021-02-24\\evaluation-results\\iteration-0\\testFeb24-trainset85shuffle1  already exists!\n",
      "Running  DLC_resnet50_testFeb24shuffle1_710000  with # of trainingiterations: 710000\n",
      "This net has already been evaluated!\n"
     ]
    }
   ],
   "source": [
    "dlc.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authentic-stanford",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['middle_fingers', 'index', 'pinky', 'pellet'],\n",
      " 'alpha_r': 0.02,\n",
      " 'batch_size': 8,\n",
      " 'bottomheight': 400,\n",
      " 'crop': False,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testFeb24\\\\test_pw85shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testFeb24\\\\Documentation_data-test_85shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'num_outputs': 1,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\test-pw-2021-02-24',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\test-pw-2021-02-24\\\\dlc-models\\\\iteration-0\\\\testFeb24-trainset85shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-710000 for model C:\\Users\\Peter\\Desktop\\DLC\\test-pw-2021-02-24\\dlc-models\\iteration-0\\testFeb24-trainset85shuffle1\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\Desktop\\DLC\\test-pw-2021-02-24\\dlc-models\\iteration-0\\testFeb24-trainset85shuffle1\\train\\snapshot-710000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                                                           | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Starting to analyze %  M7_2021-02-16_00026_FRONT.avi\n",
      "Loading  M7_2021-02-16_00026_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 188.53it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:02, 341.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-17_00061_FRONT.avi\n",
      "Loading  M7_2021-02-17_00061_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:04, 210.92it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:02, 325.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-16_00021_FRONT.avi\n",
      "Loading  M7_2021-02-16_00021_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 197.37it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 310.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-16_00025_FRONT.avi\n",
      "Loading  M7_2021-02-16_00025_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 193.21it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 310.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-17_00069_FRONT.avi\n",
      "Loading  M7_2021-02-17_00069_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 188.53it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 298.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-16_00027_FRONT.avi\n",
      "Loading  M7_2021-02-16_00027_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 188.46it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 277.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-17_00064_FRONT.avi\n",
      "Loading  M7_2021-02-17_00064_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 183.39it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 275.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-16_00022_FRONT.avi\n",
      "Loading  M7_2021-02-16_00022_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 184.43it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:02, 339.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-16_00028_FRONT.avi\n",
      "Loading  M7_2021-02-16_00028_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 187.65it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 310.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-17_00066_FRONT.avi\n",
      "Loading  M7_2021-02-17_00066_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 184.06it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 307.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-16_00030_FRONT.avi\n",
      "Loading  M7_2021-02-16_00030_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 188.11it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 307.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-16_00023_FRONT.avi\n",
      "Loading  M7_2021-02-16_00023_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 186.85it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 310.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-16_00029_FRONT.avi\n",
      "Loading  M7_2021-02-16_00029_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 187.97it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 287.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-17_00067_FRONT.avi\n",
      "Loading  M7_2021-02-17_00067_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 184.50it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 296.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-17_00068_FRONT.avi\n",
      "Loading  M7_2021-02-17_00068_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 188.74it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:02, 328.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-17_00065_FRONT.avi\n",
      "Loading  M7_2021-02-17_00065_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 192.85it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:02, 327.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-16_00024_FRONT.avi\n",
      "Loading  M7_2021-02-16_00024_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 190.84it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 289.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-17_00062_FRONT.avi\n",
      "Loading  M7_2021-02-17_00062_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 187.34it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:02, 320.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-17_00070_FRONT.avi\n",
      "Loading  M7_2021-02-17_00070_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 188.32it/s]                                                                                                                                                                                                                                                               \n",
      "  4%|█████████▋                                                                                                                                                                                                                                       | 40/1000 [00:00<00:03, 305.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "Starting to analyze %  M7_2021-02-17_00063_FRONT.avi\n",
      "Loading  M7_2021-02-17_00063_FRONT.avi\n",
      "Duration of video [s]:  25.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:05, 191.71it/s]                                                                                                                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1000\n",
      "Saving results in ....\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_testFeb24shuffle1_710000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc.analyze_videos(config_path, \n",
    "                   videos=[video_path], \n",
    "                   videotype='avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "crucial-sharp",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 121.20it/s]\n",
      "4it [00:00, 148.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Filtering with median model M7_2021-02-16_00026_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-17_00067_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-16_00023_FRONT.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 142.82it/s]\n",
      "4it [00:00, 97.56it/s]\n",
      "4it [00:00, 117.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-16_00029_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-16_00025_FRONT.avi\n",
      "Saving filtered csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 148.22it/s]\n",
      "4it [00:00, 148.22it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model M7_2021-02-16_00022_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-17_00066_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-17_00062_FRONT.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 117.69it/s]\n",
      "4it [00:00, 153.79it/s]\n",
      "4it [00:00, 148.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-17_00068_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-16_00024_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-17_00070_FRONT.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 148.20it/s]\n",
      "4it [00:00, 129.09it/s]\n",
      "4it [00:00, 121.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-16_00028_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-16_00021_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-17_00063_FRONT.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 117.69it/s]\n",
      "4it [00:00, 105.30it/s]\n",
      "4it [00:00, 80.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-17_00061_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-16_00027_FRONT.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 108.14it/s]\n",
      "4it [00:00, 117.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-16_00030_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-17_00064_FRONT.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 111.15it/s]\n",
      "4it [00:00, 133.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-17_00069_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model M7_2021-02-17_00065_FRONT.avi\n",
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "dlc.filterpredictions(config_path, [video_path], videotype='avi')\n",
    "# dlc.create_labeled_video(config_path, [video_path], videotype='avi', filtered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reserved-disease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'outlier_frame_extraction_toolbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2be8d53b7580>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m dlc.extract_outlier_frames(config_path,\n\u001b[0;32m      2\u001b[0m                            \u001b[1;33m[\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                            \u001b[0moutlieralgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'manual'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m                            )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\refine_training_dataset\\outlier_frames.py\u001b[0m in \u001b[0;36mextract_outlier_frames\u001b[1;34m(config, videos, videotype, shuffle, trainingsetindex, outlieralgorithm, comparisonbodyparts, epsilon, p_bound, ARdegree, MAdegree, alpha, extractionalgorithm, automatic, cluster_resizewidth, cluster_color, opencv, savelabeled, destfolder)\u001b[0m\n\u001b[0;32m    167\u001b[0m               \u001b[0mwd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m               \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m               \u001b[1;32mfrom\u001b[0m \u001b[0mdeeplabcutcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefine_training_dataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moutlier_frame_extraction_toolbox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m               \u001b[0moutlier_frame_extraction_toolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msavelabeled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'outlier_frame_extraction_toolbox'"
     ]
    }
   ],
   "source": [
    "dlc.extract_outlier_frames(config_path,\n",
    "                           [video_path],\n",
    "                           outlieralgorithm='manual',\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-topic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:behavioral_analysis_tf1]",
   "language": "python",
   "name": "conda-env-behavioral_analysis_tf1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
