{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "documented-apartment",
   "metadata": {},
   "source": [
    "### Training networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heard-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow\n",
    "tensorflow.__version__\n",
    "import deeplabcutcore as dlc\n",
    "import matplotlib as mpl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "important-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = r'C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24'\n",
    "config_path = os.path.join(project_path, 'config.yaml')\n",
    "video_path = os.path.join(project_path, 'videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "invisible-parts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\training-datasets\\iteration-0\\UnaugmentedDataSet_pawFeb24  already exists!\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-16_00026_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-16_00027_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-16_00028_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-16_00029_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-16_00030_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-17_00061_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-17_00062_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-17_00063_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-17_00064_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-17_00065_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-17_00066_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-17_00067_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-17_00068_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-17_00069_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-17_00070_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-20_00001_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-20_00002_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-20_00003_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-20_00004_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-20_00005_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-20_00006_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-20_00007_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-20_00008_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-20_00009_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-20_00010_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-21_00031_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-21_00032_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-21_00033_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-21_00034_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-21_00035_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-21_00036_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-21_00037_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-21_00038_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-21_00039_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\labeled-data\\M7_2021-02-21_00040_FRONT\\CollectedData_pw.h5  not found (perhaps not annotated)\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\dlc-models\\iteration-0\\pawFeb24-trainset85shuffle1  already exists!\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\dlc-models\\iteration-0\\pawFeb24-trainset85shuffle1/train  already exists!\n",
      "C:\\Users\\Peter\\Desktop\\DLC\\project-pw-2021-02-24\\dlc-models\\iteration-0\\pawFeb24-trainset85shuffle1/test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.85,\n",
       "  1,\n",
       "  (array([ 79,  17,  52,   7,  88,  32,  71,  92,  51,  69,   8,  34,  58,\n",
       "           74,  50,  45,  33, 111, 103,  75,  14,  97,  19,  87,  66,  95,\n",
       "           11,  41, 102, 100,  85,  99,  81,  15,   5,   2,  82,  94,  73,\n",
       "           62, 109,  48,  25,  39,  46, 114,   0,   9,  40,  98,  77,  96,\n",
       "           84, 113,  67, 117,  43, 119,  56,  22, 104,  49,  80,  70,  18,\n",
       "           76,  60,  44,  38,  78,  26,  21, 116,  16,  72,  68,  59,   3,\n",
       "           23,  47,  55,  29,  61, 105,  20,  31,  90,  65, 112,  93,  24,\n",
       "           63, 108,  10,  12, 110,  36, 115,   1,  28,   4,  27]),\n",
       "   array([ 35,  53, 107,  54,  83,  86,  13,  91,  64, 106,  89,  37, 101,\n",
       "           57,   6,  42,  30, 118])))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc.create_training_dataset(config_path, augmenter_type='imgaug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-novel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['middle_fingers', 'index', 'pinky', 'pellet'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_pawFeb24\\\\paw_pw85shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis_tf2\\\\lib\\\\site-packages\\\\deeplabcutcore\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_pawFeb24\\\\Documentation_data-paw_85shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\project-pw-2021-02-24',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\project-pw-2021-02-24\\\\dlc-models\\\\iteration-0\\\\pawFeb24-trainset85shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with imgaug pose-dataset loader.\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\n",
      "Display_iters overwritten as 1000\n",
      "Save_iters overwritten as 10000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\project-pw-2021-02-24\\\\dlc-models\\\\iteration-0\\\\pawFeb24-trainset85shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['middle_fingers', 'index', 'pinky', 'pellet'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_pawFeb24\\\\paw_pw85shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis_tf2\\\\lib\\\\site-packages\\\\deeplabcutcore\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_pawFeb24\\\\Documentation_data-paw_85shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\project-pw-2021-02-24', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'output_stride': 16, 'deconvolutionstride': 2}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0296 lr: 0.005\n",
      "iteration: 2000 loss: 0.0160 lr: 0.005\n"
     ]
    }
   ],
   "source": [
    "dlc.train_network(config_path, displayiters=1000, saveiters=10000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anonymous-filename",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['paw', 'index', 'pinky', 'pellet'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\proj_pw85shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Peter\\\\anaconda3\\\\envs\\\\behavior_analysis_tf2\\\\lib\\\\site-packages\\\\deeplabcutcore\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_projFeb11\\\\Documentation_data-proj_85shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Peter\\\\Desktop\\\\behavioral_analysis\\\\proj-pw-2021-02-11\\\\dlc-models\\\\iteration-0\\\\projFeb11-trainset85shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11/evaluation-results/  already exists!\n",
      "C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11\\evaluation-results\\iteration-0\\projFeb11-trainset85shuffle1  already exists!\n",
      "Running  DLC_resnet50_projFeb11shuffle1_830000  with # of trainingiterations: 830000\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\Desktop\\behavioral_analysis\\proj-pw-2021-02-11\\dlc-models\\iteration-0\\projFeb11-trainset85shuffle1\\train\\snapshot-830000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:00, 45.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-830000\n",
      "Results for 830000  training iterations: 85 1 train error: 0.82 pixels. Test error: 3.67  pixels.\n",
      "With pcutoff of 0.6  train error: 0.82 pixels. Test error: 3.76 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "authentic-stanford",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-830000 for model C:\\Users\\Peter\\Desktop\\DLC\\proj-pw-2021-02-11\\dlc-models\\iteration-0\\projFeb11-trainset85shuffle1\n",
      "Initializing ResNet\n",
      "WARNING:tensorflow:From C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tf_slim\\layers\\layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\tf_slim\\layers\\layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\Desktop\\DLC\\proj-pw-2021-02-11\\dlc-models\\iteration-0\\projFeb11-trainset85shuffle1\\train\\snapshot-830000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Peter\\Desktop\\DLC\\proj-pw-2021-02-11\\dlc-models\\iteration-0\\projFeb11-trainset85shuffle1\\train\\snapshot-830000\n",
      "  0%|                                                                                                                                                                                                                                                          | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Starting to analyze %  00083__x__TRIAL_FRONT.avi\n",
      "Video already analyzed! .\\00083__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000.h5\n",
      "Starting to analyze %  00082__x__TRIAL_FRONT.avi\n",
      "Video already analyzed! .\\00082__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000.h5\n",
      "Starting to analyze %  00091__x__TRIAL_FRONT.avi\n",
      "Loading  00091__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:09, 162.19it/s]                                                                                                                                                                                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00090__x__TRIAL_FRONT.avi\n",
      "Video already analyzed! .\\00090__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000.h5\n",
      "Starting to analyze %  00084__x__TRIAL_FRONT.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                                                          | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video already analyzed! .\\00084__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000.h5\n",
      "Starting to analyze %  00086__x__TRIAL_FRONT.avi\n",
      "Video already analyzed! .\\00086__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000.h5\n",
      "Starting to analyze %  00081__x__TRIAL_FRONT.avi\n",
      "Video already analyzed! .\\00081__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000.h5\n",
      "Starting to analyze %  00087__x__TRIAL_FRONT.avi\n",
      "Video already analyzed! .\\00087__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000.h5\n",
      "Starting to analyze %  00085__x__TRIAL_FRONT.avi\n",
      "Video already analyzed! .\\00085__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000.h5\n",
      "Starting to analyze %  00088__x__TRIAL_FRONT.avi\n",
      "Video already analyzed! .\\00088__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000.h5\n",
      "Starting to analyze %  00092__x__TRIAL_FRONT.avi\n",
      "Loading  00092__x__TRIAL_FRONT.avi\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600  found with (before cropping) frame dimensions:  352 272\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:06, 233.67it/s]                                                                                                                                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1600\n",
      "Saving results in ....\n",
      "Starting to analyze %  00089__x__TRIAL_FRONT.avi\n",
      "Video already analyzed! .\\00089__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000.h5\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_projFeb11shuffle1_830000'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config_path, videos=[video_path], videotype='avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crucial-sharp",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 114.32it/s]\n",
      "4it [00:00, 93.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Filtering with median model 00091__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model 00088__x__TRIAL_FRONT.avi\n",
      "Video already filtered... .\\00088__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000filtered.h5\n",
      "Filtering with median model 00081__x__TRIAL_FRONT.avi\n",
      "Video already filtered... .\\00081__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000filtered.h5\n",
      "Filtering with median model 00082__x__TRIAL_FRONT.avi\n",
      "Video already filtered... .\\00082__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000filtered.h5\n",
      "Filtering with median model 00087__x__TRIAL_FRONT.avi\n",
      "Video already filtered... .\\00087__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000filtered.h5\n",
      "Filtering with median model 00083__x__TRIAL_FRONT.avi\n",
      "Video already filtered... .\\00083__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000filtered.h5\n",
      "Filtering with median model 00084__x__TRIAL_FRONT.avi\n",
      "Video already filtered... .\\00084__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000filtered.h5\n",
      "Filtering with median model 00092__x__TRIAL_FRONT.avi\n",
      "Saving filtered csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model 00089__x__TRIAL_FRONT.avi\n",
      "Video already filtered... .\\00089__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000filtered.h5\n",
      "Filtering with median model 00085__x__TRIAL_FRONT.avi\n",
      "Video already filtered... .\\00085__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000filtered.h5\n",
      "Filtering with median model 00090__x__TRIAL_FRONT.avi\n",
      "Video already filtered... .\\00090__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000filtered.h5\n",
      "Filtering with median model 00086__x__TRIAL_FRONT.avi\n",
      "Video already filtered... .\\00086__x__TRIAL_FRONTDLC_resnet50_projFeb11shuffle1_830000filtered.h5\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.filterpredictions(config_path, [video_path], videotype='avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "herbal-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                          | 0/1600 [00:00<?, ?it/s]C:\\Users\\Peter\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\utils\\make_labeled_video.py:110: FutureWarning: circle is deprecated in favor of disk.circle will be removed in version 0.19\n",
      "  rr, cc = circle(yc,xc,dotsize,shape=(ny,nx))\n",
      "  4%|█████████▊                                                                                                                                                                                                                                      | 65/1600 [00:00<00:02, 643.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00085__x__TRIAL_FRONT.avi and data.\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00092__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 592.34it/s]\n",
      "  2%|██████                                                                                                                                                                                                                                          | 40/1600 [00:00<00:03, 396.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00081__x__TRIAL_FRONT.avi and data.\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00083__x__TRIAL_FRONT.avi and data.\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00090__x__TRIAL_FRONT.avi and data.\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00086__x__TRIAL_FRONT.avi and data.\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00082__x__TRIAL_FRONT.avi and data.\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00088__x__TRIAL_FRONT.avi and data.\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00087__x__TRIAL_FRONT.avi and data.\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00084__x__TRIAL_FRONT.avi and data.\n",
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00091__x__TRIAL_FRONT.avi and data.\n",
      "1600\n",
      "Duration of video [s]:  40.0 , recorded with  40.0 fps!\n",
      "Overall # of frames:  1600 with cropped frame dimensions:  352 272\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:02<00:00, 605.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Peter\\\\Desktop\\\\DLC\\\\proj-pw-2021-02-11\\\\videos']\n",
      "Loading  00089__x__TRIAL_FRONT.avi and data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(config_path, [video_path], videotype='avi', filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adult-chemistry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Method  jump  found  16  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "yes/noyes\n",
      "Frames from video 00090__x__TRIAL_FRONT  already extracted (more will be added)!\n",
      "Loading video...\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bcef5868856d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_outlier_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\refine_training_dataset\\outlier_frames.py\u001b[0m in \u001b[0;36mextract_outlier_frames\u001b[1;34m(config, videos, videotype, shuffle, trainingsetindex, outlieralgorithm, comparisonbodyparts, epsilon, p_bound, ARdegree, MAdegree, alpha, extractionalgorithm, automatic, cluster_resizewidth, cluster_color, opencv, savelabeled, destfolder)\u001b[0m\n\u001b[0;32m    189\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0maskuser\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'y'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0maskuser\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'yes'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0maskuser\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Ja'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0maskuser\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'ha'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# multilanguage support :)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                   \u001b[1;31m#Now extract from those Indices!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                   \u001b[0mExtractFramesbasedonPreselection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mextractionalgorithm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopencv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcluster_resizewidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcluster_color\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msavelabeled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Nothing extracted, please change the parameters and start again...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_analysis_tf2\\lib\\site-packages\\deeplabcutcore\\refine_training_dataset\\outlier_frames.py\u001b[0m in \u001b[0;36mExtractFramesbasedonPreselection\u001b[1;34m(Index, extractionalgorithm, Dataframe, dataname, scorer, video, cfg, config, opencv, cluster_resizewidth, cluster_color, savelabeled)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0mcap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mfps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnframes\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_outlier_frames(config_path, [video_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-maximum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
